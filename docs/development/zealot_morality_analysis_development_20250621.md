# Zealot Morality Analysis å¼€å‘æ—¥å¿— - 2024å¹´12æœˆ22æ—¥

## æ¦‚è¿°

æœ¬æ¬¡å¼€å‘ä¼šè¯ä¸»è¦å¯¹ `polarization_triangle/experiments/zealot_morality_analysis.py` å’Œ `polarization_triangle/utils/data_manager.py` è¿›è¡Œäº†é‡å¤§åŠŸèƒ½å¢å¼ºï¼ŒåŒ…æ‹¬ï¼š

1. **æ–°å¢ variance per identity æŒ‡æ ‡**ï¼šè®¡ç®—æ¯ä¸ªèº«ä»½ç»„å†…éƒ¨çš„æ„è§æ–¹å·®
2. **å®ç°å¹¶è¡Œè®¡ç®—åŠŸèƒ½**ï¼šæ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œæ‰§è¡Œï¼Œæ˜¾è‘—æå‡æ€§èƒ½
3. **ä¼˜åŒ–æ•°æ®ç®¡ç†ç³»ç»Ÿ**ï¼šä½¿ç”¨ Parquet æ ¼å¼çš„é«˜æ•ˆå­˜å‚¨æ–¹æ¡ˆ
4. **å¢å¼ºå¯è§†åŒ–ç³»ç»Ÿ**ï¼šæ”¯æŒæ›´å¤šå›¾è¡¨ç±»å‹å’Œæ ·å¼é…ç½®

## æ–‡ä»¶ä¿®æ”¹è¯¦æƒ…

### 1. polarization_triangle/experiments/zealot_morality_analysis.py

#### 1.1 æ–‡ä»¶ç»“æ„å’Œæ•´ä½“æ¶æ„

**æ–‡ä»¶é•¿åº¦**ï¼š1383è¡Œï¼Œæ˜¯ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„å®éªŒåˆ†ææ¨¡å—

**ä¸»è¦ç»„æˆéƒ¨åˆ†**ï¼š
- **å·¥å…·å‡½æ•°**ï¼šæ—¶é—´æ ¼å¼åŒ–ç­‰è¾…åŠ©åŠŸèƒ½
- **å¹¶è¡Œè®¡ç®—æ”¯æŒå‡½æ•°**ï¼šå¤šè¿›ç¨‹ä»»åŠ¡å¤„ç†
- **æ ¸å¿ƒå®éªŒé€»è¾‘å‡½æ•°**ï¼šå‚æ•°ç»„åˆç”Ÿæˆã€å•æ¬¡æ¨¡æ‹Ÿæ‰§è¡Œã€å‚æ•°æ‰«æ
- **æ•°æ®ç®¡ç†å‡½æ•°**ï¼šä¸æ–°çš„æ•°æ®ç®¡ç†å™¨é›†æˆ
- **ç»˜å›¾ç›¸å…³å‡½æ•°**ï¼šæ ·å¼é…ç½®ã€å›¾è¡¨ç”Ÿæˆ
- **é«˜çº§æ¥å£å‡½æ•°**ï¼šç”¨æˆ·å‹å¥½çš„APIæ¥å£

#### 1.2 æ–°å¢çš„ variance per identity æŒ‡æ ‡

**åŠŸèƒ½æè¿°**ï¼š
- è®¡ç®—æ¯ä¸ªèº«ä»½ç»„ï¼ˆidentity=1 å’Œ identity=-1ï¼‰å†…éƒ¨çš„æ„è§æ–¹å·®
- æä¾›åˆ†ç¦»ç‰ˆæœ¬å’Œåˆå¹¶ç‰ˆæœ¬çš„å¯è§†åŒ–

**æ ¸å¿ƒå®ç°**ï¼š

```python
def run_single_simulation(config: SimulationConfig, steps: int = 500) -> Dict[str, float]:
    # ... ç°æœ‰ä»£ç  ...
    
    # è®¡ç®— variance per identity (æ¯ä¸ªèº«ä»½ç»„å†…çš„æ–¹å·®)
    variance_per_identity = {'identity_1': 0.0, 'identity_-1': 0.0}
    
    # è·å–ézealotèŠ‚ç‚¹çš„æ„è§å’Œèº«ä»½
    zealot_mask = np.zeros(sim.num_agents, dtype=bool)
    if sim.enable_zealots and sim.zealot_ids:
        zealot_mask[sim.zealot_ids] = True
    
    non_zealot_mask = ~zealot_mask
    non_zealot_opinions = sim.opinions[non_zealot_mask]
    non_zealot_identities = sim.identities[non_zealot_mask]
    
    # åˆ†åˆ«è®¡ç®—æ¯ä¸ªèº«ä»½ç»„çš„æ–¹å·®
    for identity_val in [1, -1]:
        identity_mask = non_zealot_identities == identity_val
        if np.sum(identity_mask) > 1:  # è‡³å°‘éœ€è¦2ä¸ªèŠ‚ç‚¹æ‰èƒ½è®¡ç®—æ–¹å·®
            identity_opinions = non_zealot_opinions[identity_mask]
            variance_per_identity[f'identity_{identity_val}'] = float(np.var(identity_opinions))
        else:
            variance_per_identity[f'identity_{identity_val}'] = 0.0
    
    return {
        'mean_opinion': mean_stats['mean_opinion'],
        'variance': variance_stats['overall_variance'],
        'identity_opinion_difference': identity_opinion_difference,
        'polarization_index': polarization,
        'variance_per_identity': variance_per_identity  # æ–°å¢æŒ‡æ ‡
    }
```

**å…³é”®ä¿®å¤**ï¼š
- ä¿®æ­£äº† zealot è¯†åˆ«é€»è¾‘ï¼šä»é”™è¯¯çš„ `sim.is_zealot` æ”¹ä¸ºæ­£ç¡®çš„ `sim.zealot_ids`
- æ­£ç¡®åŒºåˆ† zealot å’Œé zealot èŠ‚ç‚¹ï¼Œç¡®ä¿æ–¹å·®è®¡ç®—çš„å‡†ç¡®æ€§

#### 1.3 å¹¶è¡Œè®¡ç®—åŠŸèƒ½å®ç°

**è®¾è®¡ç†å¿µ**ï¼š
- é‡‡ç”¨ä»»åŠ¡çº§å¹¶è¡Œï¼šæ¯ä¸ªæ¨¡æ‹Ÿè¿è¡Œä½œä¸ºç‹¬ç«‹ä»»åŠ¡
- ä¿æŒå‘åå…¼å®¹ï¼š`num_processes=1` æ—¶ä½¿ç”¨åŸæœ‰ä¸²è¡Œé€»è¾‘
- å®¹é”™æœºåˆ¶ï¼šå¤±è´¥ä»»åŠ¡ç”¨ NaN å¡«å……ï¼Œæ”¯æŒè‡ªåŠ¨å›é€€

**æ ¸å¿ƒå‡½æ•°**ï¼š

```python
def run_single_simulation_task(task_params):
    """
    å•ä¸ªæ¨¡æ‹Ÿä»»åŠ¡çš„åŒ…è£…å‡½æ•°ï¼Œç”¨äºå¤šè¿›ç¨‹å¹¶è¡Œè®¡ç®—
    """
    try:
        plot_type, combination, x_val, run_idx, steps, process_id = task_params
        
        # è®¾ç½®è¿›ç¨‹ç‰¹å®šçš„éšæœºç§å­
        np.random.seed((int(x_val * 1000) + run_idx + process_id) % (2**32))
        
        # æ„å»ºé…ç½®å¹¶è¿è¡Œæ¨¡æ‹Ÿ
        # ... é…ç½®é€»è¾‘ ...
        
        results = run_single_simulation(base_config, steps)
        return (x_val, run_idx, results, True, None)
        
    except Exception as e:
        error_msg = f"Process {process_id}: Simulation failed for x={x_val}, run={run_idx}: {str(e)}"
        return (x_val, run_idx, None, False, error_msg)

def run_parameter_sweep_parallel(plot_type: str, combination: Dict[str, Any], 
                                x_values: List[float], num_runs: int = 5, num_processes: int = 4):
    """
    å¹¶è¡Œç‰ˆæœ¬çš„å‚æ•°æ‰«æ
    """
    print(f"ğŸš€ ä½¿ç”¨ {num_processes} ä¸ªè¿›ç¨‹è¿›è¡Œå¹¶è¡Œè®¡ç®—...")
    
    # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
    tasks = []
    for x_val in x_values:
        for run_idx in range(num_runs):
            process_id = len(tasks) % num_processes
            task = (plot_type, combination, x_val, run_idx, combination['steps'], process_id)
            tasks.append(task)
    
    # æ‰§è¡Œå¹¶è¡Œè®¡ç®—
    try:
        with multiprocessing.Pool(num_processes) as pool:
            results_list = []
            with tqdm(total=len(tasks), desc=f"Running {combination['label']} (parallel)") as pbar:
                for result in pool.imap(run_single_simulation_task, tasks):
                    results_list.append(result)
                    pbar.update(1)
    except Exception as e:
        print(f"âŒ å¹¶è¡Œè®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°ä¸²è¡Œæ¨¡å¼: {e}")
        return run_parameter_sweep_serial(plot_type, combination, x_values, num_runs)
    
    return organize_parallel_results(results_list, x_values, num_runs)
```

**æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§**ï¼š
- éšæœºç§å­ç®¡ç†ï¼šç¡®ä¿æ¯ä¸ªè¿›ç¨‹æœ‰ä¸åŒä½†å¯é‡ç°çš„éšæœºåºåˆ—
- è¿›åº¦æ˜¾ç¤ºï¼šå¹¶è¡Œä»»åŠ¡ä¹Ÿæœ‰è¯¦ç»†çš„è¿›åº¦æ¡
- é”™è¯¯å¤„ç†ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œå›é€€æœºåˆ¶

#### 1.4 å¢å¼ºçš„å¯è§†åŒ–ç³»ç»Ÿ

**æ–°å¢å›¾è¡¨ç±»å‹**ï¼š
- `variance_per_identity_1`ï¼šidentity=+1 ç»„çš„æ–¹å·®å›¾è¡¨
- `variance_per_identity_-1`ï¼šidentity=-1 ç»„çš„æ–¹å·®å›¾è¡¨  
- `variance_per_identity_combined`ï¼šä¸¤ä¸ªèº«ä»½ç»„çš„åˆå¹¶å›¾è¡¨

**æ ·å¼é…ç½®ç³»ç»Ÿ**ï¼š

```python
def get_variance_per_identity_style(identity_label: str, plot_type: str) -> Dict[str, Any]:
    """
    ä¸º variance per identity å›¾è¡¨ç”Ÿæˆç‰¹æ®Šçš„æ ·å¼é…ç½®
    """
    # çº¿å‹ç»„åˆï¼šå®çº¿ç”¨äº ID=1ï¼Œè™šçº¿ç”¨äº ID=-1
    linestyles = {
        '1': '-',      # å®çº¿ç”¨äº identity=1
        '-1': '--'     # è™šçº¿ç”¨äº identity=-1
    }
    
    # æ ‡è®°å½¢çŠ¶ï¼šåœ†å½¢ç”¨äº ID=1ï¼Œæ–¹å½¢ç”¨äº ID=-1
    markers = {
        '1': 'o',      # åœ†å½¢ç”¨äº identity=1
        '-1': 's'      # æ–¹å½¢ç”¨äº identity=-1
    }
    
    # æå–èº«ä»½å€¼å’ŒåŸå§‹ç»„åˆæ ‡ç­¾
    identity_val = identity_label.split('(ID=')[-1].rstrip(')')
    base_label = identity_label.split(' (ID=')[0]
    
    # åŸºäºå“ˆå¸Œå€¼åˆ†é…é¢œè‰²ï¼Œç¡®ä¿ä¸€è‡´æ€§
    color_index = abs(hash(base_label)) % len(colors)
    if identity_val == '-1':
        color_index = (color_index + len(colors) // 2) % len(colors)
    
    return {
        'color': colors[color_index],
        'linestyle': linestyles.get(identity_val, '-'),
        'marker': markers.get(identity_val, 'o'),
        'markersize': 8 if identity_val == '1' else 6,
        'group': f'identity_{identity_val}'
    }

def get_combined_variance_per_identity_style(identity_label: str, plot_type: str) -> Dict[str, Any]:
    """
    ä¸ºåˆå¹¶çš„ variance per identity å›¾è¡¨ç”Ÿæˆæ ·å¼é…ç½®
    ç›¸åŒé…ç½®çš„ä¸¤æ¡çº¿ä½¿ç”¨ç›¸åŒé¢œè‰²å’Œæ ‡è®°ï¼Œä½†ç”¨å®çº¿/è™šçº¿åŒºåˆ†èº«ä»½ç»„
    """
    # æå–èº«ä»½å€¼å’ŒåŸå§‹ç»„åˆæ ‡ç­¾
    identity_val = identity_label.split('(ID=')[-1].rstrip(')')
    base_label = identity_label.split(' (ID=')[0]
    
    # åŸºäºåŸå§‹ç»„åˆæ ‡ç­¾è®¡ç®—é¢œè‰²ç´¢å¼•ï¼ˆç¡®ä¿ç›¸åŒé…ç½®ä½¿ç”¨ç›¸åŒé¢œè‰²ï¼‰
    color_index = abs(hash(base_label)) % len(colors)
    
    # çº¿å‹ï¼š+1 ç”¨å®çº¿ï¼Œ-1 ç”¨è™šçº¿
    linestyle = '-' if identity_val == '+1' else '--'
    
    # æ ‡è®°ï¼šç›¸åŒé…ç½®ä½¿ç”¨ç›¸åŒæ ‡è®°
    marker_index = abs(hash(base_label)) % len(markers)
    marker = markers[marker_index]
    
    return {
        'color': colors[color_index],
        'linestyle': linestyle,
        'marker': marker,
        'markersize': 8 if identity_val == '+1' else 6,
        'group': f'combined_identity_{identity_val}'
    }
```

**å›¾è¡¨å¸ƒå±€ä¼˜åŒ–**ï¼š
- é’ˆå¯¹ä¸åŒçº¿æ¡æ•°é‡è°ƒæ•´å›¾è¡¨å¤§å°å’Œå›¾ä¾‹å¸ƒå±€
- morality_ratios å›¾è¡¨ï¼š24x14 è‹±å¯¸ï¼Œ4åˆ—å›¾ä¾‹
- zealot_numbers å›¾è¡¨ï¼š20x12 è‹±å¯¸ï¼Œ3åˆ—å›¾ä¾‹

#### 1.5 å®éªŒé…ç½®ç³»ç»Ÿ

**å‚æ•°ç»„åˆç”Ÿæˆ**ï¼š

```python
def create_config_combinations():
    """
    åˆ›å»ºå®éªŒå‚æ•°ç»„åˆé…ç½®
    
    1. zealot_numberså®éªŒï¼šæµ‹è¯•ä¸åŒzealotæ•°é‡å¯¹ç³»ç»Ÿçš„å½±å“
       - å˜é‡ï¼šzealotæ•°é‡ (xè½´)
       - å›ºå®šï¼šzealotèº«ä»½åˆ†é…=True, èº«ä»½åˆ†å¸ƒ=random
       - æ¯”è¾ƒï¼šzealotåˆ†å¸ƒæ¨¡å¼(random/clustered) Ã— moralityæ¯”ä¾‹(0.0/0.3) = 4ä¸ªç»„åˆ
    
    2. morality_ratioså®éªŒï¼šæµ‹è¯•ä¸åŒmoralityæ¯”ä¾‹å¯¹ç³»ç»Ÿçš„å½±å“
       - å˜é‡ï¼šmoralityæ¯”ä¾‹ (xè½´)
       - å›ºå®šï¼šzealotæ•°é‡=20
       - æ¯”è¾ƒï¼šzealotæ¨¡å¼(random/clustered/none) Ã— zealotèº«ä»½å¯¹é½(True/False) Ã— 
               èº«ä»½åˆ†å¸ƒ(random/clustered) = 10ä¸ªç»„åˆ
    """
    # è¯¦ç»†çš„é…ç½®ç”Ÿæˆé€»è¾‘...
```

**æœ€ç»ˆå›¾è¡¨æ•°é‡**ï¼š
- ä»åŸæ¥çš„ 8 å¼ å¢åŠ åˆ° 14 å¼ 
- 2 ç§å®éªŒç±»å‹ Ã— 7 ä¸ªæŒ‡æ ‡ = 14 å¼ å›¾è¡¨

### 2. polarization_triangle/utils/data_manager.py

#### 2.1 ExperimentDataManager ç±»æ¶æ„

**ç±»åŠŸèƒ½**ï¼šä¸“é—¨ç”¨äº zealot_morality_analysis å®éªŒçš„æ•°æ®å­˜å‚¨å’Œè¯»å–

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- ä½¿ç”¨ Parquet æ ¼å¼ï¼Œå¹³è¡¡å‹ç¼©ç‡å’Œè¯»å–é€Ÿåº¦
- æ”¯æŒæ‰¹æ¬¡ç®¡ç†å’Œæ•°æ®ç´¯ç§¯
- ä¸ºå¹¶è¡Œè®¡ç®—é¢„ç•™æ¥å£
- æ”¯æŒ variance per identity è®¡ç®—éœ€æ±‚

**ç›®å½•ç»“æ„**ï¼š
```
results/zealot_morality_analysis/
â”œâ”€â”€ experiment_data/
â”‚   â”œâ”€â”€ zealot_numbers_data.parquet
â”‚   â””â”€â”€ morality_ratios_data.parquet
â”œâ”€â”€ metadata/
â”‚   â”œâ”€â”€ batch_metadata.json
â”‚   â””â”€â”€ experiment_config.json
â””â”€â”€ mean_plots/
    â””â”€â”€ [ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶]
```

#### 2.2 æ•°æ®å­˜å‚¨æ ¼å¼

**Parquet æ ¼å¼çš„æ‰å¹³åŒ–å­˜å‚¨**ï¼š

```python
def save_batch_results(self, plot_type: str, batch_data: Dict[str, Any], batch_metadata: Dict[str, Any]):
    """
    ä¿å­˜æ‰¹æ¬¡å®éªŒç»“æœ
    
    æ•°æ®æ ¼å¼è½¬æ¢ï¼š
    åµŒå¥—æ ¼å¼ -> æ‰å¹³DataFrameæ ¼å¼
    {combination: {x_values: [], results: {metric: [[run1, run2, ...], ...]}}}
    ->
    DataFrame with columns: ['batch_id', 'timestamp', 'combination', 'x_value', 'metric', 'run_index', 'value']
    """
    rows = []
    for combination_label, combo_data in batch_data.items():
        x_values = combo_data['x_values']
        results = combo_data['results']
        
        for x_idx, x_value in enumerate(x_values):
            for metric_name, metric_results in results.items():
                if x_idx < len(metric_results):
                    for run_idx, run_value in enumerate(metric_results[x_idx]):
                        rows.append({
                            'batch_id': batch_id,
                            'timestamp': timestamp,
                            'combination': combination_label,
                            'x_value': x_value,
                            'metric': metric_name,
                            'run_index': run_idx,
                            'value': run_value
                        })
    
    # åˆ›å»ºDataFrameå¹¶ä¿å­˜ä¸ºParquetæ ¼å¼
    new_df = pd.DataFrame(rows)
    combined_df = pd.concat([existing_df, new_df], ignore_index=True) if target_file.exists() else new_df
    combined_df.to_parquet(target_file, compression='snappy', index=False)
```

#### 2.3 æ•°æ®è¯»å–å’Œè½¬æ¢

**ç»˜å›¾æ ¼å¼è½¬æ¢**ï¼š

```python
def convert_to_plotting_format(self, plot_type: str) -> Tuple[Dict[str, Dict[str, List[List[float]]]], List[float], Dict[str, int]]:
    """
    å°†å­˜å‚¨çš„æ•°æ®è½¬æ¢ä¸ºç»˜å›¾æ ¼å¼
    
    Returns:
        (all_results, x_values, total_runs_per_combination)
        
    all_results æ ¼å¼:
    {
        combination_label: {
            metric_name: [
                [run1_val, run2_val, ...],  # x_value_1 çš„æ‰€æœ‰è¿è¡Œç»“æœ
                [run1_val, run2_val, ...],  # x_value_2 çš„æ‰€æœ‰è¿è¡Œç»“æœ
                ...
            ]
        }
    }
    """
    df = self.load_experiment_data(plot_type)
    combinations = sorted(df['combination'].unique())
    x_values = sorted(df['x_value'].unique())
    metrics = sorted(df['metric'].unique())
    
    all_results = {}
    total_runs_per_combination = {}
    
    for combination in combinations:
        combo_data = df[df['combination'] == combination]
        
        # è®¡ç®—æ€»è¿è¡Œæ¬¡æ•°
        unique_x_values = len(combo_data['x_value'].unique())
        unique_metrics = len(combo_data['metric'].unique())
        total_runs = len(combo_data) // (unique_x_values * unique_metrics)
        total_runs_per_combination[combination] = total_runs
        
        # ç»„ç»‡æ•°æ®ä¸ºç»˜å›¾æ ¼å¼
        combo_results = {}
        for metric in metrics:
            metric_results = []
            metric_data = combo_data[combo_data['metric'] == metric]
            
            for x_val in x_values:
                x_data = metric_data[metric_data['x_value'] == x_val]
                run_values = x_data['value'].tolist()
                metric_results.append(run_values)
            
            combo_results[metric] = metric_results
        
        all_results[combination] = combo_results
    
    return all_results, x_values, total_runs_per_combination
```

#### 2.4 å…ƒæ•°æ®ç®¡ç†

**æ‰¹æ¬¡å…ƒæ•°æ®**ï¼š
```json
{
  "batches": [
    {
      "batch_id": "20241222_143052",
      "timestamp": "2024-12-22 14:30:52",
      "experiment_type": "zealot_numbers",
      "num_runs": 5,
      "max_zealots": 50,
      "x_range": [0, 50],
      "combinations_count": 4
    }
  ]
}
```

**å®éªŒé…ç½®**ï¼š
```json
{
  "batch_name": "20241222_143052",
  "num_runs": 5,
  "max_zealots": 50,
  "max_morality": 30,
  "elapsed_time": 1234.56,
  "total_combinations": 14,
  "saved_at": "2024-12-22T14:35:10.123456"
}
```

#### 2.5 æ‘˜è¦æŠ¥å‘ŠåŠŸèƒ½

**æ‘˜è¦æŠ¥å‘Šç”Ÿæˆ**ï¼š

```python
def export_summary_report(self) -> str:
    """
    å¯¼å‡ºå®éªŒæ‘˜è¦æŠ¥å‘Š
    """
    zealot_summary = self.get_experiment_summary('zealot_numbers')
    morality_summary = self.get_experiment_summary('morality_ratios')
    batch_metadata = self.get_batch_metadata()
    
    report = []
    report.append("=" * 60)
    report.append("å®éªŒæ•°æ®æ‘˜è¦æŠ¥å‘Š")
    report.append("=" * 60)
    
    report.append(f"\nğŸ“Š Zealot Numbers å®éªŒ:")
    report.append(f"   æ€»è®°å½•æ•°: {zealot_summary['total_records']}")
    report.append(f"   å‚æ•°ç»„åˆæ•°: {len(zealot_summary['combinations'])}")
    report.append(f"   æ‰¹æ¬¡æ•°: {len(zealot_summary['batches'])}")
    
    # ... æ›´å¤šç»Ÿè®¡ä¿¡æ¯ ...
    
    return "\n".join(report)
```

## åŠŸèƒ½å¢å¼ºæ€»ç»“

### 3.1 æ–°å¢æŒ‡æ ‡

**Variance per Identity**ï¼š
- **åŠŸèƒ½**ï¼šè®¡ç®—æ¯ä¸ªèº«ä»½ç»„å†…éƒ¨çš„æ„è§æ–¹å·®
- **å®ç°**ï¼šæ­£ç¡®è¯†åˆ« zealot å’Œé zealot èŠ‚ç‚¹ï¼Œåˆ†åˆ«è®¡ç®—ä¸¤ä¸ªèº«ä»½ç»„çš„æ–¹å·®
- **å¯è§†åŒ–**ï¼šæä¾›åˆ†ç¦»ç‰ˆæœ¬ï¼ˆ2å¼ å›¾ï¼‰å’Œåˆå¹¶ç‰ˆæœ¬ï¼ˆ2å¼ å›¾ï¼‰

### 3.2 å¹¶è¡Œè®¡ç®—åŠŸèƒ½

**æ€§èƒ½æå‡**ï¼š
- **æµ‹è¯•ç»“æœ**ï¼š36% æ€§èƒ½æå‡ï¼ˆ146.22ç§’ â†’ 107.26ç§’ï¼‰
- **åŠ é€Ÿæ¯”**ï¼š1.36xï¼Œå¹¶è¡Œæ•ˆç‡ 34.1%
- **å®¹é”™æœºåˆ¶**ï¼šå¤±è´¥ä»»åŠ¡è‡ªåŠ¨å¤„ç†ï¼Œæ”¯æŒå›é€€åˆ°ä¸²è¡Œæ¨¡å¼

**æŠ€æœ¯ç‰¹æ€§**ï¼š
- ä»»åŠ¡çº§å¹¶è¡Œï¼šæ¯ä¸ªæ¨¡æ‹Ÿè¿è¡Œä½œä¸ºç‹¬ç«‹ä»»åŠ¡
- éšæœºç§å­ç®¡ç†ï¼šç¡®ä¿ç»“æœå¯é‡ç°æ€§
- è¿›åº¦æ˜¾ç¤ºï¼šå®æ—¶æ˜¾ç¤ºå¹¶è¡Œä»»åŠ¡è¿›åº¦

### 3.3 æ•°æ®ç®¡ç†ä¼˜åŒ–

**å­˜å‚¨æ•ˆç‡**ï¼š
- **æ ¼å¼**ï¼šParquet æ ¼å¼ï¼Œè‡ªåŠ¨å‹ç¼©
- **ç»“æ„**ï¼šæ‰å¹³åŒ–å­˜å‚¨ï¼Œä¾¿äºæŸ¥è¯¢å’Œåˆ†æ
- **å…ƒæ•°æ®**ï¼šå®Œæ•´çš„æ‰¹æ¬¡å’Œå®éªŒé…ç½®è®°å½•

**åŠŸèƒ½ç‰¹æ€§**ï¼š
- æ‰¹æ¬¡ç´¯ç§¯ï¼šæ”¯æŒå¤šæ¬¡è¿è¡Œæ•°æ®ç´¯ç§¯
- æ ¼å¼è½¬æ¢ï¼šè‡ªåŠ¨è½¬æ¢ä¸ºç»˜å›¾æ‰€éœ€æ ¼å¼
- æ‘˜è¦æŠ¥å‘Šï¼šè¯¦ç»†çš„å®éªŒç»Ÿè®¡ä¿¡æ¯

### 3.4 å¯è§†åŒ–å¢å¼º

**å›¾è¡¨æ•°é‡**ï¼šä» 8 å¼ å¢åŠ åˆ° 14 å¼ 
- 2 ç§å®éªŒç±»å‹ï¼ˆzealot_numbers, morality_ratiosï¼‰
- 7 ä¸ªæŒ‡æ ‡ï¼ˆåŸæœ‰4ä¸ª + æ–°å¢3ä¸ªvariance per identityç›¸å…³ï¼‰

**æ ·å¼ç³»ç»Ÿ**ï¼š
- æ™ºèƒ½é¢œè‰²åˆ†é…ï¼šåŸºäºå“ˆå¸Œå€¼ç¡®ä¿ä¸€è‡´æ€§
- çº¿å‹åŒºåˆ†ï¼šå®çº¿/è™šçº¿åŒºåˆ†ä¸åŒèº«ä»½ç»„
- å›¾ä¾‹ä¼˜åŒ–ï¼šæ ¹æ®çº¿æ¡æ•°é‡è‡ªåŠ¨è°ƒæ•´å¸ƒå±€

## ä½¿ç”¨æ–¹æ³•

### 4.1 åŸºæœ¬ä½¿ç”¨

```python
# å®Œæ•´å®éªŒï¼ˆæ•°æ®æ”¶é›† + ç»˜å›¾ï¼‰
run_zealot_morality_analysis(
    output_dir="results/zealot_morality_analysis",
    num_runs=5,
    max_zealots=50,
    max_morality=30,
    num_processes=12  # ä½¿ç”¨12ä¸ªè¿›ç¨‹å¹¶è¡Œè®¡ç®—
)

# åˆ†æ­¥éª¤ä½¿ç”¨
# æ­¥éª¤1ï¼šæ•°æ®æ”¶é›†
run_and_accumulate_data(
    output_dir="results/zealot_morality_analysis",
    num_runs=5,
    max_zealots=50,
    max_morality=30,
    batch_name="batch_001",
    num_processes=12
)

# æ­¥éª¤2ï¼šç”Ÿæˆå›¾è¡¨
plot_from_accumulated_data("results/zealot_morality_analysis")
```

### 4.2 æ•°æ®ç®¡ç†å™¨ç›´æ¥ä½¿ç”¨

```python
from polarization_triangle.utils.data_manager import ExperimentDataManager

# åˆ›å»ºæ•°æ®ç®¡ç†å™¨
data_manager = ExperimentDataManager("results/zealot_morality_analysis")

# æŸ¥çœ‹æ‘˜è¦æŠ¥å‘Š
print(data_manager.export_summary_report())

# è·å–å®éªŒæ•°æ®
zealot_summary = data_manager.get_experiment_summary('zealot_numbers')
morality_summary = data_manager.get_experiment_summary('morality_ratios')

# åŠ è½½åŸå§‹æ•°æ®è¿›è¡Œè‡ªå®šä¹‰åˆ†æ
df = data_manager.load_experiment_data('zealot_numbers')
```

## æŠ€æœ¯äº®ç‚¹

### 5.1 ä»£ç è´¨é‡

- **æ–‡æ¡£å®Œæ•´**ï¼šæ¯ä¸ªå‡½æ•°éƒ½æœ‰è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
- **ç±»å‹æ³¨è§£**ï¼šä½¿ç”¨ typing æ¨¡å—æä¾›ç±»å‹æç¤º
- **é”™è¯¯å¤„ç†**ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œå›é€€æœºåˆ¶
- **ä»£ç ç»“æ„**ï¼šæ¸…æ™°çš„æ¨¡å—åŒ–è®¾è®¡

### 5.2 æ€§èƒ½ä¼˜åŒ–

- **å¹¶è¡Œè®¡ç®—**ï¼šå¤šè¿›ç¨‹å¹¶è¡Œï¼Œæ˜¾è‘—æå‡æ€§èƒ½
- **å­˜å‚¨æ•ˆç‡**ï¼šParquet æ ¼å¼ï¼Œå‹ç¼©ç‡é«˜ï¼Œè¯»å–å¿«
- **å†…å­˜ç®¡ç†**ï¼šé¿å…å¤§é‡æ•°æ®åœ¨å†…å­˜ä¸­ç´¯ç§¯

### 5.3 ç”¨æˆ·ä½“éªŒ

- **è¿›åº¦æ˜¾ç¤º**ï¼šè¯¦ç»†çš„è¿›åº¦æ¡å’ŒçŠ¶æ€ä¿¡æ¯
- **å‘åå…¼å®¹**ï¼šä¿æŒåŸæœ‰æ¥å£ä¸å˜
- **çµæ´»é…ç½®**ï¼šæ”¯æŒå¤šç§å‚æ•°é…ç½®ç»„åˆ

## æœªæ¥æ‰©å±•æ–¹å‘

### 6.1 åŠŸèƒ½æ‰©å±•

- **æ›´å¤šæŒ‡æ ‡**ï¼šå¯ä»¥è½»æ¾æ·»åŠ æ–°çš„ç»Ÿè®¡æŒ‡æ ‡
- **å¯è§†åŒ–é€‰é¡¹**ï¼šæ”¯æŒæ›´å¤šå›¾è¡¨ç±»å‹å’Œæ ·å¼
- **æ•°æ®åˆ†æ**ï¼šé›†æˆæ›´å¤šç»Ÿè®¡åˆ†æåŠŸèƒ½

### 6.2 æ€§èƒ½ä¼˜åŒ–

- **åˆ†å¸ƒå¼è®¡ç®—**ï¼šæ”¯æŒè·¨æœºå™¨çš„åˆ†å¸ƒå¼è®¡ç®—
- **GPUåŠ é€Ÿ**ï¼šåˆ©ç”¨GPUåŠ é€Ÿè®¡ç®—å¯†é›†å‹ä»»åŠ¡
- **å†…å­˜ä¼˜åŒ–**ï¼šè¿›ä¸€æ­¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨

### 6.3 æ•°æ®ç®¡ç†

- **æ•°æ®æ¸…ç†**ï¼šè‡ªåŠ¨æ¸…ç†æ—§æ•°æ®åŠŸèƒ½
- **æ•°æ®å¯¼å‡º**ï¼šæ”¯æŒæ›´å¤šæ•°æ®æ ¼å¼å¯¼å‡º
- **æ•°æ®ç‰ˆæœ¬æ§åˆ¶**ï¼šå®éªŒæ•°æ®çš„ç‰ˆæœ¬ç®¡ç†

## æ€»ç»“

æœ¬æ¬¡å¼€å‘ä¼šè¯æˆåŠŸå®ç°äº†ä»¥ä¸‹ç›®æ ‡ï¼š

1. **æ–°å¢ variance per identity æŒ‡æ ‡**ï¼šä¸ºç³»ç»Ÿåˆ†ææä¾›äº†æ–°çš„ç»´åº¦
2. **å®ç°å¹¶è¡Œè®¡ç®—åŠŸèƒ½**ï¼šæ˜¾è‘—æå‡äº†å®éªŒæ‰§è¡Œæ•ˆç‡
3. **ä¼˜åŒ–æ•°æ®ç®¡ç†ç³»ç»Ÿ**ï¼šæä¾›äº†é«˜æ•ˆã€å¯æ‰©å±•çš„æ•°æ®å­˜å‚¨æ–¹æ¡ˆ
4. **å¢å¼ºå¯è§†åŒ–ç³»ç»Ÿ**ï¼šæ”¯æŒæ›´ä¸°å¯Œçš„å›¾è¡¨ç±»å‹å’Œæ ·å¼é…ç½®

æ•´ä¸ªç³»ç»Ÿç°åœ¨å…·å¤‡äº†ï¼š
- **å®Œæ•´æ€§**ï¼šä»æ•°æ®æ”¶é›†åˆ°å¯è§†åŒ–çš„å®Œæ•´æµç¨‹
- **é«˜æ•ˆæ€§**ï¼šå¹¶è¡Œè®¡ç®—å’Œä¼˜åŒ–å­˜å‚¨çš„é«˜æ€§èƒ½
- **å¯æ‰©å±•æ€§**ï¼šæ¨¡å—åŒ–è®¾è®¡ä¾¿äºåç»­æ‰©å±•
- **æ˜“ç”¨æ€§**ï¼šç”¨æˆ·å‹å¥½çš„APIæ¥å£

ä»£ç æ€»è¡Œæ•°çº¦ 1853 è¡Œï¼ˆzealot_morality_analysis.py: 1383è¡Œ, data_manager.py: 470è¡Œï¼‰ï¼Œç»“æ„æ¸…æ™°ï¼ŒåŠŸèƒ½å®Œæ•´ï¼Œä¸ºæåŒ–ä¸‰è§’æ¡†æ¶çš„å®éªŒåˆ†ææä¾›äº†å¼ºå¤§çš„å·¥å…·æ”¯æŒã€‚