# Zealot Morality Analysis å¼€å‘æ—¥å¿— - 2024å¹´12æœˆ22æ—¥

## æ¦‚è¿°

æœ¬æ¬¡å¼€å‘ä¼šè¯ä¸»è¦å¯¹ `polarization_triangle/experiments/zealot_morality_analysis.py` å’Œ `polarization_triangle/utils/data_manager.py` è¿›è¡Œäº†é‡å¤§åŠŸèƒ½å¢å¼ºï¼ŒåŒ…æ‹¬ï¼š

1. **æ–°å¢ variance per identity æŒ‡æ ‡**ï¼šè®¡ç®—æ¯ä¸ªèº«ä»½ç»„å†…éƒ¨çš„æ„è§æ–¹å·®
2. **å®ç°å¹¶è¡Œè®¡ç®—åŠŸèƒ½**ï¼šæ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œæ‰§è¡Œï¼Œæ˜¾è‘—æå‡æ€§èƒ½
3. **ä¼˜åŒ–æ•°æ®ç®¡ç†ç³»ç»Ÿ**ï¼šä½¿ç”¨ Parquet æ ¼å¼çš„é«˜æ•ˆå­˜å‚¨æ–¹æ¡ˆ
4. **å¢å¼ºå¯è§†åŒ–ç³»ç»Ÿ**ï¼šæ”¯æŒæ›´å¤šå›¾è¡¨ç±»å‹å’Œæ ·å¼é…ç½®
5. **æ–°å¢æ•°æ®å¹³æ»‘å’Œé‡é‡‡æ ·åŠŸèƒ½**ï¼šè§£å†³é«˜å¯†åº¦é‡‡æ ·å¸¦æ¥çš„å™ªå£°é—®é¢˜ï¼Œæä¾›æ›´æ¸…æ™°çš„è¶‹åŠ¿å¯è§†åŒ–

## æ–‡ä»¶ä¿®æ”¹è¯¦æƒ…

### 1. polarization_triangle/experiments/zealot_morality_analysis.py

#### 1.1 æ–‡ä»¶ç»“æ„å’Œæ•´ä½“æ¶æ„

**æ–‡ä»¶é•¿åº¦**ï¼šçº¦1500è¡Œï¼ˆå¢åŠ å¹³æ»‘åŠŸèƒ½åï¼‰ï¼Œæ˜¯ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„å®éªŒåˆ†ææ¨¡å—

**ä¸»è¦ç»„æˆéƒ¨åˆ†**ï¼š
- **å·¥å…·å‡½æ•°**ï¼šæ—¶é—´æ ¼å¼åŒ–ç­‰è¾…åŠ©åŠŸèƒ½
- **æ•°æ®å¹³æ»‘å’Œé‡é‡‡æ ·å‡½æ•°**ï¼šè§£å†³å™ªå£°é—®é¢˜çš„æ ¸å¿ƒåŠŸèƒ½
- **å¹¶è¡Œè®¡ç®—æ”¯æŒå‡½æ•°**ï¼šå¤šè¿›ç¨‹ä»»åŠ¡å¤„ç†
- **æ ¸å¿ƒå®éªŒé€»è¾‘å‡½æ•°**ï¼šå‚æ•°ç»„åˆç”Ÿæˆã€å•æ¬¡æ¨¡æ‹Ÿæ‰§è¡Œã€å‚æ•°æ‰«æ
- **æ•°æ®ç®¡ç†å‡½æ•°**ï¼šä¸æ–°çš„æ•°æ®ç®¡ç†å™¨é›†æˆ
- **ç»˜å›¾ç›¸å…³å‡½æ•°**ï¼šæ ·å¼é…ç½®ã€å›¾è¡¨ç”Ÿæˆï¼ˆæ”¯æŒå¹³æ»‘å¤„ç†ï¼‰
- **é«˜çº§æ¥å£å‡½æ•°**ï¼šç”¨æˆ·å‹å¥½çš„APIæ¥å£

#### 1.1.1 æ–°å¢æ•°æ®å¹³æ»‘å’Œé‡é‡‡æ ·åŠŸèƒ½

**èƒŒæ™¯é—®é¢˜**ï¼š
- ä»æ­¥é•¿2æ”¹ä¸ºæ­¥é•¿1åï¼Œæ•°æ®ç‚¹å¯†åº¦å¢åŠ ï¼ˆä»51ä¸ªç‚¹å¢åŠ åˆ°101ä¸ªç‚¹ï¼‰
- é«˜å¯†åº¦é‡‡æ ·å¯¼è‡´ç›¸é‚»æ•°æ®ç‚¹çš„çœŸå®å·®å¼‚å°äºéšæœºå™ªå£°
- äº§ç”Ÿé”¯é½¿çŠ¶æŒ¯è¡ï¼Œå½±å“è¶‹åŠ¿åˆ¤æ–­

**è§£å†³æ–¹æ¡ˆ**ï¼šä¸‰çº§å¹³æ»‘å¤„ç†ç³»ç»Ÿ

##### **æ ¸å¿ƒå‡½æ•°å®ç°**ï¼š

```python
def resample_and_smooth_data(x_values, y_values, target_step=2, smooth_window=3):
    """
    å¯¹æ•°æ®è¿›è¡Œé‡é‡‡æ ·å’Œå¹³æ»‘å¤„ç†
    
    Args:
        x_values: åŸå§‹xå€¼æ•°ç»„ï¼Œå¦‚[0,1,2,3,4,5,6,7,8,9,10,...]
        y_values: åŸå§‹yå€¼æ•°ç»„
        target_step: ç›®æ ‡æ­¥é•¿ï¼Œå¦‚2è¡¨ç¤ºä»[0,1,2,3,4,5,...]å˜ä¸º[0,2,4,6,8,10,...]
        smooth_window: å¹³æ»‘çª—å£å¤§å°
    
    Returns:
        new_x_values, new_y_values: é‡é‡‡æ ·å’Œå¹³æ»‘åçš„æ•°æ®
    """
    import numpy as np
    from scipy import interpolate
    
    # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
    x_values = np.array(x_values)
    y_values = np.array(y_values)
    
    # ç§»é™¤NaNå€¼
    valid_mask = ~np.isnan(y_values)
    x_clean = x_values[valid_mask]
    y_clean = y_values[valid_mask]
    
    if len(x_clean) < 3:
        return x_values, y_values
    
    # ç¬¬ä¸€æ­¥ï¼šå±€éƒ¨å¹³æ»‘ï¼ˆå°çª—å£ç§»åŠ¨å¹³å‡ï¼‰
    if smooth_window > 1 and len(y_clean) >= smooth_window:
        kernel = np.ones(smooth_window) / smooth_window
        # ä½¿ç”¨'same'æ¨¡å¼ä¿æŒæ•°ç»„é•¿åº¦
        y_smooth = np.convolve(y_clean, kernel, mode='same')
    else:
        y_smooth = y_clean.copy()
    
    # ç¬¬äºŒæ­¥ï¼šé‡é‡‡æ ·åˆ°ç›®æ ‡æ­¥é•¿
    x_min, x_max = x_clean.min(), x_clean.max()
    new_x_values = np.arange(x_min, x_max + target_step, target_step)
    
    # ä½¿ç”¨æ’å€¼è·å–æ–°xç‚¹çš„yå€¼
    try:
        # çº¿æ€§æ’å€¼
        f = interpolate.interp1d(x_clean, y_smooth, kind='linear', 
                                bounds_error=False, fill_value='extrapolate')
        new_y_values = f(new_x_values)
    except Exception:
        # æ’å€¼å¤±è´¥æ—¶å›é€€åˆ°åŸå§‹æ•°æ®
        return x_values, y_values
    
    return new_x_values, new_y_values

def apply_final_smooth(y_values, method='savgol', window=5):
    """
    åº”ç”¨æœ€ç»ˆå¹³æ»‘å¤„ç†
    
    Args:
        y_values: è¾“å…¥æ•°æ®
        method: å¹³æ»‘æ–¹æ³•
            - 'savgol': Savitzky-Golayæ»¤æ³¢ï¼ˆé»˜è®¤ï¼‰
            - 'moving_avg': ç§»åŠ¨å¹³å‡
            - 'none': ä¸åº”ç”¨å¹³æ»‘
        window: çª—å£å¤§å°
    
    Returns:
        å¹³æ»‘åçš„æ•°æ®
    """
    if method == 'none' or len(y_values) < window:
        return y_values
    
    try:
        if method == 'savgol':
            from scipy.signal import savgol_filter
            # ç¡®ä¿çª—å£å¤§å°æ˜¯å¥‡æ•°ä¸”ä¸è¶…è¿‡æ•°æ®é•¿åº¦
            window = min(window, len(y_values))
            if window % 2 == 0:
                window -= 1
            if window < 3:
                return y_values
            
            # å¤šé¡¹å¼é˜¶æ•°è®¾ä¸ºmin(3, window-1)
            polyorder = min(3, window - 1)
            return savgol_filter(y_values, window, polyorder)
            
        elif method == 'moving_avg':
            # ç§»åŠ¨å¹³å‡
            kernel = np.ones(window) / window
            return np.convolve(y_values, kernel, mode='same')
            
    except Exception as e:
        print(f"âš ï¸  å¹³æ»‘å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {e}")
        return y_values
    
    return y_values
```

##### **ç»˜å›¾å‡½æ•°é›†æˆ**ï¼š

**å‡½æ•°ç­¾åæ›´æ–°**ï¼š
```python
def plot_results_with_manager(data_manager: ExperimentDataManager, 
                            plot_type: str,
                            enable_smoothing: bool = True,
                            target_step: int = 2,
                            smooth_method: str = 'savgol') -> None:
    """
    ä½¿ç”¨æ•°æ®ç®¡ç†å™¨ç»˜åˆ¶å®éªŒç»“æœå›¾è¡¨
    
    Args:
        data_manager: æ•°æ®ç®¡ç†å™¨å®ä¾‹  
        plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
        enable_smoothing: æ˜¯å¦å¯ç”¨å¹³æ»‘å’Œé‡é‡‡æ ·
        target_step: é‡é‡‡æ ·çš„ç›®æ ‡æ­¥é•¿ï¼ˆæ¯”å¦‚ä»æ­¥é•¿1å˜ä¸ºæ­¥é•¿2ï¼‰
        smooth_method: å¹³æ»‘æ–¹æ³• ('savgol', 'moving_avg', 'none')
    """
```

**å¹³æ»‘å¤„ç†é€»è¾‘**ï¼š
```python
# åœ¨ç»˜å›¾å¾ªç¯ä¸­æ·»åŠ å¹³æ»‘å¤„ç†
if enable_smoothing:
    # åº”ç”¨ä¸‰çº§å¹³æ»‘å¤„ç†
    smoothed_x, smoothed_means = resample_and_smooth_data(
        x_values, data['means'], target_step=target_step, smooth_window=3
    )
    final_smoothed_means = apply_final_smooth(
        smoothed_means, method=smooth_method, window=5
    )
    
    # ä½¿ç”¨å¹³æ»‘åçš„æ•°æ®ç»˜å›¾
    x_plot, y_plot = smoothed_x, final_smoothed_means
    label_suffix = " (smoothed)"
else:
    # ä½¿ç”¨åŸå§‹æ•°æ®
    x_plot, y_plot = x_values, data['means']
    label_suffix = ""

# ç»˜åˆ¶æ›²çº¿
plt.plot(x_plot, y_plot, 
         label=f"{label_with_runs}{label_suffix}",
         color=line_color,
         linestyle=style.get('linestyle', '-'),
         marker=style.get('marker', 'o'),
         markersize=style.get('markersize', 8),
         markerfacecolor=style.get('markerfacecolor', line_color),
         markeredgecolor=style.get('markeredgecolor', line_color),
         linewidth=2.5, alpha=0.9)
```

##### **æ–‡ä»¶å‘½åå’Œæ ‡è¯†**ï¼š

**æ–‡ä»¶å‘½åè§„åˆ™**ï¼š
```python
# ä¸ºæ–‡ä»¶åæ·»åŠ å¹³æ»‘æ ‡è¯†
if enable_smoothing:
    if plot_type == 'zealot_numbers':
        filename = f"{plot_type}_{metric}_smoothed_step{target_step}_{smooth_method}{runs_suffix}.png"
    else:
        filename = f"{plot_type}_{metric}_smoothed_step{target_step}_{smooth_method}{runs_suffix}.png"
else:
    # åŸå§‹æ–‡ä»¶å‘½åä¿æŒä¸å˜
    if plot_type == 'zealot_numbers':
        filename = f"{plot_type}_{metric}_mean_with_error_bands{runs_suffix}.png"
    else:
        filename = f"{plot_type}_{metric}_mean{runs_suffix}.png"
```

##### **æ•ˆæœå’Œä¼˜åŠ¿**ï¼š

**æ•°æ®è½¬æ¢ç¤ºä¾‹**ï¼š
```python
# åŸå§‹é«˜å¯†åº¦æ•°æ®ï¼ˆæ­¥é•¿=1ï¼‰
x_original = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...]  # 101ä¸ªç‚¹
y_original = [0.000, 0.023, 0.041, 0.055, 0.083, 0.095, 0.118, ...]  # å«å™ªå£°

# ç»è¿‡å¹³æ»‘å¤„ç†å
x_smoothed = [0, 2, 4, 6, 8, 10, ...]  # 51ä¸ªç‚¹
y_smoothed = [0.000, 0.032, 0.069, 0.101, 0.134, ...]  # å¹³æ»‘è¶‹åŠ¿
```

**ä¿¡å™ªæ¯”æ”¹å–„**ï¼š
- **æ­¥é•¿1æ—¶**ï¼šä¿¡å™ªæ¯” â‰ˆ 0.02/0.01 = 2:1ï¼ˆå™ªå£°æ˜æ˜¾ï¼‰
- **é‡é‡‡æ ·åˆ°æ­¥é•¿2**ï¼šä¿¡å™ªæ¯” â‰ˆ 0.04/0.01 = 4:1ï¼ˆä¿¡å·ä¸»å¯¼ï¼‰
- **ä¸‰çº§å¹³æ»‘å**ï¼šè¿›ä¸€æ­¥æŠ‘åˆ¶å™ªå£°ï¼Œè¶‹åŠ¿æ›´æ¸…æ™°

#### 1.2 æ–°å¢çš„ variance per identity æŒ‡æ ‡

**åŠŸèƒ½æè¿°**ï¼š
- è®¡ç®—æ¯ä¸ªèº«ä»½ç»„ï¼ˆidentity=1 å’Œ identity=-1ï¼‰å†…éƒ¨çš„æ„è§æ–¹å·®
- æä¾›åˆ†ç¦»ç‰ˆæœ¬å’Œåˆå¹¶ç‰ˆæœ¬çš„å¯è§†åŒ–

**æ ¸å¿ƒå®ç°**ï¼š

```python
def run_single_simulation(config: SimulationConfig, steps: int = 500) -> Dict[str, float]:
    # ... ç°æœ‰ä»£ç  ...
    
    # è®¡ç®— variance per identity (æ¯ä¸ªèº«ä»½ç»„å†…çš„æ–¹å·®)
    variance_per_identity = {'identity_1': 0.0, 'identity_-1': 0.0}
    
    # è·å–ézealotèŠ‚ç‚¹çš„æ„è§å’Œèº«ä»½
    zealot_mask = np.zeros(sim.num_agents, dtype=bool)
    if sim.enable_zealots and sim.zealot_ids:
        zealot_mask[sim.zealot_ids] = True
    
    non_zealot_mask = ~zealot_mask
    non_zealot_opinions = sim.opinions[non_zealot_mask]
    non_zealot_identities = sim.identities[non_zealot_mask]
    
    # åˆ†åˆ«è®¡ç®—æ¯ä¸ªèº«ä»½ç»„çš„æ–¹å·®
    for identity_val in [1, -1]:
        identity_mask = non_zealot_identities == identity_val
        if np.sum(identity_mask) > 1:  # è‡³å°‘éœ€è¦2ä¸ªèŠ‚ç‚¹æ‰èƒ½è®¡ç®—æ–¹å·®
            identity_opinions = non_zealot_opinions[identity_mask]
            variance_per_identity[f'identity_{identity_val}'] = float(np.var(identity_opinions))
        else:
            variance_per_identity[f'identity_{identity_val}'] = 0.0
    
    return {
        'mean_opinion': mean_stats['mean_opinion'],
        'variance': variance_stats['overall_variance'],
        'identity_opinion_difference': identity_opinion_difference,
        'polarization_index': polarization,
        'variance_per_identity': variance_per_identity  # æ–°å¢æŒ‡æ ‡
    }
```

**å…³é”®ä¿®å¤**ï¼š
- ä¿®æ­£äº† zealot è¯†åˆ«é€»è¾‘ï¼šä»é”™è¯¯çš„ `sim.is_zealot` æ”¹ä¸ºæ­£ç¡®çš„ `sim.zealot_ids`
- æ­£ç¡®åŒºåˆ† zealot å’Œé zealot èŠ‚ç‚¹ï¼Œç¡®ä¿æ–¹å·®è®¡ç®—çš„å‡†ç¡®æ€§

#### 1.3 å¹¶è¡Œè®¡ç®—åŠŸèƒ½å®ç°

**è®¾è®¡ç†å¿µ**ï¼š
- é‡‡ç”¨ä»»åŠ¡çº§å¹¶è¡Œï¼šæ¯ä¸ªæ¨¡æ‹Ÿè¿è¡Œä½œä¸ºç‹¬ç«‹ä»»åŠ¡
- ä¿æŒå‘åå…¼å®¹ï¼š`num_processes=1` æ—¶ä½¿ç”¨åŸæœ‰ä¸²è¡Œé€»è¾‘
- å®¹é”™æœºåˆ¶ï¼šå¤±è´¥ä»»åŠ¡ç”¨ NaN å¡«å……ï¼Œæ”¯æŒè‡ªåŠ¨å›é€€

**æ ¸å¿ƒå‡½æ•°**ï¼š

```python
def run_single_simulation_task(task_params):
    """
    å•ä¸ªæ¨¡æ‹Ÿä»»åŠ¡çš„åŒ…è£…å‡½æ•°ï¼Œç”¨äºå¤šè¿›ç¨‹å¹¶è¡Œè®¡ç®—
    """
    try:
        plot_type, combination, x_val, run_idx, steps, process_id = task_params
        
        # è®¾ç½®è¿›ç¨‹ç‰¹å®šçš„éšæœºç§å­
        np.random.seed((int(x_val * 1000) + run_idx + process_id) % (2**32))
        
        # æ„å»ºé…ç½®å¹¶è¿è¡Œæ¨¡æ‹Ÿ
        # ... é…ç½®é€»è¾‘ ...
        
        results = run_single_simulation(base_config, steps)
        return (x_val, run_idx, results, True, None)
        
    except Exception as e:
        error_msg = f"Process {process_id}: Simulation failed for x={x_val}, run={run_idx}: {str(e)}"
        return (x_val, run_idx, None, False, error_msg)

def run_parameter_sweep_parallel(plot_type: str, combination: Dict[str, Any], 
                                x_values: List[float], num_runs: int = 5, num_processes: int = 4):
    """
    å¹¶è¡Œç‰ˆæœ¬çš„å‚æ•°æ‰«æ
    """
    print(f"ğŸš€ ä½¿ç”¨ {num_processes} ä¸ªè¿›ç¨‹è¿›è¡Œå¹¶è¡Œè®¡ç®—...")
    
    # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
    tasks = []
    for x_val in x_values:
        for run_idx in range(num_runs):
            process_id = len(tasks) % num_processes
            task = (plot_type, combination, x_val, run_idx, combination['steps'], process_id)
            tasks.append(task)
    
    # æ‰§è¡Œå¹¶è¡Œè®¡ç®—
    try:
        with multiprocessing.Pool(num_processes) as pool:
            results_list = []
            with tqdm(total=len(tasks), desc=f"Running {combination['label']} (parallel)") as pbar:
                for result in pool.imap(run_single_simulation_task, tasks):
                    results_list.append(result)
                    pbar.update(1)
    except Exception as e:
        print(f"âŒ å¹¶è¡Œè®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°ä¸²è¡Œæ¨¡å¼: {e}")
        return run_parameter_sweep_serial(plot_type, combination, x_values, num_runs)
    
    return organize_parallel_results(results_list, x_values, num_runs)
```

**æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§**ï¼š
- éšæœºç§å­ç®¡ç†ï¼šç¡®ä¿æ¯ä¸ªè¿›ç¨‹æœ‰ä¸åŒä½†å¯é‡ç°çš„éšæœºåºåˆ—
- è¿›åº¦æ˜¾ç¤ºï¼šå¹¶è¡Œä»»åŠ¡ä¹Ÿæœ‰è¯¦ç»†çš„è¿›åº¦æ¡
- é”™è¯¯å¤„ç†ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œå›é€€æœºåˆ¶

#### 1.4 å¢å¼ºçš„å¯è§†åŒ–ç³»ç»Ÿ

**æ–°å¢å›¾è¡¨ç±»å‹**ï¼š
- `variance_per_identity_1`ï¼šidentity=+1 ç»„çš„æ–¹å·®å›¾è¡¨
- `variance_per_identity_-1`ï¼šidentity=-1 ç»„çš„æ–¹å·®å›¾è¡¨  
- `variance_per_identity_combined`ï¼šä¸¤ä¸ªèº«ä»½ç»„çš„åˆå¹¶å›¾è¡¨

**æ ·å¼é…ç½®ç³»ç»Ÿ**ï¼š

```python
def get_variance_per_identity_style(identity_label: str, plot_type: str) -> Dict[str, Any]:
    """
    ä¸º variance per identity å›¾è¡¨ç”Ÿæˆç‰¹æ®Šçš„æ ·å¼é…ç½®
    """
    # çº¿å‹ç»„åˆï¼šå®çº¿ç”¨äº ID=1ï¼Œè™šçº¿ç”¨äº ID=-1
    linestyles = {
        '1': '-',      # å®çº¿ç”¨äº identity=1
        '-1': '--'     # è™šçº¿ç”¨äº identity=-1
    }
    
    # æ ‡è®°å½¢çŠ¶ï¼šåœ†å½¢ç”¨äº ID=1ï¼Œæ–¹å½¢ç”¨äº ID=-1
    markers = {
        '1': 'o',      # åœ†å½¢ç”¨äº identity=1
        '-1': 's'      # æ–¹å½¢ç”¨äº identity=-1
    }
    
    # æå–èº«ä»½å€¼å’ŒåŸå§‹ç»„åˆæ ‡ç­¾
    identity_val = identity_label.split('(ID=')[-1].rstrip(')')
    base_label = identity_label.split(' (ID=')[0]
    
    # åŸºäºå“ˆå¸Œå€¼åˆ†é…é¢œè‰²ï¼Œç¡®ä¿ä¸€è‡´æ€§
    color_index = abs(hash(base_label)) % len(colors)
    if identity_val == '-1':
        color_index = (color_index + len(colors) // 2) % len(colors)
    
    return {
        'color': colors[color_index],
        'linestyle': linestyles.get(identity_val, '-'),
        'marker': markers.get(identity_val, 'o'),
        'markersize': 8 if identity_val == '1' else 6,
        'group': f'identity_{identity_val}'
    }

def get_combined_variance_per_identity_style(identity_label: str, plot_type: str) -> Dict[str, Any]:
    """
    ä¸ºåˆå¹¶çš„ variance per identity å›¾è¡¨ç”Ÿæˆæ ·å¼é…ç½®
    ç›¸åŒé…ç½®çš„ä¸¤æ¡çº¿ä½¿ç”¨ç›¸åŒé¢œè‰²å’Œæ ‡è®°ï¼Œä½†ç”¨å®çº¿/è™šçº¿åŒºåˆ†èº«ä»½ç»„
    """
    # æå–èº«ä»½å€¼å’ŒåŸå§‹ç»„åˆæ ‡ç­¾
    identity_val = identity_label.split('(ID=')[-1].rstrip(')')
    base_label = identity_label.split(' (ID=')[0]
    
    # åŸºäºåŸå§‹ç»„åˆæ ‡ç­¾è®¡ç®—é¢œè‰²ç´¢å¼•ï¼ˆç¡®ä¿ç›¸åŒé…ç½®ä½¿ç”¨ç›¸åŒé¢œè‰²ï¼‰
    color_index = abs(hash(base_label)) % len(colors)
    
    # çº¿å‹ï¼š+1 ç”¨å®çº¿ï¼Œ-1 ç”¨è™šçº¿
    linestyle = '-' if identity_val == '+1' else '--'
    
    # æ ‡è®°ï¼šç›¸åŒé…ç½®ä½¿ç”¨ç›¸åŒæ ‡è®°
    marker_index = abs(hash(base_label)) % len(markers)
    marker = markers[marker_index]
    
    return {
        'color': colors[color_index],
        'linestyle': linestyle,
        'marker': marker,
        'markersize': 8 if identity_val == '+1' else 6,
        'group': f'combined_identity_{identity_val}'
    }
```

**å›¾è¡¨å¸ƒå±€ä¼˜åŒ–**ï¼š
- é’ˆå¯¹ä¸åŒçº¿æ¡æ•°é‡è°ƒæ•´å›¾è¡¨å¤§å°å’Œå›¾ä¾‹å¸ƒå±€
- morality_ratios å›¾è¡¨ï¼š24x14 è‹±å¯¸ï¼Œ4åˆ—å›¾ä¾‹
- zealot_numbers å›¾è¡¨ï¼š20x12 è‹±å¯¸ï¼Œ3åˆ—å›¾ä¾‹

#### 1.5 å®éªŒé…ç½®ç³»ç»Ÿ

**å‚æ•°ç»„åˆç”Ÿæˆ**ï¼š

```python
def create_config_combinations():
    """
    åˆ›å»ºå®éªŒå‚æ•°ç»„åˆé…ç½®
    
    1. zealot_numberså®éªŒï¼šæµ‹è¯•ä¸åŒzealotæ•°é‡å¯¹ç³»ç»Ÿçš„å½±å“
       - å˜é‡ï¼šzealotæ•°é‡ (xè½´)
       - å›ºå®šï¼šzealotèº«ä»½åˆ†é…=True, èº«ä»½åˆ†å¸ƒ=random
       - æ¯”è¾ƒï¼šzealotåˆ†å¸ƒæ¨¡å¼(random/clustered) Ã— moralityæ¯”ä¾‹(0.0/0.3) = 4ä¸ªç»„åˆ
    
    2. morality_ratioså®éªŒï¼šæµ‹è¯•ä¸åŒmoralityæ¯”ä¾‹å¯¹ç³»ç»Ÿçš„å½±å“
       - å˜é‡ï¼šmoralityæ¯”ä¾‹ (xè½´)
       - å›ºå®šï¼šzealotæ•°é‡=20
       - æ¯”è¾ƒï¼šzealotæ¨¡å¼(random/clustered/none) Ã— zealotèº«ä»½å¯¹é½(True/False) Ã— 
               èº«ä»½åˆ†å¸ƒ(random/clustered) = 10ä¸ªç»„åˆ
    """
    # è¯¦ç»†çš„é…ç½®ç”Ÿæˆé€»è¾‘...
```

**æœ€ç»ˆå›¾è¡¨æ•°é‡**ï¼š
- ä»åŸæ¥çš„ 8 å¼ å¢åŠ åˆ° 14 å¼ 
- 2 ç§å®éªŒç±»å‹ Ã— 7 ä¸ªæŒ‡æ ‡ = 14 å¼ å›¾è¡¨

### 2. polarization_triangle/utils/data_manager.py

#### 2.1 ExperimentDataManager ç±»æ¶æ„

**ç±»åŠŸèƒ½**ï¼šä¸“é—¨ç”¨äº zealot_morality_analysis å®éªŒçš„æ•°æ®å­˜å‚¨å’Œè¯»å–

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- ä½¿ç”¨ Parquet æ ¼å¼ï¼Œå¹³è¡¡å‹ç¼©ç‡å’Œè¯»å–é€Ÿåº¦
- æ”¯æŒæ‰¹æ¬¡ç®¡ç†å’Œæ•°æ®ç´¯ç§¯
- ä¸ºå¹¶è¡Œè®¡ç®—é¢„ç•™æ¥å£
- æ”¯æŒ variance per identity è®¡ç®—éœ€æ±‚

**ç›®å½•ç»“æ„**ï¼š
```
results/zealot_morality_analysis/
â”œâ”€â”€ experiment_data/
â”‚   â”œâ”€â”€ zealot_numbers_data.parquet
â”‚   â””â”€â”€ morality_ratios_data.parquet
â”œâ”€â”€ metadata/
â”‚   â”œâ”€â”€ batch_metadata.json
â”‚   â””â”€â”€ experiment_config.json
â””â”€â”€ mean_plots/
    â””â”€â”€ [ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶]
```

#### 2.2 æ•°æ®å­˜å‚¨æ ¼å¼

**Parquet æ ¼å¼çš„æ‰å¹³åŒ–å­˜å‚¨**ï¼š

```python
def save_batch_results(self, plot_type: str, batch_data: Dict[str, Any], batch_metadata: Dict[str, Any]):
    """
    ä¿å­˜æ‰¹æ¬¡å®éªŒç»“æœ
    
    æ•°æ®æ ¼å¼è½¬æ¢ï¼š
    åµŒå¥—æ ¼å¼ -> æ‰å¹³DataFrameæ ¼å¼
    {combination: {x_values: [], results: {metric: [[run1, run2, ...], ...]}}}
    ->
    DataFrame with columns: ['batch_id', 'timestamp', 'combination', 'x_value', 'metric', 'run_index', 'value']
    """
    rows = []
    for combination_label, combo_data in batch_data.items():
        x_values = combo_data['x_values']
        results = combo_data['results']
        
        for x_idx, x_value in enumerate(x_values):
            for metric_name, metric_results in results.items():
                if x_idx < len(metric_results):
                    for run_idx, run_value in enumerate(metric_results[x_idx]):
                        rows.append({
                            'batch_id': batch_id,
                            'timestamp': timestamp,
                            'combination': combination_label,
                            'x_value': x_value,
                            'metric': metric_name,
                            'run_index': run_idx,
                            'value': run_value
                        })
    
    # åˆ›å»ºDataFrameå¹¶ä¿å­˜ä¸ºParquetæ ¼å¼
    new_df = pd.DataFrame(rows)
    combined_df = pd.concat([existing_df, new_df], ignore_index=True) if target_file.exists() else new_df
    combined_df.to_parquet(target_file, compression='snappy', index=False)
```

#### 2.3 æ•°æ®è¯»å–å’Œè½¬æ¢

**ç»˜å›¾æ ¼å¼è½¬æ¢**ï¼š

```python
def convert_to_plotting_format(self, plot_type: str) -> Tuple[Dict[str, Dict[str, List[List[float]]]], List[float], Dict[str, int]]:
    """
    å°†å­˜å‚¨çš„æ•°æ®è½¬æ¢ä¸ºç»˜å›¾æ ¼å¼
    
    Returns:
        (all_results, x_values, total_runs_per_combination)
        
    all_results æ ¼å¼:
    {
        combination_label: {
            metric_name: [
                [run1_val, run2_val, ...],  # x_value_1 çš„æ‰€æœ‰è¿è¡Œç»“æœ
                [run1_val, run2_val, ...],  # x_value_2 çš„æ‰€æœ‰è¿è¡Œç»“æœ
                ...
            ]
        }
    }
    """
    df = self.load_experiment_data(plot_type)
    combinations = sorted(df['combination'].unique())
    x_values = sorted(df['x_value'].unique())
    metrics = sorted(df['metric'].unique())
    
    all_results = {}
    total_runs_per_combination = {}
    
    for combination in combinations:
        combo_data = df[df['combination'] == combination]
        
        # è®¡ç®—æ€»è¿è¡Œæ¬¡æ•°
        unique_x_values = len(combo_data['x_value'].unique())
        unique_metrics = len(combo_data['metric'].unique())
        total_runs = len(combo_data) // (unique_x_values * unique_metrics)
        total_runs_per_combination[combination] = total_runs
        
        # ç»„ç»‡æ•°æ®ä¸ºç»˜å›¾æ ¼å¼
        combo_results = {}
        for metric in metrics:
            metric_results = []
            metric_data = combo_data[combo_data['metric'] == metric]
            
            for x_val in x_values:
                x_data = metric_data[metric_data['x_value'] == x_val]
                run_values = x_data['value'].tolist()
                metric_results.append(run_values)
            
            combo_results[metric] = metric_results
        
        all_results[combination] = combo_results
    
    return all_results, x_values, total_runs_per_combination
```

#### 2.4 å…ƒæ•°æ®ç®¡ç†

**æ‰¹æ¬¡å…ƒæ•°æ®**ï¼š
```json
{
  "batches": [
    {
      "batch_id": "20241222_143052",
      "timestamp": "2024-12-22 14:30:52",
      "experiment_type": "zealot_numbers",
      "num_runs": 5,
      "max_zealots": 50,
      "x_range": [0, 50],
      "combinations_count": 4
    }
  ]
}
```

**å®éªŒé…ç½®**ï¼š
```json
{
  "batch_name": "20241222_143052",
  "num_runs": 5,
  "max_zealots": 50,
  "max_morality": 30,
  "elapsed_time": 1234.56,
  "total_combinations": 14,
  "saved_at": "2024-12-22T14:35:10.123456"
}
```

#### 2.5 æ‘˜è¦æŠ¥å‘ŠåŠŸèƒ½

**æ‘˜è¦æŠ¥å‘Šç”Ÿæˆ**ï¼š

```python
def export_summary_report(self) -> str:
    """
    å¯¼å‡ºå®éªŒæ‘˜è¦æŠ¥å‘Š
    """
    zealot_summary = self.get_experiment_summary('zealot_numbers')
    morality_summary = self.get_experiment_summary('morality_ratios')
    batch_metadata = self.get_batch_metadata()
    
    report = []
    report.append("=" * 60)
    report.append("å®éªŒæ•°æ®æ‘˜è¦æŠ¥å‘Š")
    report.append("=" * 60)
    
    report.append(f"\nğŸ“Š Zealot Numbers å®éªŒ:")
    report.append(f"   æ€»è®°å½•æ•°: {zealot_summary['total_records']}")
    report.append(f"   å‚æ•°ç»„åˆæ•°: {len(zealot_summary['combinations'])}")
    report.append(f"   æ‰¹æ¬¡æ•°: {len(zealot_summary['batches'])}")
    
    # ... æ›´å¤šç»Ÿè®¡ä¿¡æ¯ ...
    
    return "\n".join(report)
```

## åŠŸèƒ½å¢å¼ºæ€»ç»“

### 3.1 æ–°å¢æŒ‡æ ‡

**Variance per Identity**ï¼š
- **åŠŸèƒ½**ï¼šè®¡ç®—æ¯ä¸ªèº«ä»½ç»„å†…éƒ¨çš„æ„è§æ–¹å·®
- **å®ç°**ï¼šæ­£ç¡®è¯†åˆ« zealot å’Œé zealot èŠ‚ç‚¹ï¼Œåˆ†åˆ«è®¡ç®—ä¸¤ä¸ªèº«ä»½ç»„çš„æ–¹å·®
- **å¯è§†åŒ–**ï¼šæä¾›åˆ†ç¦»ç‰ˆæœ¬ï¼ˆ2å¼ å›¾ï¼‰å’Œåˆå¹¶ç‰ˆæœ¬ï¼ˆ2å¼ å›¾ï¼‰

### 3.2 å¹¶è¡Œè®¡ç®—åŠŸèƒ½

**æ€§èƒ½æå‡**ï¼š
- **æµ‹è¯•ç»“æœ**ï¼š36% æ€§èƒ½æå‡ï¼ˆ146.22ç§’ â†’ 107.26ç§’ï¼‰
- **åŠ é€Ÿæ¯”**ï¼š1.36xï¼Œå¹¶è¡Œæ•ˆç‡ 34.1%
- **å®¹é”™æœºåˆ¶**ï¼šå¤±è´¥ä»»åŠ¡è‡ªåŠ¨å¤„ç†ï¼Œæ”¯æŒå›é€€åˆ°ä¸²è¡Œæ¨¡å¼

**æŠ€æœ¯ç‰¹æ€§**ï¼š
- ä»»åŠ¡çº§å¹¶è¡Œï¼šæ¯ä¸ªæ¨¡æ‹Ÿè¿è¡Œä½œä¸ºç‹¬ç«‹ä»»åŠ¡
- éšæœºç§å­ç®¡ç†ï¼šç¡®ä¿ç»“æœå¯é‡ç°æ€§
- è¿›åº¦æ˜¾ç¤ºï¼šå®æ—¶æ˜¾ç¤ºå¹¶è¡Œä»»åŠ¡è¿›åº¦

### 3.3 æ•°æ®ç®¡ç†ä¼˜åŒ–

**å­˜å‚¨æ•ˆç‡**ï¼š
- **æ ¼å¼**ï¼šParquet æ ¼å¼ï¼Œè‡ªåŠ¨å‹ç¼©
- **ç»“æ„**ï¼šæ‰å¹³åŒ–å­˜å‚¨ï¼Œä¾¿äºæŸ¥è¯¢å’Œåˆ†æ
- **å…ƒæ•°æ®**ï¼šå®Œæ•´çš„æ‰¹æ¬¡å’Œå®éªŒé…ç½®è®°å½•

**åŠŸèƒ½ç‰¹æ€§**ï¼š
- æ‰¹æ¬¡ç´¯ç§¯ï¼šæ”¯æŒå¤šæ¬¡è¿è¡Œæ•°æ®ç´¯ç§¯
- æ ¼å¼è½¬æ¢ï¼šè‡ªåŠ¨è½¬æ¢ä¸ºç»˜å›¾æ‰€éœ€æ ¼å¼
- æ‘˜è¦æŠ¥å‘Šï¼šè¯¦ç»†çš„å®éªŒç»Ÿè®¡ä¿¡æ¯

### 3.4 æ•°æ®å¹³æ»‘å’Œé‡é‡‡æ ·åŠŸèƒ½

**è§£å†³çš„æ ¸å¿ƒé—®é¢˜**ï¼š
- **é«˜å¯†åº¦é‡‡æ ·å™ªå£°**ï¼šä»æ­¥é•¿2æ”¹ä¸ºæ­¥é•¿1åï¼Œå™ªå£°å ä¸»å¯¼åœ°ä½
- **é”¯é½¿çŠ¶æŒ¯è¡**ï¼šç›¸é‚»æ•°æ®ç‚¹å·®å¼‚å°äºéšæœºæ³¢åŠ¨ï¼Œå½±å“è¶‹åŠ¿åˆ¤æ–­
- **ä¿¡å™ªæ¯”ä½**ï¼šåŸå§‹æ­¥é•¿1æ—¶ä¿¡å™ªæ¯”çº¦2:1ï¼Œéš¾ä»¥è¯†åˆ«çœŸå®è¶‹åŠ¿

**ä¸‰çº§å¹³æ»‘ç³»ç»Ÿ**ï¼š

1. **ç¬¬ä¸€çº§ - å±€éƒ¨å¹³æ»‘**ï¼š
   - ä½¿ç”¨å°çª—å£ï¼ˆ3ç‚¹ï¼‰ç§»åŠ¨å¹³å‡
   - ä¿æŒåŸå§‹æ•°æ®é•¿åº¦
   - åˆæ­¥å‡å°‘éšæœºå™ªå£°

2. **ç¬¬äºŒçº§ - é‡é‡‡æ ·**ï¼š
   - ä»é«˜å¯†åº¦ï¼ˆ101ä¸ªç‚¹ï¼‰é‡é‡‡æ ·åˆ°ä½å¯†åº¦ï¼ˆ51ä¸ªç‚¹ï¼‰
   - ä½¿ç”¨çº¿æ€§æ’å€¼ç¡®ä¿å¹³æ»‘è¿‡æ¸¡
   - å°†ä¿¡å™ªæ¯”ä»2:1æå‡åˆ°4:1

3. **ç¬¬ä¸‰çº§ - æœ€ç»ˆå¹³æ»‘**ï¼š
   - æ”¯æŒå¤šç§å¹³æ»‘æ–¹æ³•ï¼š
     - `'savgol'`ï¼šSavitzky-Golayæ»¤æ³¢ï¼ˆé»˜è®¤ï¼Œä¿æŒè¶‹åŠ¿å½¢çŠ¶ï¼‰
     - `'moving_avg'`ï¼šç§»åŠ¨å¹³å‡ï¼ˆç®€å•æœ‰æ•ˆï¼‰
     - `'none'`ï¼šä¸åº”ç”¨æœ€ç»ˆå¹³æ»‘
   - è¿›ä¸€æ­¥æŠ‘åˆ¶å™ªå£°ï¼Œçªå‡ºä¸»è¦è¶‹åŠ¿

**æŠ€æœ¯ç‰¹æ€§**ï¼š
- **å®¹é”™å¤„ç†**ï¼šæ’å€¼å¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ°åŸå§‹æ•°æ®
- **è¾¹ç•Œå¤„ç†**ï¼šæ­£ç¡®å¤„ç†æ•°æ®è¾¹ç•Œï¼Œé¿å…å¤±çœŸ
- **å‚æ•°å¯è°ƒ**ï¼šæ”¯æŒè‡ªå®šä¹‰æ­¥é•¿å’Œå¹³æ»‘æ–¹æ³•
- **å‘åå…¼å®¹**ï¼šå¯å®Œå…¨å…³é—­å¹³æ»‘åŠŸèƒ½

**æ•ˆæœè¯„ä¼°**ï¼š
```python
# æ•ˆæœå¯¹æ¯”
åŸå§‹æ•°æ®ï¼ˆæ­¥é•¿=1ï¼‰:  å™ªå£°æ˜æ˜¾ï¼Œé”¯é½¿çŠ¶ä¸¥é‡
é‡é‡‡æ ·ï¼ˆæ­¥é•¿=2ï¼‰:    ä¿¡å™ªæ¯”æå‡1å€ï¼Œåˆæ­¥æ”¹å–„
ä¸‰çº§å¹³æ»‘å:         è¶‹åŠ¿æ¸…æ™°ï¼Œå™ªå£°æ˜¾è‘—æŠ‘åˆ¶
```

### 3.5 å¯è§†åŒ–å¢å¼º

**å›¾è¡¨æ•°é‡**ï¼šä» 8 å¼ å¢åŠ åˆ° 14 å¼ 
- 2 ç§å®éªŒç±»å‹ï¼ˆzealot_numbers, morality_ratiosï¼‰
- 7 ä¸ªæŒ‡æ ‡ï¼ˆåŸæœ‰4ä¸ª + æ–°å¢3ä¸ªvariance per identityç›¸å…³ï¼‰

**æ ·å¼ç³»ç»Ÿ**ï¼š
- æ™ºèƒ½é¢œè‰²åˆ†é…ï¼šåŸºäºå“ˆå¸Œå€¼ç¡®ä¿ä¸€è‡´æ€§
- çº¿å‹åŒºåˆ†ï¼šå®çº¿/è™šçº¿åŒºåˆ†ä¸åŒèº«ä»½ç»„
- å›¾ä¾‹ä¼˜åŒ–ï¼šæ ¹æ®çº¿æ¡æ•°é‡è‡ªåŠ¨è°ƒæ•´å¸ƒå±€

**å¹³æ»‘å¯è§†åŒ–ç‰¹æ€§**ï¼š
- **åŒæ ‡è¯†ç³»ç»Ÿ**ï¼šåŸå§‹å›¾å’Œå¹³æ»‘å›¾åˆ†åˆ«æ ‡è¯†
- **æ–‡ä»¶å‘½ååŒºåˆ†**ï¼šå¹³æ»‘å›¾æ–‡ä»¶ååŒ…å«æ­¥é•¿å’Œæ–¹æ³•ä¿¡æ¯
- **å›¾ä¾‹è¯´æ˜**ï¼šè‡ªåŠ¨æ·»åŠ "(smoothed)"æ ‡è¯†
- **Error Bandså¤„ç†**ï¼šå¹³æ»‘æ¨¡å¼ä¸‹æ™ºèƒ½å…³é—­error bandsï¼ˆé¿å…ä¸ä¸€è‡´ï¼‰

## ä½¿ç”¨æ–¹æ³•

### 4.1 åŸºæœ¬ä½¿ç”¨

```python
# å®Œæ•´å®éªŒï¼ˆæ•°æ®æ”¶é›† + ç»˜å›¾ï¼‰
run_zealot_morality_analysis(
    output_dir="results/zealot_morality_analysis",
    num_runs=5,
    max_zealots=50,
    max_morality=30,
    num_processes=12  # ä½¿ç”¨12ä¸ªè¿›ç¨‹å¹¶è¡Œè®¡ç®—
)

# åˆ†æ­¥éª¤ä½¿ç”¨
# æ­¥éª¤1ï¼šæ•°æ®æ”¶é›†
run_and_accumulate_data(
    output_dir="results/zealot_morality_analysis",
    num_runs=5,
    max_zealots=50,
    max_morality=30,
    batch_name="batch_001",
    num_processes=12
)

# æ­¥éª¤2ï¼šç”Ÿæˆå›¾è¡¨ï¼ˆå¯ç”¨å¹³æ»‘åŠŸèƒ½ï¼‰
plot_from_accumulated_data(
    output_dir="results/zealot_morality_analysis",
    enable_smoothing=True,      # å¯ç”¨å¹³æ»‘å¤„ç†
    target_step=2,             # ä»æ­¥é•¿1é‡é‡‡æ ·åˆ°æ­¥é•¿2
    smooth_method='savgol'     # ä½¿ç”¨Savitzky-Golayå¹³æ»‘
)
```

### 4.1.1 å¹³æ»‘åŠŸèƒ½çš„ä½¿ç”¨é€‰é¡¹

```python
# æ–¹æ¡ˆ1ï¼šé»˜è®¤å¹³æ»‘ï¼ˆæ¨èï¼‰
plot_from_accumulated_data(
    output_dir="results/zealot_morality_analysis",
    enable_smoothing=True,      # å¯ç”¨å¹³æ»‘
    target_step=2,             # ä»101ä¸ªç‚¹é‡é‡‡æ ·åˆ°51ä¸ªç‚¹
    smooth_method='savgol'     # ä½¿ç”¨Savitzky-Golayæ»¤æ³¢
)

# æ–¹æ¡ˆ2ï¼šç®€å•ç§»åŠ¨å¹³å‡å¹³æ»‘
plot_from_accumulated_data(
    output_dir="results/zealot_morality_analysis",
    enable_smoothing=True,
    target_step=2,
    smooth_method='moving_avg'  # ä½¿ç”¨ç§»åŠ¨å¹³å‡
)

# æ–¹æ¡ˆ3ï¼šä»…é‡é‡‡æ ·ï¼Œä¸é¢å¤–å¹³æ»‘
plot_from_accumulated_data(
    output_dir="results/zealot_morality_analysis",
    enable_smoothing=True,
    target_step=2,
    smooth_method='none'       # ä¸åº”ç”¨æœ€ç»ˆå¹³æ»‘
)

# æ–¹æ¡ˆ4ï¼šè‡ªå®šä¹‰é‡é‡‡æ ·æ­¥é•¿
plot_from_accumulated_data(
    output_dir="results/zealot_morality_analysis",
    enable_smoothing=True,
    target_step=3,             # ä»101ä¸ªç‚¹é‡é‡‡æ ·åˆ°34ä¸ªç‚¹
    smooth_method='savgol'
)

# æ–¹æ¡ˆ5ï¼šå®Œå…¨å…³é—­å¹³æ»‘ï¼ˆè·å¾—åŸå§‹é”¯é½¿çŠ¶å›¾ï¼‰
plot_from_accumulated_data(
    output_dir="results/zealot_morality_analysis",
    enable_smoothing=False     # å…³é—­å¹³æ»‘ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
)
```

### 4.1.2 å¹³æ»‘å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|---------|------|
| `enable_smoothing` | bool | True | æ˜¯å¦å¯ç”¨å¹³æ»‘åŠŸèƒ½ |
| `target_step` | int | 2 | é‡é‡‡æ ·ç›®æ ‡æ­¥é•¿ï¼ˆ1è¡¨ç¤ºä¸é‡é‡‡æ ·ï¼‰ |
| `smooth_method` | str | 'savgol' | æœ€ç»ˆå¹³æ»‘æ–¹æ³• |

**smooth_methodå‚æ•°é€‰é¡¹**ï¼š
- `'savgol'`ï¼šSavitzky-Golayæ»¤æ³¢ï¼Œä¿æŒæ•°æ®çš„å±€éƒ¨ç‰¹å¾å’Œè¶‹åŠ¿
- `'moving_avg'`ï¼šç§»åŠ¨å¹³å‡ï¼Œç®€å•æœ‰æ•ˆçš„å¹³æ»‘æ–¹æ³•
- `'none'`ï¼šä¸åº”ç”¨æœ€ç»ˆå¹³æ»‘ï¼Œä»…ä½¿ç”¨é‡é‡‡æ ·

**target_stepå‚æ•°å»ºè®®**ï¼š
- `target_step=1`ï¼šä¸é‡é‡‡æ ·ï¼Œä¿æŒåŸå§‹å¯†åº¦
- `target_step=2`ï¼šæ¨èå€¼ï¼Œä»101ç‚¹â†’51ç‚¹ï¼Œå¹³è¡¡å¯†åº¦å’Œå¹³æ»‘åº¦
- `target_step=3`ï¼šä»101ç‚¹â†’34ç‚¹ï¼Œæ›´å¼ºçš„å¹³æ»‘æ•ˆæœ
- `target_step=5`ï¼šä»101ç‚¹â†’21ç‚¹ï¼Œéå¸¸å¹³æ»‘ä½†å¯èƒ½ä¸¢å¤±ç»†èŠ‚

### 4.2 æ•°æ®ç®¡ç†å™¨ç›´æ¥ä½¿ç”¨

```python
from polarization_triangle.utils.data_manager import ExperimentDataManager

# åˆ›å»ºæ•°æ®ç®¡ç†å™¨
data_manager = ExperimentDataManager("results/zealot_morality_analysis")

# æŸ¥çœ‹æ‘˜è¦æŠ¥å‘Š
print(data_manager.export_summary_report())

# è·å–å®éªŒæ•°æ®
zealot_summary = data_manager.get_experiment_summary('zealot_numbers')
morality_summary = data_manager.get_experiment_summary('morality_ratios')

# åŠ è½½åŸå§‹æ•°æ®è¿›è¡Œè‡ªå®šä¹‰åˆ†æ
df = data_manager.load_experiment_data('zealot_numbers')
```

## æŠ€æœ¯äº®ç‚¹

### 5.1 ä»£ç è´¨é‡

- **æ–‡æ¡£å®Œæ•´**ï¼šæ¯ä¸ªå‡½æ•°éƒ½æœ‰è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
- **ç±»å‹æ³¨è§£**ï¼šä½¿ç”¨ typing æ¨¡å—æä¾›ç±»å‹æç¤º
- **é”™è¯¯å¤„ç†**ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œå›é€€æœºåˆ¶
- **ä»£ç ç»“æ„**ï¼šæ¸…æ™°çš„æ¨¡å—åŒ–è®¾è®¡

### 5.2 æ€§èƒ½ä¼˜åŒ–

- **å¹¶è¡Œè®¡ç®—**ï¼šå¤šè¿›ç¨‹å¹¶è¡Œï¼Œæ˜¾è‘—æå‡æ€§èƒ½
- **å­˜å‚¨æ•ˆç‡**ï¼šParquet æ ¼å¼ï¼Œå‹ç¼©ç‡é«˜ï¼Œè¯»å–å¿«
- **å†…å­˜ç®¡ç†**ï¼šé¿å…å¤§é‡æ•°æ®åœ¨å†…å­˜ä¸­ç´¯ç§¯

### 5.3 ç”¨æˆ·ä½“éªŒ

- **è¿›åº¦æ˜¾ç¤º**ï¼šè¯¦ç»†çš„è¿›åº¦æ¡å’ŒçŠ¶æ€ä¿¡æ¯
- **å‘åå…¼å®¹**ï¼šä¿æŒåŸæœ‰æ¥å£ä¸å˜
- **çµæ´»é…ç½®**ï¼šæ”¯æŒå¤šç§å‚æ•°é…ç½®ç»„åˆ

## æœªæ¥æ‰©å±•æ–¹å‘

### 6.1 åŠŸèƒ½æ‰©å±•

- **æ›´å¤šæŒ‡æ ‡**ï¼šå¯ä»¥è½»æ¾æ·»åŠ æ–°çš„ç»Ÿè®¡æŒ‡æ ‡
- **å¯è§†åŒ–é€‰é¡¹**ï¼šæ”¯æŒæ›´å¤šå›¾è¡¨ç±»å‹å’Œæ ·å¼
- **æ•°æ®åˆ†æ**ï¼šé›†æˆæ›´å¤šç»Ÿè®¡åˆ†æåŠŸèƒ½

### 6.2 æ€§èƒ½ä¼˜åŒ–

- **åˆ†å¸ƒå¼è®¡ç®—**ï¼šæ”¯æŒè·¨æœºå™¨çš„åˆ†å¸ƒå¼è®¡ç®—
- **GPUåŠ é€Ÿ**ï¼šåˆ©ç”¨GPUåŠ é€Ÿè®¡ç®—å¯†é›†å‹ä»»åŠ¡
- **å†…å­˜ä¼˜åŒ–**ï¼šè¿›ä¸€æ­¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨

### 6.3 æ•°æ®ç®¡ç†

- **æ•°æ®æ¸…ç†**ï¼šè‡ªåŠ¨æ¸…ç†æ—§æ•°æ®åŠŸèƒ½
- **æ•°æ®å¯¼å‡º**ï¼šæ”¯æŒæ›´å¤šæ•°æ®æ ¼å¼å¯¼å‡º
- **æ•°æ®ç‰ˆæœ¬æ§åˆ¶**ï¼šå®éªŒæ•°æ®çš„ç‰ˆæœ¬ç®¡ç†

## æ€»ç»“

æœ¬æ¬¡å¼€å‘ä¼šè¯æˆåŠŸå®ç°äº†ä»¥ä¸‹ç›®æ ‡ï¼š

1. **æ–°å¢ variance per identity æŒ‡æ ‡**ï¼šä¸ºç³»ç»Ÿåˆ†ææä¾›äº†æ–°çš„ç»´åº¦
2. **å®ç°å¹¶è¡Œè®¡ç®—åŠŸèƒ½**ï¼šæ˜¾è‘—æå‡äº†å®éªŒæ‰§è¡Œæ•ˆç‡
3. **ä¼˜åŒ–æ•°æ®ç®¡ç†ç³»ç»Ÿ**ï¼šæä¾›äº†é«˜æ•ˆã€å¯æ‰©å±•çš„æ•°æ®å­˜å‚¨æ–¹æ¡ˆ
4. **å¢å¼ºå¯è§†åŒ–ç³»ç»Ÿ**ï¼šæ”¯æŒæ›´ä¸°å¯Œçš„å›¾è¡¨ç±»å‹å’Œæ ·å¼é…ç½®
5. **æ–°å¢æ•°æ®å¹³æ»‘å’Œé‡é‡‡æ ·åŠŸèƒ½**ï¼šè§£å†³é«˜å¯†åº¦é‡‡æ ·å¸¦æ¥çš„å™ªå£°é—®é¢˜ï¼Œæä¾›æ›´æ¸…æ™°çš„è¶‹åŠ¿å¯è§†åŒ–

## å¹³æ»‘åŠŸèƒ½çš„é‡è¦ä»·å€¼

### è§£å†³çš„å®é™…é—®é¢˜
- **æ•°æ®å¯†åº¦è¿‡é«˜**ï¼šä»æ­¥é•¿2â†’æ­¥é•¿1ï¼Œæ•°æ®ç‚¹ä»51ä¸ªå¢åŠ åˆ°101ä¸ª
- **å™ªå£°å ä¸»å¯¼**ï¼šé«˜å¯†åº¦é‡‡æ ·å¯¼è‡´ç›¸é‚»ç‚¹çš„çœŸå®å·®å¼‚è¢«éšæœºå™ªå£°æ©ç›–
- **å¯è§†åŒ–å›°éš¾**ï¼šé”¯é½¿çŠ¶æŒ¯è¡ä¸¥é‡å½±å“è¶‹åŠ¿åˆ¤æ–­

### æŠ€æœ¯åˆ›æ–°ç‚¹
- **ä¸‰çº§å¹³æ»‘ç³»ç»Ÿ**ï¼šå±€éƒ¨å¹³æ»‘â†’é‡é‡‡æ ·â†’æœ€ç»ˆå¹³æ»‘çš„å±‚æ¬¡åŒ–å¤„ç†
- **æ™ºèƒ½å‚æ•°è°ƒèŠ‚**ï¼šæ”¯æŒå¤šç§å¹³æ»‘æ–¹æ³•å’Œè‡ªå®šä¹‰æ­¥é•¿
- **æ•°æ®å……åˆ†åˆ©ç”¨**ï¼šåœ¨å‡å°‘æ•°æ®ç‚¹çš„åŒæ—¶ä¿ç•™æ‰€æœ‰åŸå§‹ä¿¡æ¯
- **å‘åå…¼å®¹**ï¼šå¯å®Œå…¨å…³é—­å¹³æ»‘åŠŸèƒ½ï¼Œä¿æŒåŸæœ‰è¡Œä¸º

### å®é™…æ•ˆæœ
- **ä¿¡å™ªæ¯”æå‡**ï¼šä»2:1æå‡åˆ°4:1ä»¥ä¸Š
- **è¶‹åŠ¿æ¸…æ™°åŒ–**ï¼šæ¶ˆé™¤é”¯é½¿çŠ¶æŒ¯è¡ï¼Œçªå‡ºä¸»è¦å˜åŒ–è¶‹åŠ¿
- **ä¿æŒç²¾åº¦**ï¼šé€šè¿‡æ’å€¼å’Œé«˜çº§æ»¤æ³¢ä¿æŒæ•°æ®ç²¾åº¦
- **çµæ´»å¯æ§**ï¼šç”¨æˆ·å¯æ ¹æ®éœ€è¦è°ƒæ•´å¹³æ»‘å¼ºåº¦

æ•´ä¸ªç³»ç»Ÿç°åœ¨å…·å¤‡äº†ï¼š
- **å®Œæ•´æ€§**ï¼šä»æ•°æ®æ”¶é›†åˆ°å¯è§†åŒ–çš„å®Œæ•´æµç¨‹
- **é«˜æ•ˆæ€§**ï¼šå¹¶è¡Œè®¡ç®—å’Œä¼˜åŒ–å­˜å‚¨çš„é«˜æ€§èƒ½
- **å¯æ‰©å±•æ€§**ï¼šæ¨¡å—åŒ–è®¾è®¡ä¾¿äºåç»­æ‰©å±•
- **æ˜“ç”¨æ€§**ï¼šç”¨æˆ·å‹å¥½çš„APIæ¥å£
- **æ™ºèƒ½åŒ–**ï¼šè‡ªåŠ¨å¤„ç†æ•°æ®å™ªå£°ï¼Œæä¾›æ¸…æ™°çš„å¯è§†åŒ–ç»“æœ

ä»£ç æ€»è¡Œæ•°çº¦ 2000 è¡Œï¼ˆzealot_morality_analysis.py: ~1500è¡Œ, data_manager.py: 470è¡Œï¼‰ï¼Œç»“æ„æ¸…æ™°ï¼ŒåŠŸèƒ½å®Œæ•´ï¼Œä¸ºæåŒ–ä¸‰è§’æ¡†æ¶çš„å®éªŒåˆ†ææä¾›äº†å¼ºå¤§çš„å·¥å…·æ”¯æŒã€‚

## å¹³æ»‘åŠŸèƒ½çš„æ–‡ä»¶è¾“å‡º

å¯ç”¨å¹³æ»‘åŠŸèƒ½åï¼Œç³»ç»Ÿä¼šç”Ÿæˆä¸¤å¥—å›¾è¡¨ï¼š

### æ–‡ä»¶å‘½åè§„åˆ™
```
# å¹³æ»‘ç‰ˆæœ¬
morality_ratios_mean_opinion_smoothed_step2_savgol_5runs.png
zealot_numbers_variance_smoothed_step2_savgol_5runs.png

# åŸå§‹ç‰ˆæœ¬ï¼ˆå¦‚æœåŒæ—¶éœ€è¦å¯¹æ¯”ï¼‰
morality_ratios_mean_opinion_mean_5runs.png
zealot_numbers_variance_mean_with_error_bands_5runs.png
```

### æ–‡ä»¶ç»„ç»‡ç»“æ„
```
results/zealot_morality_analysis/mean_plots/
â”œâ”€â”€ morality_ratios_mean_opinion_smoothed_step2_savgol_5runs.png
â”œâ”€â”€ morality_ratios_variance_smoothed_step2_savgol_5runs.png
â”œâ”€â”€ morality_ratios_identity_opinion_difference_smoothed_step2_savgol_5runs.png
â”œâ”€â”€ morality_ratios_polarization_index_smoothed_step2_savgol_5runs.png
â”œâ”€â”€ morality_ratios_variance_per_identity_1_smoothed_step2_savgol_5runs.png
â”œâ”€â”€ morality_ratios_variance_per_identity_-1_smoothed_step2_savgol_5runs.png
â”œâ”€â”€ morality_ratios_variance_per_identity_combined_smoothed_step2_savgol_5runs.png
â”œâ”€â”€ zealot_numbers_mean_opinion_smoothed_step2_savgol_5runs.png
â”œâ”€â”€ zealot_numbers_variance_smoothed_step2_savgol_5runs.png
â”œâ”€â”€ zealot_numbers_identity_opinion_difference_smoothed_step2_savgol_5runs.png
â”œâ”€â”€ zealot_numbers_polarization_index_smoothed_step2_savgol_5runs.png
â”œâ”€â”€ zealot_numbers_variance_per_identity_1_smoothed_step2_savgol_5runs.png
â”œâ”€â”€ zealot_numbers_variance_per_identity_-1_smoothed_step2_savgol_5runs.png
â””â”€â”€ zealot_numbers_variance_per_identity_combined_smoothed_step2_savgol_5runs.png
```

æ€»è®¡ **14 å¼ å¹³æ»‘å›¾è¡¨**ï¼Œæ¯å¼ éƒ½æ¸…æ™°å±•ç¤ºäº†ç›¸åº”æŒ‡æ ‡çš„å˜åŒ–è¶‹åŠ¿ï¼Œæ¶ˆé™¤äº†åŸæœ‰çš„é”¯é½¿çŠ¶å™ªå£°é—®é¢˜ã€‚