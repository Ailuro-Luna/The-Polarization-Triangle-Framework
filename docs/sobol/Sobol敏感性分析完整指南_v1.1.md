# æåŒ–ä¸‰è§’æ¡†æ¶ Sobolæ•æ„Ÿæ€§åˆ†æå®Œæ•´æŒ‡å— v1.1

## ğŸ“‹ ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [ç³»ç»Ÿè¦æ±‚ä¸å®‰è£…](#ç³»ç»Ÿè¦æ±‚ä¸å®‰è£…)
3. [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
4. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
5. [è¯¦ç»†é…ç½®](#è¯¦ç»†é…ç½®)
6. [è¾“å‡ºæŒ‡æ ‡è¯¦è§£](#è¾“å‡ºæŒ‡æ ‡è¯¦è§£)
7. [å¯è§†åŒ–åŠŸèƒ½](#å¯è§†åŒ–åŠŸèƒ½)
8. [é«˜çº§ç”¨æ³•](#é«˜çº§ç”¨æ³•)
9. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
10. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
11. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
12. [APIå‚è€ƒ](#apiå‚è€ƒ)
13. [æ›´æ–°æ—¥å¿—](#æ›´æ–°æ—¥å¿—)

## æ¦‚è¿°

æåŒ–ä¸‰è§’æ¡†æ¶Sobolæ•æ„Ÿæ€§åˆ†æå·¥å…·æ˜¯ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„å…¨å±€æ•æ„Ÿæ€§åˆ†æç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºåˆ†ææåŒ–åŠ¨åŠ›å­¦æ¨¡å‹ä¸­å››ä¸ªå…³é”®å‚æ•°ï¼ˆÎ±ã€Î²ã€Î³ã€cohesion_factorï¼‰çš„å½±å“ç¨‹åº¦å’Œç›¸äº’ä½œç”¨ã€‚

### ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

- **ğŸ” å…¨å±€æ•æ„Ÿæ€§åˆ†æ**: åŸºäºSobolæ–¹æ³•çš„å‚æ•°é‡è¦æ€§é‡åŒ–
- **ğŸš€ é«˜æ€§èƒ½è®¡ç®—**: å¤šè¿›ç¨‹å¹¶è¡Œï¼Œæ”¯æŒå¤§è§„æ¨¡æ ·æœ¬åˆ†æ
- **ğŸ“Š ä¸°å¯Œçš„è¾“å‡ºæŒ‡æ ‡**: 14ç§æ¶µç›–æåŒ–ã€æ”¶æ•›ã€åŠ¨æ€ã€èº«ä»½çš„å…³é”®æŒ‡æ ‡
- **ğŸ¨ ä¸“ä¸šå¯è§†åŒ–**: å¤šç±»å‹å›¾è¡¨ï¼Œæ”¯æŒé«˜è´¨é‡è¾“å‡º
- **ğŸ› ï¸ æ˜“äºä½¿ç”¨**: å‘½ä»¤è¡Œå’Œç¼–ç¨‹æ¥å£åŒé‡æ”¯æŒ
- **ğŸ’¾ å¯é å­˜å‚¨**: è‡ªåŠ¨ä¿å­˜ä¸­é—´ç»“æœï¼Œæ”¯æŒæ–­ç‚¹ç»­ç®—
- **ğŸ”§ é«˜åº¦å¯é…ç½®**: é¢„è®¾é…ç½® + è‡ªå®šä¹‰å‚æ•°ç»„åˆ

### ğŸ¯ åˆ†æç›®æ ‡

1. **å‚æ•°é‡è¦æ€§æ’åº**: ç¡®å®šå“ªä¸ªå‚æ•°å¯¹æ¨¡å‹è¡Œä¸ºå½±å“æœ€å¤§
2. **äº¤äº’æ•ˆåº”è¯†åˆ«**: å‘ç°å‚æ•°é—´çš„ååŒæˆ–æ‹®æŠ—ä½œç”¨
3. **æ¨¡å‹è¡Œä¸ºç†è§£**: æ·±åŒ–å¯¹æåŒ–ä¸‰è§’æ¡†æ¶æœºåˆ¶çš„è®¤è¯†
4. **å‚æ•°è°ƒä¼˜æŒ‡å¯¼**: ä¸ºå®é™…åº”ç”¨æä¾›å‚æ•°è®¾ç½®å»ºè®®

## ç³»ç»Ÿè¦æ±‚ä¸å®‰è£…

### ç¯å¢ƒè¦æ±‚

- **Python**: 3.8+ (æ¨è 3.9 æˆ– 3.10)
- **æ“ä½œç³»ç»Ÿ**: Windows 10+, macOS 10.14+, Linux (Ubuntu 18.04+)
- **å†…å­˜**: æœ€å°‘8GBï¼Œæ¨è16GB+
- **CPU**: å¤šæ ¸å¤„ç†å™¨ï¼ˆ4æ ¸+ï¼‰æ¨èç”¨äºå¹¶è¡Œè®¡ç®—

### å®‰è£…æ­¥éª¤

#### 1. åŸºç¡€ä¾èµ–å®‰è£…

```bash
# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install SALib==1.4.7 seaborn==0.12.2 pandas==2.0.3 openpyxl

# æˆ–è€…æ›´æ–°æ•´ä¸ªç¯å¢ƒ
pip install -r requirements.txt
```

#### 2. éªŒè¯å®‰è£…

```bash
python -c "from polarization_triangle.analysis import SobolAnalyzer; print('âœ… å®‰è£…æˆåŠŸ')"
```

#### 3. å¿«é€Ÿæµ‹è¯•

```bash
python polarization_triangle/scripts/run_sobol_analysis.py --config quick
```

### ğŸ†• v1.1æ–°å¢ä¾èµ–

- **openpyxl**: Excelæ–‡ä»¶å¯¼å‡ºæ”¯æŒ
- ä¼˜åŒ–çš„å­—ä½“å¤„ç†ï¼ˆæ— éœ€é¢å¤–ä¸­æ–‡å­—ä½“åŒ…ï¼‰

## æ ¸å¿ƒåŠŸèƒ½

### å‚æ•°æ•æ„Ÿæ€§åˆ†æ

åˆ†æå››ä¸ªå…³é”®å‚æ•°çš„å½±å“ï¼š

| å‚æ•° | ç¬¦å· | ä½œç”¨æœºåˆ¶ | å–å€¼èŒƒå›´ | é¢„æœŸå½±å“ |
|------|------|----------|----------|----------|
| è‡ªæˆ‘æ¿€æ´»ç³»æ•° | Î± | æ§åˆ¶Agentè§‚ç‚¹åšæŒå¼ºåº¦ | [0.1, 0.8] | é«˜å€¼ä¿ƒè¿›æåŒ– |
| ç¤¾ä¼šå½±å“ç³»æ•° | Î² | æ§åˆ¶é‚»å±…å½±å“å¼ºåº¦ | [0.05, 0.3] | é«˜å€¼ä¿ƒè¿›æ”¶æ•› |
| é“å¾·åŒ–å½±å“ç³»æ•° | Î³ | è°ƒèŠ‚é“å¾·åŒ–æŠ‘åˆ¶æ•ˆåº” | [0.2, 2.0] | é«˜å€¼å¢å¼ºæŠµæŠ— |
| èº«ä»½å‡èšåŠ›å› å­ | cohesion_factor | å¢å¼ºç½‘ç»œè¿æ¥å¼ºåº¦ | [0.0, 0.5] | é«˜å€¼ä¿ƒè¿›ä¼ æ’­ |

### æ•æ„Ÿæ€§æŒ‡æ•°è®¡ç®—

- **ä¸€é˜¶æ•æ„Ÿæ€§æŒ‡æ•° (S1)**: å‚æ•°å•ç‹¬å¯¹è¾“å‡ºæ–¹å·®çš„è´¡çŒ®
- **æ€»æ•æ„Ÿæ€§æŒ‡æ•° (ST)**: å‚æ•°åŠå…¶æ‰€æœ‰äº¤äº’é¡¹çš„æ€»è´¡çŒ®
- **äº¤äº’æ•ˆåº”å¼ºåº¦ (ST-S1)**: å‚æ•°é—´ç›¸äº’ä½œç”¨çš„å¼ºåº¦

### è¾“å‡ºæŒ‡æ ‡ä½“ç³»

æ¶µç›–æåŒ–åŠ¨åŠ›å­¦çš„å¤šä¸ªç»´åº¦ï¼š

1. **æåŒ–æŒ‡æ ‡** (4ä¸ª)
2. **æ”¶æ•›æŒ‡æ ‡** (2ä¸ª)  
3. **åŠ¨æ€æŒ‡æ ‡** (3ä¸ª)
4. **èº«ä»½æŒ‡æ ‡** (2ä¸ª)
5. **Variance Per IdentityæŒ‡æ ‡** (3ä¸ª) - æ–°å¢

## å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1: å‘½ä»¤è¡Œä½¿ç”¨ï¼ˆæ¨èï¼‰

```bash
# å¿«é€Ÿæµ‹è¯• (1-3åˆ†é’Ÿ)
python polarization_triangle/scripts/run_sobol_analysis.py --config quick

# æ ‡å‡†åˆ†æ (15-30åˆ†é’Ÿ)
python polarization_triangle/scripts/run_sobol_analysis.py --config standard

# é«˜ç²¾åº¦åˆ†æ (1-2å°æ—¶)
python polarization_triangle/scripts/run_sobol_analysis.py --config high_precision

# è®ºæ–‡å‘è¡¨çº§ (4-8å°æ—¶)
python polarization_triangle/scripts/run_sobol_analysis.py --config full
```

### æ–¹æ³•2: Pythonç¼–ç¨‹æ¥å£

```python
from polarization_triangle.analysis import SobolAnalyzer, SobolConfig

# åˆ›å»ºé…ç½®
config = SobolConfig(
    n_samples=200,         # æ ·æœ¬æ•°
    n_runs=3,             # é‡å¤è¿è¡Œæ¬¡æ•°
    n_processes=4,        # å¹¶è¡Œè¿›ç¨‹æ•°
    output_dir="my_analysis"
)

# è¿è¡Œåˆ†æ
analyzer = SobolAnalyzer(config)
sensitivity_indices = analyzer.run_complete_analysis()

# æŸ¥çœ‹ç»“æœæ‘˜è¦
summary = analyzer.get_summary_table()
print(summary.head(10))
```

### æ–¹æ³•3: ä½¿ç”¨ç¤ºä¾‹è„šæœ¬

```bash
# åŸºç¡€æ•æ„Ÿæ€§åˆ†æç¤ºä¾‹
python polarization_triangle/examples/sobol_sensitivity_example.py

# Variance Per Identity ä¸“é—¨ç¤ºä¾‹ (æ–°å¢)
python polarization_triangle/examples/variance_per_identity_example.py
```

## è¯¦ç»†é…ç½®

### é¢„è®¾é…ç½®å¯¹æ¯”

| é…ç½®å | æ ·æœ¬æ•° | è¿è¡Œæ¬¡æ•° | æ¨¡æ‹Ÿæ­¥æ•° | è¿›ç¨‹æ•° | æ€»æ¨¡æ‹Ÿæ¬¡æ•° | é€‚ç”¨åœºæ™¯ | é¢„è®¡è€—æ—¶ |
|--------|--------|----------|----------|--------|------------|----------|----------|
| `quick` | 50 | 2 | 100 | 2 | 1,000 | å¿«é€Ÿæµ‹è¯•éªŒè¯ | 1-3åˆ†é’Ÿ |
| `standard` | 500 | 3 | 200 | 4 | 15,000 | å¸¸è§„åˆ†æç ”ç©¶ | 15-30åˆ†é’Ÿ |
| `high_precision` | 1000 | 5 | 300 | 6 | 50,000 | é«˜ç²¾åº¦ç ”ç©¶ | 1-2å°æ—¶ |
| `full` | 2000 | 10 | 500 | 8 | 200,000 | è®ºæ–‡å‘è¡¨çº§ | 4-8å°æ—¶ |

### è‡ªå®šä¹‰é…ç½®

```python
# åˆ›å»ºè‡ªå®šä¹‰åŸºç¡€æ¨¡æ‹Ÿé…ç½®
from polarization_triangle.core.config import SimulationConfig

custom_base = SimulationConfig(
    num_agents=300,                    # Agentæ•°é‡
    network_type='lfr',               # ç½‘ç»œç±»å‹
    morality_rate=0.6,                # é“å¾·åŒ–ç‡
    opinion_distribution='twin_peak',  # åˆå§‹æ„è§åˆ†å¸ƒ
    network_params={
        'tau1': 3, 'tau2': 1.5, 'mu': 0.1,
        'average_degree': 6, 'min_community': 15
    }
)

# åˆ›å»ºæ•æ„Ÿæ€§åˆ†æé…ç½®
config = SobolConfig(
    base_config=custom_base,
    n_samples=800,
    n_runs=4,
    parameter_bounds={              # è‡ªå®šä¹‰å‚æ•°èŒƒå›´
        'alpha': [0.2, 0.7],
        'beta': [0.08, 0.25],
        'gamma': [0.5, 1.8],
        'cohesion_factor': [0.1, 0.4]
    },
    output_dir="custom_analysis"
)
```

### é«˜çº§é…ç½®é€‰é¡¹

```python
config = SobolConfig(
    # æ ¸å¿ƒå‚æ•°
    n_samples=1000,
    n_runs=5,
    n_processes=6,
    
    # æ¨¡æ‹Ÿæ§åˆ¶
    num_steps=250,
    save_intermediate=True,        # ä¿å­˜ä¸­é—´ç»“æœ
    
    # è¾“å‡ºæ§åˆ¶
    output_dir="advanced_analysis",
    export_raw_data=True,         # å¯¼å‡ºåŸå§‹æ•°æ®
    
    # è´¨é‡æ§åˆ¶
    validate_results=True,        # ç»“æœéªŒè¯
    confidence_level=0.95,        # ç½®ä¿¡åŒºé—´
    
    # æ€§èƒ½è°ƒä¼˜
    chunk_size=100,               # æ‰¹å¤„ç†å¤§å°
    memory_limit=8,               # å†…å­˜é™åˆ¶(GB)
)
```

## è¾“å‡ºæŒ‡æ ‡è¯¦è§£

### æåŒ–ç›¸å…³æŒ‡æ ‡

#### 1. polarization_index (KoudenburgæåŒ–æŒ‡æ•°)
- **è®¡ç®—æ–¹æ³•**: åŸºäº5ç±»æ„è§åˆ†å¸ƒçš„æ ‡å‡†åŒ–æåŒ–åº¦é‡
- **å–å€¼èŒƒå›´**: [0, âˆ)ï¼Œ0è¡¨ç¤ºå®Œå…¨ä¸€è‡´ï¼Œå€¼è¶Šå¤§æåŒ–è¶Šä¸¥é‡
- **è§£é‡Š**: åæ˜ ç³»ç»Ÿæ•´ä½“çš„æ„è§ä¸¤æåŒ–ç¨‹åº¦

#### 2. opinion_variance (æ„è§æ–¹å·®)
- **è®¡ç®—æ–¹æ³•**: `np.var(opinions)`
- **å–å€¼èŒƒå›´**: [0, 1]
- **è§£é‡Š**: ç›´æ¥åº¦é‡æ„è§åˆ†æ•£ç¨‹åº¦ï¼Œå€¼è¶Šå¤§åˆ†æ­§è¶Šå¤§

#### 3. extreme_ratio (æç«¯è§‚ç‚¹æ¯”ä¾‹)
- **è®¡ç®—æ–¹æ³•**: `|opinion| > 0.8` çš„Agentæ¯”ä¾‹
- **å–å€¼èŒƒå›´**: [0, 1]
- **è§£é‡Š**: æŒæœ‰æç«¯è§‚ç‚¹çš„Agentå æ¯”

#### 4. identity_polarization (èº«ä»½é—´æåŒ–å·®å¼‚)
- **è®¡ç®—æ–¹æ³•**: ä¸åŒèº«ä»½ç¾¤ä½“é—´æ„è§å·®å¼‚çš„æ–¹å·®
- **è§£é‡Š**: åæ˜ èº«ä»½è®¤åŒå¯¹æåŒ–çš„å½±å“

### æ”¶æ•›ç›¸å…³æŒ‡æ ‡

#### 5. mean_abs_opinion (å¹³å‡ç»å¯¹æ„è§)
- **è®¡ç®—æ–¹æ³•**: `np.mean(np.abs(opinions))`
- **å–å€¼èŒƒå›´**: [0, 1]
- **è§£é‡Š**: ç³»ç»Ÿæ•´ä½“çš„æ„è§å¼ºåº¦ï¼Œåæ˜ "æ²‰é»˜èºæ—‹"ç°è±¡

#### 6. final_stability (æœ€ç»ˆç¨³å®šæ€§)
- **è®¡ç®—æ–¹æ³•**: æœ€å10%æ­¥æ•°å†…çš„å˜å¼‚ç³»æ•°
- **è§£é‡Š**: ç³»ç»Ÿè¾¾åˆ°å¹³è¡¡çŠ¶æ€çš„ç¨³å®šç¨‹åº¦

### åŠ¨æ€è¿‡ç¨‹æŒ‡æ ‡

#### 7. trajectory_length (æ„è§è½¨è¿¹é•¿åº¦)
- **è®¡ç®—æ–¹æ³•**: æ‰€æœ‰Agentæ„è§å˜åŒ–è·ç¦»çš„ç´¯ç§¯
- **è§£é‡Š**: åæ˜ ç³»ç»ŸåŠ¨æ€å˜åŒ–çš„å¤æ‚ç¨‹åº¦

#### 8. oscillation_frequency (æŒ¯è¡é¢‘ç‡)
- **è®¡ç®—æ–¹æ³•**: æ„è§æ–¹å‘æ”¹å˜æ¬¡æ•°çš„å¹³å‡å€¼
- **è§£é‡Š**: è¡¡é‡ç³»ç»Ÿçš„åŠ¨æ€ä¸ç¨³å®šæ€§

#### 9. group_divergence (ç¾¤ä½“åˆ†åŒ–åº¦)
- **è®¡ç®—æ–¹æ³•**: ä¸åŒç¾¤ä½“æ„è§çš„KLæ•£åº¦
- **è§£é‡Š**: é‡åŒ–ç¾¤ä½“é—´çš„æ„è§åˆ†åŒ–ç¨‹åº¦

### èº«ä»½ç›¸å…³æŒ‡æ ‡

#### 10. identity_variance_ratio (èº«ä»½æ–¹å·®æ¯”)
- **è®¡ç®—æ–¹æ³•**: ç»„é—´æ–¹å·® / ç»„å†…æ–¹å·®
- **è§£é‡Š**: èº«ä»½è®¤åŒå¯¹æ„è§å½¢æˆçš„å½±å“å¼ºåº¦

#### 11. cross_identity_correlation (è·¨èº«ä»½ç›¸å…³æ€§)
- **è®¡ç®—æ–¹æ³•**: ä¸åŒèº«ä»½ç¾¤ä½“æ„è§çš„ç›¸å…³ç³»æ•°
- **è§£é‡Š**: èº«ä»½è¾¹ç•Œçš„æ¸—é€æ€§

### Variance Per Identity æŒ‡æ ‡ (æ–°å¢)

#### 12. variance_per_identity_1 (èº«ä»½ç¾¤ä½“1æ–¹å·®)
- **è®¡ç®—æ–¹æ³•**: `np.var(identity_1_opinions)` (æ’é™¤zealot)
- **å–å€¼èŒƒå›´**: [0, 1]
- **è§£é‡Š**: identity=1ç¾¤ä½“å†…éƒ¨çš„æ„è§åˆ†åŒ–ç¨‹åº¦ï¼Œé«˜å€¼è¡¨ç¤ºç¾¤ä½“å†…éƒ¨æ„è§åˆ†æ­§è¾ƒå¤§

#### 13. variance_per_identity_neg1 (èº«ä»½ç¾¤ä½“-1æ–¹å·®)
- **è®¡ç®—æ–¹æ³•**: `np.var(identity_neg1_opinions)` (æ’é™¤zealot)
- **å–å€¼èŒƒå›´**: [0, 1]
- **è§£é‡Š**: identity=-1ç¾¤ä½“å†…éƒ¨çš„æ„è§åˆ†åŒ–ç¨‹åº¦ï¼Œé«˜å€¼è¡¨ç¤ºç¾¤ä½“å†…éƒ¨æ„è§åˆ†æ­§è¾ƒå¤§

#### 14. variance_per_identity_mean (èº«ä»½ç¾¤ä½“å¹³å‡æ–¹å·®)
- **è®¡ç®—æ–¹æ³•**: `(variance_identity_1 + variance_identity_neg1) / 2`
- **å–å€¼èŒƒå›´**: [0, 1]
- **è§£é‡Š**: ä¸¤ä¸ªèº«ä»½ç¾¤ä½“æ–¹å·®çš„å‡å€¼ï¼Œåæ˜ ç³»ç»Ÿæ•´ä½“çš„ç¾¤ä½“å†…éƒ¨åˆ†åŒ–æ°´å¹³

## å¯è§†åŒ–åŠŸèƒ½

### è‡ªåŠ¨ç”Ÿæˆçš„å›¾è¡¨ç±»å‹

#### 1. æ•æ„Ÿæ€§æŒ‡æ•°å¯¹æ¯”å›¾
- **æ–‡ä»¶å**: `sensitivity_comparison_*.png`
- **å†…å®¹**: S1å’ŒSTçš„æ¡å½¢å›¾å¯¹æ¯”
- **ç”¨é€”**: ç›´è§‚æ¯”è¾ƒå‚æ•°çš„ä¸»æ•ˆåº”å’Œæ€»æ•ˆåº”

#### 2. æ•æ„Ÿæ€§çƒ­åŠ›å›¾
- **æ–‡ä»¶å**: `sensitivity_heatmap_*.png`
- **å†…å®¹**: å‚æ•°-æŒ‡æ ‡æ•æ„Ÿæ€§çŸ©é˜µ
- **ç”¨é€”**: è¯†åˆ«å‚æ•°-æŒ‡æ ‡çš„æ•æ„Ÿæ€§æ¨¡å¼

#### 3. äº¤äº’æ•ˆåº”åˆ†æå›¾
- **æ–‡ä»¶å**: `interaction_effects.png`
- **å†…å®¹**: ST-S1çš„å¯è§†åŒ–å±•ç¤º
- **ç”¨é€”**: è¯†åˆ«å¼ºäº¤äº’æ•ˆåº”çš„å‚æ•°

#### 4. å‚æ•°é‡è¦æ€§æ’åºå›¾
- **æ–‡ä»¶å**: `parameter_ranking_*.png`
- **å†…å®¹**: æŒ‰æ•æ„Ÿæ€§æ’åºçš„å‚æ•°é‡è¦æ€§
- **ç”¨é€”**: ä¸ºå‚æ•°è°ƒä¼˜æä¾›ä¼˜å…ˆçº§æŒ‡å¯¼

### å¯è§†åŒ–è‡ªå®šä¹‰

```python
from polarization_triangle.analysis import SensitivityVisualizer

visualizer = SensitivityVisualizer()

# åˆ›å»ºå•ä¸ªå›¾è¡¨
fig = visualizer.plot_sensitivity_comparison(
    sensitivity_indices, 
    'polarization_index',
    save_path='custom_comparison.png',
    figsize=(12, 8),
    dpi=300
)

# æ‰¹é‡ç”ŸæˆæŠ¥å‘Š
plot_files = visualizer.create_comprehensive_report(
    sensitivity_indices,
    param_samples,
    simulation_results,
    output_dir='custom_plots'
)
```

## é«˜çº§ç”¨æ³•

### æ‰¹é‡åœºæ™¯åˆ†æ

```python
scenarios = {
    'high_morality': {'morality_rate': 0.8},
    'low_morality': {'morality_rate': 0.2},
    'large_network': {'num_agents': 500},
    'dense_network': {'network_params': {'average_degree': 8}}
}

results = {}
for scenario_name, params in scenarios.items():
    base_config = SimulationConfig(**params)
    config = SobolConfig(
        base_config=base_config,
        n_samples=300,
        output_dir=f"scenario_{scenario_name}"
    )
    
    analyzer = SobolAnalyzer(config)
    results[scenario_name] = analyzer.run_complete_analysis()

# æ¯”è¾ƒä¸åŒåœºæ™¯çš„æ•æ„Ÿæ€§æ¨¡å¼
compare_scenarios(results)
```

### è‡ªå®šä¹‰æŒ‡æ ‡

```python
from polarization_triangle.analysis import SensitivityMetrics

class ExtendedMetrics(SensitivityMetrics):
    def __init__(self):
        super().__init__()
        self.metric_names.extend(['custom_metric1', 'custom_metric2'])
    
    def _calculate_custom_metric1(self, sim):
        """è‡ªå®šä¹‰æŒ‡æ ‡1: æ„è§é›†ä¸­åº¦"""
        return 1 - np.std(sim.opinions)
    
    def _calculate_custom_metric2(self, sim):
        """è‡ªå®šä¹‰æŒ‡æ ‡2: ç½‘ç»œæåŒ–åº¦"""
        return calculate_network_polarization(sim)
    
    def calculate_all_metrics(self, sim):
        metrics = super().calculate_all_metrics(sim)
        metrics['custom_metric1'] = self._calculate_custom_metric1(sim)
        metrics['custom_metric2'] = self._calculate_custom_metric2(sim)
        return metrics

# ä½¿ç”¨è‡ªå®šä¹‰æŒ‡æ ‡
config.custom_metrics_class = ExtendedMetrics
```

### ç»“æœåå¤„ç†ä¸åˆ†æ

```python
# åŠ è½½å·²æœ‰ç»“æœ
analyzer = SobolAnalyzer(config)
sensitivity_indices = analyzer.load_results("existing_results")

# ç»Ÿè®¡åˆ†æ
import numpy as np

# è¯†åˆ«é«˜æ•æ„Ÿæ€§å‚æ•°
high_sensitivity_params = []
for output_name, indices in sensitivity_indices.items():
    for i, param in enumerate(['alpha', 'beta', 'gamma', 'cohesion_factor']):
        if indices['ST'][i] > 0.2:  # æ•æ„Ÿæ€§é˜ˆå€¼
            high_sensitivity_params.append((param, output_name, indices['ST'][i]))

# å‚æ•°é‡è¦æ€§èšç±»åˆ†æ
from sklearn.cluster import KMeans

# æå–æ•æ„Ÿæ€§çŸ©é˜µ
sensitivity_matrix = np.array([indices['ST'] for indices in sensitivity_indices.values()])

# èšç±»åˆ†ææ‰¾å‡ºç›¸ä¼¼çš„æ•æ„Ÿæ€§æ¨¡å¼
kmeans = KMeans(n_clusters=3)
clusters = kmeans.fit_predict(sensitivity_matrix.T)  # å¯¹å‚æ•°èšç±»

print("å‚æ•°èšç±»ç»“æœ:")
param_names = ['alpha', 'beta', 'gamma', 'cohesion_factor']
for i, cluster in enumerate(clusters):
    print(f"{param_names[i]}: èšç±»{cluster}")
```

## æ€§èƒ½ä¼˜åŒ–

### è®¡ç®—èµ„æºä¼˜åŒ–

```python
# æ ¹æ®ç³»ç»Ÿé…ç½®è‡ªåŠ¨è°ƒæ•´
import multiprocessing as mp
import psutil

def optimize_config(base_config: SobolConfig) -> SobolConfig:
    """æ ¹æ®ç³»ç»Ÿèµ„æºè‡ªåŠ¨ä¼˜åŒ–é…ç½®"""
    
    # CPUä¼˜åŒ–
    cpu_count = mp.cpu_count()
    base_config.n_processes = min(cpu_count - 1, base_config.n_processes)
    
    # å†…å­˜ä¼˜åŒ–
    available_memory = psutil.virtual_memory().available / (1024**3)  # GB
    if available_memory < 8:
        base_config.n_processes = max(2, base_config.n_processes // 2)
        base_config.chunk_size = 50
    
    # æ‰¹æ¬¡å¤§å°ä¼˜åŒ–
    total_samples = base_config.n_samples * 10  # Saltellié‡‡æ ·
    if total_samples > 10000:
        base_config.save_intermediate = True
    
    return base_config

# åº”ç”¨ä¼˜åŒ–
config = optimize_config(config)
```

### å†…å­˜ç®¡ç†

```python
# å¤§è§„æ¨¡åˆ†æçš„å†…å­˜ä¼˜åŒ–ç­–ç•¥
config = SobolConfig(
    n_samples=5000,
    chunk_size=200,           # åˆ†æ‰¹å¤„ç†
    save_intermediate=True,   # ä¿å­˜ä¸­é—´ç»“æœ
    clear_cache=True,         # æ¸…ç†ç¼“å­˜
    memory_limit=12,          # å†…å­˜é™åˆ¶
)

# æ‰‹åŠ¨å†…å­˜ç®¡ç†
import gc

def memory_efficient_analysis(config):
    analyzer = SobolAnalyzer(config)
    
    # åˆ†é˜¶æ®µæ‰§è¡Œ
    param_samples = analyzer.generate_samples()
    gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
    
    simulation_results = analyzer.run_simulations_batch(param_samples)
    del param_samples
    gc.collect()
    
    sensitivity_indices = analyzer.calculate_sensitivity(simulation_results)
    del simulation_results
    gc.collect()
    
    return sensitivity_indices
```

### åˆ†å¸ƒå¼è®¡ç®—

```python
# ä¸ºè¶…å¤§è§„æ¨¡åˆ†æå‡†å¤‡çš„åˆ†å¸ƒå¼æ–¹æ¡ˆ
from concurrent.futures import ProcessPoolExecutor, as_completed

def distributed_analysis(config, n_workers=None):
    """åˆ†å¸ƒå¼æ•æ„Ÿæ€§åˆ†æ"""
    
    if n_workers is None:
        n_workers = min(8, mp.cpu_count())
    
    # å°†æ ·æœ¬åˆ†å‰²ä¸ºå¤šä¸ªå­ä»»åŠ¡
    total_samples = config.n_samples
    samples_per_worker = total_samples // n_workers
    
    tasks = []
    for i in range(n_workers):
        worker_config = config.copy()
        worker_config.n_samples = samples_per_worker
        worker_config.output_dir = f"{config.output_dir}_worker_{i}"
        tasks.append(worker_config)
    
    # å¹¶è¡Œæ‰§è¡Œ
    results = []
    with ProcessPoolExecutor(max_workers=n_workers) as executor:
        futures = [executor.submit(run_worker_analysis, task) for task in tasks]
        
        for future in as_completed(futures):
            results.append(future.result())
    
    # åˆå¹¶ç»“æœ
    return merge_sensitivity_results(results)

def run_worker_analysis(config):
    """å•ä¸ªå·¥ä½œè¿›ç¨‹çš„åˆ†æä»»åŠ¡"""
    analyzer = SobolAnalyzer(config)
    return analyzer.run_complete_analysis()
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### âœ… å·²ä¿®å¤çš„é—®é¢˜

##### 1. æ¨¡æ‹Ÿè¿è¡Œé”™è¯¯
**ç—‡çŠ¶**: `'Simulation' object has no attribute 'run'`
**è§£å†³æ–¹æ¡ˆ**: å·²ä¿®å¤ï¼Œç°ä½¿ç”¨ `sim.step()` å¾ªç¯

##### 2. Excelå¯¼å‡ºå¤±è´¥
**ç—‡çŠ¶**: `No module named 'openpyxl'`
**è§£å†³æ–¹æ¡ˆ**: å·²æ·»åŠ åˆ°ä¾èµ–ï¼Œè¿è¡Œ `pip install openpyxl`

##### 3. å›¾å½¢ç•Œé¢å¡ä½
**ç—‡çŠ¶**: ç¨‹åºåœ¨å¯è§†åŒ–é˜¶æ®µé•¿æ—¶é—´æ— å“åº”
**è§£å†³æ–¹æ¡ˆ**: å·²ç§»é™¤ `plt.show()`ï¼Œåªä¿å­˜å›¾ç‰‡æ–‡ä»¶

##### 4. ä¸­æ–‡å­—ä½“è­¦å‘Š
**ç—‡çŠ¶**: å¤§é‡å­—ä½“è­¦å‘Šä¿¡æ¯
**è§£å†³æ–¹æ¡ˆ**: å›¾è¡¨æ ‡ç­¾æ”¹ä¸ºè‹±æ–‡ï¼Œæé«˜å…¼å®¹æ€§

#### ğŸ”§ å½“å‰å¯èƒ½çš„é—®é¢˜

##### 5. å†…å­˜ä¸è¶³
**ç—‡çŠ¶**: `MemoryError` æˆ–ç³»ç»Ÿå†…å­˜è€—å°½
**è§£å†³æ–¹æ¡ˆ**:
```python
# å‡å°‘èµ„æºæ¶ˆè€—
config = SobolConfig(
    n_samples=200,        # å‡å°‘æ ·æœ¬æ•°
    n_processes=2,        # å‡å°‘å¹¶è¡Œè¿›ç¨‹
    chunk_size=50,        # åˆ†æ‰¹å¤„ç†
    save_intermediate=True
)

# åŸºç¡€é…ç½®ä¼˜åŒ–
base_config = SimulationConfig(
    num_agents=150,       # å‡å°‘Agentæ•°é‡
    num_steps=150         # å‡å°‘æ¨¡æ‹Ÿæ­¥æ•°
)
```

##### 6. è®¡ç®—æ—¶é—´è¿‡é•¿
**ç—‡çŠ¶**: åˆ†ææ—¶é—´è¿œè¶…é¢„æœŸ
**è¯Šæ–­ä¸è§£å†³**:
```python
# æ—¶é—´ä¼°ç®—å‡½æ•°
def estimate_time(config):
    """ä¼°ç®—è®¡ç®—æ—¶é—´"""
    total_sims = config.n_samples * 10 * config.n_runs
    time_per_sim = 2  # ç§’ï¼Œæ ¹æ®ç³»ç»Ÿè°ƒæ•´
    estimated_hours = (total_sims * time_per_sim) / (3600 * config.n_processes)
    
    print(f"é¢„è®¡è¿è¡Œæ—¶é—´: {estimated_hours:.1f} å°æ—¶")
    print(f"æ€»æ¨¡æ‹Ÿæ¬¡æ•°: {total_sims:,}")
    print(f"å¹¶è¡Œè¿›ç¨‹æ•°: {config.n_processes}")
    
    return estimated_hours

# ä½¿ç”¨å‰è¯„ä¼°
estimate_time(config)

# å¦‚æœæ—¶é—´è¿‡é•¿ï¼Œä½¿ç”¨æ¸è¿›å¼åˆ†æ
progressive_configs = [
    SobolConfig(n_samples=50, output_dir="test_50"),
    SobolConfig(n_samples=200, output_dir="test_200"),
    SobolConfig(n_samples=500, output_dir="test_500")
]

for config in progressive_configs:
    if estimate_time(config) < 1:  # å°äº1å°æ—¶
        analyzer = SobolAnalyzer(config)
        results = analyzer.run_complete_analysis()
        # æ£€æŸ¥ç»“æœç¨³å®šæ€§å†å†³å®šæ˜¯å¦ç»§ç»­
```

##### 7. æ•æ„Ÿæ€§ç»“æœå¼‚å¸¸
**ç—‡çŠ¶**: ST < S1, å…¨é›¶å€¼, æˆ–å¼‚å¸¸é«˜å€¼
**è¯Šæ–­æ­¥éª¤**:
```python
def diagnose_results(sensitivity_indices):
    """è¯Šæ–­æ•æ„Ÿæ€§ç»“æœ"""
    issues = []
    
    for output_name, indices in sensitivity_indices.items():
        s1_values = np.array(indices['S1'])
        st_values = np.array(indices['ST'])
        
        # æ£€æŸ¥ST >= S1å…³ç³»
        if np.any(st_values < s1_values - 0.05):  # å…è®¸å°è¯¯å·®
            issues.append(f"{output_name}: ST < S1")
        
        # æ£€æŸ¥é›¶å€¼
        if np.all(s1_values < 0.01) and np.all(st_values < 0.01):
            issues.append(f"{output_name}: æ‰€æœ‰æ•æ„Ÿæ€§æ¥è¿‘é›¶")
        
        # æ£€æŸ¥å¼‚å¸¸å€¼
        if np.any(st_values > 2):
            issues.append(f"{output_name}: å¼‚å¸¸é«˜æ•æ„Ÿæ€§å€¼")
    
    if issues:
        print("å‘ç°çš„é—®é¢˜:")
        for issue in issues:
            print(f"  - {issue}")
        
        print("\nå»ºè®®è§£å†³æ–¹æ¡ˆ:")
        print("  1. å¢åŠ æ ·æœ¬æ•°é‡")
        print("  2. æ£€æŸ¥å‚æ•°èŒƒå›´è®¾ç½®")
        print("  3. éªŒè¯åŸºç¡€æ¨¡æ‹Ÿé…ç½®")
        print("  4. å¢åŠ è¿è¡Œæ¬¡æ•°å‡å°‘éšæœºæ€§")
    else:
        print("âœ… æ•æ„Ÿæ€§ç»“æœé€šè¿‡åŸºç¡€æ£€æŸ¥")

# ä½¿ç”¨è¯Šæ–­å·¥å…·
diagnose_results(sensitivity_indices)
```

### è°ƒè¯•æ¨¡å¼

```python
# è¯¦ç»†è°ƒè¯•é…ç½®
debug_config = SobolConfig(
    n_samples=10,             # æœ€å°æ ·æœ¬
    n_runs=1,                 # å•æ¬¡è¿è¡Œ
    num_steps=20,             # çŸ­æ¨¡æ‹Ÿ
    n_processes=1,            # å•è¿›ç¨‹ä¾¿äºè°ƒè¯•
    output_dir="debug_test",
    verbose=True              # è¯¦ç»†è¾“å‡º
)

# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# é€æ­¥è°ƒè¯•
try:
    print("1. åˆ›å»ºåˆ†æå™¨...")
    analyzer = SobolAnalyzer(debug_config)
    
    print("2. ç”Ÿæˆæ ·æœ¬...")
    param_samples = analyzer.generate_samples()
    print(f"   æ ·æœ¬å½¢çŠ¶: {param_samples.shape}")
    
    print("3. è¿è¡Œå•ä¸ªæ¨¡æ‹Ÿæµ‹è¯•...")
    test_params = {
        'alpha': 0.4, 'beta': 0.12, 
        'gamma': 1.0, 'cohesion_factor': 0.2
    }
    test_result = analyzer.run_single_simulation(test_params)
    print(f"   æµ‹è¯•ç»“æœ: {test_result}")
    
    print("4. è¿è¡Œå®Œæ•´åˆ†æ...")
    results = analyzer.run_complete_analysis()
    print("âœ… è°ƒè¯•æˆåŠŸ")
    
except Exception as e:
    print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
```

## æœ€ä½³å®è·µ

### åˆ†ææµç¨‹å»ºè®®

#### 1. å‡†å¤‡é˜¶æ®µ
```python
# ç¯å¢ƒæ£€æŸ¥
def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    import sys, psutil, multiprocessing as mp
    
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"å¯ç”¨å†…å­˜: {psutil.virtual_memory().available / (1024**3):.1f} GB")
    print(f"CPUæ ¸å¿ƒæ•°: {mp.cpu_count()}")
    
    # æ£€æŸ¥å…³é”®ä¾èµ–
    try:
        import SALib, seaborn, pandas, openpyxl
        print("âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…")
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")

check_environment()
```

#### 2. æ¢ç´¢æ€§åˆ†æ
```python
# ç¬¬ä¸€æ­¥ï¼šå¿«é€Ÿæ¢ç´¢
quick_config = SobolConfig(
    n_samples=50,
    n_runs=2,
    output_dir="exploration"
)

analyzer = SobolAnalyzer(quick_config)
initial_results = analyzer.run_complete_analysis()

# æŸ¥çœ‹ç»“æœæ¨¡å¼
print_key_findings(initial_results)
```

#### 3. æ·±å…¥åˆ†æ
```python
# åŸºäºåˆæ­¥ç»“æœè®¾è®¡æ·±å…¥åˆ†æ
if looks_promising(initial_results):
    standard_config = SobolConfig(
        n_samples=500,
        n_runs=5,
        output_dir="detailed_analysis"
    )
    
    analyzer = SobolAnalyzer(standard_config)
    detailed_results = analyzer.run_complete_analysis()
```

#### 4. éªŒè¯ä¸å‘å¸ƒ
```python
# é«˜ç²¾åº¦éªŒè¯
final_config = SobolConfig(
    n_samples=1000,
    n_runs=10,
    output_dir="final_results"
)

final_analyzer = SobolAnalyzer(final_config)
final_results = final_analyzer.run_complete_analysis()

# ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
final_analyzer.export_results(include_confidence_intervals=True)
```

### å‚æ•°è®¾ç½®æŒ‡å—

#### æ ·æœ¬æ•°é€‰æ‹©
- **n_samples = 50**: å¿«é€Ÿæµ‹è¯•å’Œè°ƒè¯•
- **n_samples = 200-500**: ä¸€èˆ¬ç ”ç©¶å’Œåˆ†æ
- **n_samples = 1000**: é«˜ç²¾åº¦ç ”ç©¶
- **n_samples = 2000+**: è®ºæ–‡å‘è¡¨çº§åˆ†æ

#### è¿è¡Œæ¬¡æ•°é€‰æ‹©
- **n_runs = 2**: è°ƒè¯•å’Œå¿«é€Ÿæµ‹è¯•
- **n_runs = 3-5**: æ ‡å‡†åˆ†æ
- **n_runs = 10+**: é«˜ç²¾åº¦åˆ†æï¼Œå‡å°‘éšæœºæ€§

#### è¿›ç¨‹æ•°ä¼˜åŒ–
```python
import multiprocessing as mp

# ä¿å®ˆç­–ç•¥ï¼šç•™ä¸€ä¸ªæ ¸å¿ƒç»™ç³»ç»Ÿ
n_processes = max(1, mp.cpu_count() - 1)

# å†…å­˜å—é™ç­–ç•¥
available_memory_gb = psutil.virtual_memory().available / (1024**3)
if available_memory_gb < 8:
    n_processes = min(n_processes, 2)
elif available_memory_gb < 16:
    n_processes = min(n_processes, 4)

config.n_processes = n_processes
```

### ç»“æœè§£é‡ŠæŒ‡å—

#### æ•æ„Ÿæ€§ç­‰çº§åˆ’åˆ†
```python
def interpret_sensitivity(st_value):
    """è§£é‡Šæ•æ„Ÿæ€§ç­‰çº§"""
    if st_value > 0.3:
        return "æé«˜æ•æ„Ÿæ€§ - å…³é”®å‚æ•°"
    elif st_value > 0.15:
        return "é«˜æ•æ„Ÿæ€§ - é‡è¦å‚æ•°"
    elif st_value > 0.05:
        return "ä¸­ç­‰æ•æ„Ÿæ€§ - æ¬¡è¦å‚æ•°"
    else:
        return "ä½æ•æ„Ÿæ€§ - å¯å¿½ç•¥å‚æ•°"

# åº”ç”¨åˆ°ç»“æœ
for output_name, indices in sensitivity_indices.items():
    print(f"\n{output_name}:")
    param_names = ['Î±', 'Î²', 'Î³', 'cohesion_factor']
    for i, (param, st) in enumerate(zip(param_names, indices['ST'])):
        level = interpret_sensitivity(st)
        print(f"  {param}: {st:.3f} - {level}")
```

#### äº¤äº’æ•ˆåº”åˆ†æ
```python
def analyze_interactions(sensitivity_indices):
    """åˆ†æå‚æ•°äº¤äº’æ•ˆåº”"""
    param_names = ['Î±', 'Î²', 'Î³', 'cohesion_factor']
    
    interaction_matrix = []
    for output_name, indices in sensitivity_indices.items():
        interactions = np.array(indices['ST']) - np.array(indices['S1'])
        interaction_matrix.append(interactions)
    
    mean_interactions = np.mean(interaction_matrix, axis=0)
    
    print("å¹³å‡äº¤äº’æ•ˆåº”å¼ºåº¦:")
    for param, interaction in zip(param_names, mean_interactions):
        if interaction > 0.1:
            level = "å¼º"
        elif interaction > 0.05:
            level = "ä¸­ç­‰"
        else:
            level = "å¼±"
        print(f"  {param}: {interaction:.3f} ({level})")

analyze_interactions(sensitivity_indices)
```

### è´¨é‡ä¿è¯

#### ç»“æœéªŒè¯
```python
def validate_analysis_quality(analyzer, sensitivity_indices):
    """éªŒè¯åˆ†æè´¨é‡"""
    checks = []
    
    # 1. æ ·æœ¬å……è¶³æ€§æ£€æŸ¥
    if analyzer.config.n_samples < 100:
        checks.append("è­¦å‘Š: æ ·æœ¬æ•°é‡å¯èƒ½ä¸è¶³")
    
    # 2. æ”¶æ•›æ€§æ£€æŸ¥
    # ï¼ˆéœ€è¦å¤šæ¬¡è¿è¡Œæ¯”è¾ƒï¼Œè¿™é‡Œç®€åŒ–ï¼‰
    
    # 3. ä¸€è‡´æ€§æ£€æŸ¥
    for output_name, indices in sensitivity_indices.items():
        s1_sum = sum(indices['S1'])
        if s1_sum > 1.2:  # å…è®¸ä¸€äº›è¯¯å·®
            checks.append(f"è­¦å‘Š: {output_name}çš„S1æ€»å’Œè¿‡é«˜ ({s1_sum:.2f})")
    
    # 4. ç½®ä¿¡åŒºé—´æ£€æŸ¥
    if hasattr(analyzer, 'confidence_intervals'):
        # æ£€æŸ¥ç½®ä¿¡åŒºé—´å®½åº¦
        pass
    
    if checks:
        print("è´¨é‡æ£€æŸ¥å‘ç°çš„é—®é¢˜:")
        for check in checks:
            print(f"  - {check}")
    else:
        print("âœ… åˆ†æè´¨é‡æ£€æŸ¥é€šè¿‡")

validate_analysis_quality(analyzer, sensitivity_indices)
```

## APIå‚è€ƒ

### SobolConfigç±»

```python
class SobolConfig:
    """Sobolæ•æ„Ÿæ€§åˆ†æé…ç½®ç±»"""
    
    def __init__(self,
                 parameter_bounds: Dict[str, List[float]] = None,
                 n_samples: int = 1000,
                 n_runs: int = 5,
                 n_processes: int = 4,
                 num_steps: int = 200,
                 output_dir: str = "sobol_results",
                 save_intermediate: bool = True,
                 base_config: SimulationConfig = None):
        """
        å‚æ•°:
            parameter_bounds: å‚æ•°å–å€¼èŒƒå›´å­—å…¸
            n_samples: Saltellié‡‡æ ·çš„åŸºç¡€æ ·æœ¬æ•°
            n_runs: æ¯ä¸ªå‚æ•°ç»„åˆçš„é‡å¤è¿è¡Œæ¬¡æ•°
            n_processes: å¹¶è¡Œè¿›ç¨‹æ•°
            num_steps: æ¯æ¬¡æ¨¡æ‹Ÿçš„æ­¥æ•°
            output_dir: ç»“æœè¾“å‡ºç›®å½•
            save_intermediate: æ˜¯å¦ä¿å­˜ä¸­é—´ç»“æœ
            base_config: åŸºç¡€æ¨¡æ‹Ÿé…ç½®
        """
```

### SobolAnalyzerç±»

```python
class SobolAnalyzer:
    """Sobolæ•æ„Ÿæ€§åˆ†æå™¨"""
    
    def __init__(self, config: SobolConfig):
        """åˆå§‹åŒ–åˆ†æå™¨"""
    
    def generate_samples(self) -> np.ndarray:
        """ç”ŸæˆSaltelliæ ·æœ¬"""
    
    def run_single_simulation(self, params: Dict[str, float]) -> Dict[str, float]:
        """è¿è¡Œå•æ¬¡æ¨¡æ‹Ÿ"""
    
    def run_simulations(self, param_samples: np.ndarray) -> List[Dict[str, float]]:
        """å¹¶è¡Œè¿è¡Œå¤šæ¬¡æ¨¡æ‹Ÿ"""
    
    def calculate_sensitivity(self, simulation_results: List[Dict[str, float]]) -> Dict[str, Dict]:
        """è®¡ç®—æ•æ„Ÿæ€§æŒ‡æ•°"""
    
    def run_complete_analysis(self) -> Dict[str, Dict]:
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
    
    def get_summary_table(self) -> pd.DataFrame:
        """è·å–ç»“æœæ‘˜è¦è¡¨"""
    
    def export_results(self, filename: str = None) -> str:
        """å¯¼å‡ºExcelç»“æœ"""
    
    def save_results(self, filename: str = None) -> str:
        """ä¿å­˜ç»“æœåˆ°pickleæ–‡ä»¶"""
    
    def load_results(self, filename: str = None) -> Dict[str, Dict]:
        """åŠ è½½å·²ä¿å­˜çš„ç»“æœ"""
```

### SensitivityVisualizerç±»

```python
class SensitivityVisualizer:
    """æ•æ„Ÿæ€§åˆ†æå¯è§†åŒ–å™¨"""
    
    def plot_sensitivity_comparison(self, 
                                  sensitivity_indices: Dict,
                                  output_name: str,
                                  save_path: str = None) -> plt.Figure:
        """ç»˜åˆ¶æ•æ„Ÿæ€§æŒ‡æ•°å¯¹æ¯”å›¾"""
    
    def plot_sensitivity_heatmap(self,
                               sensitivity_indices: Dict,
                               metric_type: str = 'ST',
                               save_path: str = None) -> plt.Figure:
        """ç»˜åˆ¶æ•æ„Ÿæ€§çƒ­åŠ›å›¾"""
    
    def plot_interaction_effects(self,
                               sensitivity_indices: Dict,
                               save_path: str = None) -> plt.Figure:
        """ç»˜åˆ¶äº¤äº’æ•ˆåº”å›¾"""
    
    def plot_parameter_ranking(self,
                             sensitivity_indices: Dict,
                             metric_type: str = 'ST',
                             save_path: str = None) -> plt.Figure:
        """ç»˜åˆ¶å‚æ•°é‡è¦æ€§æ’åºå›¾"""
    
    def create_comprehensive_report(self,
                                  sensitivity_indices: Dict,
                                  param_samples: np.ndarray,
                                  simulation_results: List,
                                  output_dir: str) -> List[str]:
        """åˆ›å»ºå®Œæ•´çš„å¯è§†åŒ–æŠ¥å‘Š"""
```

## æ›´æ–°æ—¥å¿—

### v1.1.0 (2024å¹´å½“å‰) - ğŸš€ ç¨³å®šæ€§å’Œå…¼å®¹æ€§å¤§å¹…æå‡

#### ğŸ”§ æ ¸å¿ƒä¿®å¤
- âœ… **æ¨¡æ‹Ÿè¿è¡Œä¿®å¤**: ä¿®å¤äº†`'Simulation' object has no attribute 'run'`é”™è¯¯ï¼Œæ”¹ç”¨ `sim.step()` å¾ªç¯
- âœ… **Excelå¯¼å‡ºæ”¯æŒ**: æ·»åŠ openpyxlä¾èµ–ï¼Œå®Œå…¨æ”¯æŒExcelç»“æœå¯¼å‡º
- âœ… **å›¾å½¢ç•Œé¢ä¼˜åŒ–**: ç§»é™¤æ‰€æœ‰ `plt.show()` è°ƒç”¨ï¼Œé¿å…ç¨‹åºå¡ä½ï¼Œåªä¿å­˜å›¾ç‰‡æ–‡ä»¶
- âœ… **å­—ä½“å…¼å®¹æ€§**: ä¼˜åŒ–ä¸­æ–‡å­—ä½“å¤„ç†ï¼Œå›¾è¡¨æ ‡ç­¾æ”¹ä¸ºè‹±æ–‡ï¼Œæé«˜è·¨å¹³å°å…¼å®¹æ€§

#### ğŸ“Š åŠŸèƒ½å¢å¼º
- ğŸ†• **æ–°å¢æŒ‡æ ‡**: æ·»åŠ 3ä¸ª Variance Per Identity æŒ‡æ ‡ï¼Œåˆ†æä¸åŒèº«ä»½ç¾¤ä½“å†…éƒ¨çš„æ„è§åˆ†åŒ–
  - `variance_per_identity_1`: identity=1ç¾¤ä½“çš„æ„è§æ–¹å·®
  - `variance_per_identity_neg1`: identity=-1ç¾¤ä½“çš„æ„è§æ–¹å·®
  - `variance_per_identity_mean`: ä¸¤ä¸ªç¾¤ä½“æ–¹å·®çš„å‡å€¼
- ğŸ†• **é¢„è®¾é…ç½®æ›´æ–°**: æ›´å‡†ç¡®çš„æ—¶é—´ä¼°ç®—å’Œèµ„æºé…ç½®
- ğŸ†• **é”™è¯¯è¯Šæ–­å·¥å…·**: æ–°å¢ç»“æœè´¨é‡éªŒè¯å’Œé—®é¢˜è¯Šæ–­åŠŸèƒ½
- ğŸ†• **æ€§èƒ½ç›‘æ§**: æ·»åŠ è¿›åº¦æ¡å’Œè¯¦ç»†çš„æ‰§è¡Œæ—¶é—´æŠ¥å‘Š
- ğŸ†• **å†…å­˜ä¼˜åŒ–**: æ”¹è¿›å¤§è§„æ¨¡åˆ†æçš„å†…å­˜ç®¡ç†

#### ğŸ¨ å¯è§†åŒ–æ”¹è¿›
- ğŸ¨ **é«˜è´¨é‡å›¾è¡¨**: é»˜è®¤300 DPIè¾“å‡ºï¼Œé€‚åˆè®ºæ–‡å‘è¡¨
- ğŸ¨ **è‹±æ–‡æ ‡ç­¾**: æ‰€æœ‰å›¾è¡¨æ ‡ç­¾æ”¹ä¸ºè‹±æ–‡ï¼Œæé«˜å›½é™…åŒ–å…¼å®¹æ€§
- ğŸ¨ **è‡ªåŠ¨å¸ƒå±€**: æ”¹è¿›å›¾è¡¨å¸ƒå±€å’Œé¢œè‰²æ–¹æ¡ˆ

#### ğŸ“š æ–‡æ¡£å®Œå–„
- ğŸ“– **å®Œæ•´ç¤ºä¾‹**: æ·»åŠ çœŸå®è¿è¡Œè¾“å‡ºç¤ºä¾‹å’Œæ–°æŒ‡æ ‡ä¸“é—¨ç¤ºä¾‹
- ğŸ“– **æ•…éšœæ’é™¤**: è¯¦ç»†çš„é—®é¢˜è¯Šæ–­å’Œè§£å†³æ–¹æ¡ˆ
- ğŸ“– **æœ€ä½³å®è·µ**: å…¨é¢çš„ä½¿ç”¨å»ºè®®å’Œä¼˜åŒ–æŒ‡å—
- ğŸ“– **æ–°æŒ‡æ ‡æ–‡æ¡£**: è¯¦ç»†è¯´æ˜ Variance Per Identity æŒ‡æ ‡çš„å«ä¹‰å’Œåº”ç”¨

### v1.0.0 (åˆå§‹ç‰ˆæœ¬)
- ğŸ¯ åŸºç¡€Sobolæ•æ„Ÿæ€§åˆ†æåŠŸèƒ½
- ğŸ“Š 11ç§æ ¸å¿ƒè¾“å‡ºæŒ‡æ ‡
- âš¡ å¹¶è¡Œè®¡ç®—æ”¯æŒ
- ğŸ¨ åŸºç¡€å¯è§†åŒ–åŠŸèƒ½
- ğŸ”§ 4ç§é¢„è®¾é…ç½®

---

## è”ç³»ä¸æ”¯æŒ

å¦‚æœæ‚¨åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œè¯·ï¼š

1. ğŸ“– é¦–å…ˆæŸ¥é˜…æœ¬æ–‡æ¡£çš„æ•…éšœæ’é™¤éƒ¨åˆ†
2. ğŸ§ª ä½¿ç”¨è°ƒè¯•æ¨¡å¼è¿›è¡Œé—®é¢˜è¯Šæ–­  
3. ğŸ’¬ æŸ¥çœ‹é¡¹ç›®çš„Issueé¡µé¢
4. ğŸš€ æäº¤è¯¦ç»†çš„BugæŠ¥å‘Šæˆ–åŠŸèƒ½è¯·æ±‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.1.0  
**æœ€åæ›´æ–°**: 2024å¹´12æœˆ  
**å…¼å®¹æ€§**: Python 3.8+, æåŒ–ä¸‰è§’æ¡†æ¶ v1.1+ 