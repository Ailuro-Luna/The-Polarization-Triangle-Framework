#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ•°æ®ç®¡ç†å·¥å…·æ¨¡å—
æä¾›æ•°æ®ä¿å­˜å’ŒåŠ è½½çš„å·¥å…·å‡½æ•°
"""

import os
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
import time
from pathlib import Path
import pickle
import json
from datetime import datetime


def save_trajectory_to_csv(history: List[np.ndarray], output_path: str) -> str:
    """
    å°†è½¨è¿¹æ•°æ®ä¿å­˜ä¸ºCSVæ–‡ä»¶
    
    å‚æ•°:
    history -- æ„è§å†å²æ•°æ®åˆ—è¡¨
    output_path -- è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„
    
    è¿”å›:
    ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    history_array = np.array(history)
    steps, num_agents = history_array.shape
    
    # åˆ›å»ºæ•°æ®æ¡†
    data = {
        'step': [],
        'agent_id': [],
        'opinion': []
    }
    
    # å¡«å……æ•°æ®
    for step in range(steps):
        for agent_id in range(num_agents):
            data['step'].append(step)
            data['agent_id'].append(agent_id)
            data['opinion'].append(history_array[step, agent_id])
    
    # åˆ›å»ºDataFrameå¹¶ä¿å­˜
    df = pd.DataFrame(data)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)
    
    # ä¿å­˜åˆ°CSV
    df.to_csv(output_path, index=False)
    
    return output_path


def save_simulation_data(sim: Any, output_dir: str, prefix: str = 'sim_data') -> Dict[str, str]:
    """
    ä¿å­˜æ¨¡æ‹Ÿæ•°æ®åˆ°æ–‡ä»¶ï¼Œä¾¿äºåç»­è¿›è¡Œç»Ÿè®¡åˆ†æ
    
    å‚æ•°:
    sim -- æ¨¡æ‹Ÿå¯¹è±¡
    output_dir -- è¾“å‡ºç›®å½•è·¯å¾„
    prefix -- æ–‡ä»¶åå‰ç¼€
    
    è¿”å›:
    åŒ…å«æ‰€æœ‰ä¿å­˜æ–‡ä»¶è·¯å¾„çš„å­—å…¸
    """
    # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # ä¿å­˜è½¨è¿¹æ•°æ®
    trajectory_data = {
        'step': [],
        'agent_id': [],
        'opinion': [],
        'identity': [],
        'morality': [],
        'self_activation': [],
        'social_influence': []
    }
    
    # è·å–å®Œæ•´å†å²
    activation_history = sim.get_activation_history()
    
    # å¦‚æœå­˜åœ¨å†å²æ•°æ®
    if sim.self_activation_history:
        # ä¸ºæ¯ä¸€æ­¥ã€æ¯ä¸ªagentæ·»åŠ æ•°æ®
        for step in range(len(sim.self_activation_history)):
            for agent_id in range(sim.num_agents):
                trajectory_data['step'].append(step)
                trajectory_data['agent_id'].append(agent_id)
                # å¯¹äºopinionéœ€è¦ä»trajectoryä¸­è·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”¨å½“å‰å€¼
                if hasattr(sim, 'opinion_trajectory') and step < len(sim.opinion_trajectory):
                    trajectory_data['opinion'].append(sim.opinion_trajectory[step][agent_id])
                else:
                    trajectory_data['opinion'].append(sim.opinions[agent_id])
                
                trajectory_data['identity'].append(sim.identities[agent_id])
                trajectory_data['morality'].append(sim.morals[agent_id])
                trajectory_data['self_activation'].append(activation_history['self_activation_history'][step][agent_id])
                trajectory_data['social_influence'].append(activation_history['social_influence_history'][step][agent_id])
    
    # å°†æ•°æ®è½¬æ¢ä¸ºDataFrameå¹¶ä¿å­˜ä¸ºCSV
    df = pd.DataFrame(trajectory_data)
    trajectory_csv_path = os.path.join(output_dir, f"{prefix}_trajectory.csv")
    df.to_csv(trajectory_csv_path, index=False)
    
    # ä¿å­˜æœ€ç»ˆçŠ¶æ€æ•°æ®
    final_state = {
        'agent_id': list(range(sim.num_agents)),
        'opinion': sim.opinions.tolist(),
        'identity': sim.identities.tolist(),
        'morality': sim.morals.tolist(),
        'self_activation': sim.self_activation.tolist(),
        'social_influence': sim.social_influence.tolist()
    }
    
    df_final = pd.DataFrame(final_state)
    final_csv_path = os.path.join(output_dir, f"{prefix}_final_state.csv")
    df_final.to_csv(final_csv_path, index=False)
    
    # ä¿å­˜ç½‘ç»œç»“æ„
    network_data = []
    for i in range(sim.num_agents):
        for j in range(i+1, sim.num_agents):  # åªä¿å­˜ä¸Šä¸‰è§’çŸ©é˜µé¿å…é‡å¤
            if sim.adj_matrix[i, j] > 0:
                network_data.append({
                    'source': i,
                    'target': j,
                    'weight': sim.adj_matrix[i, j]
                })
    
    df_network = pd.DataFrame(network_data)
    network_csv_path = os.path.join(output_dir, f"{prefix}_network.csv")
    df_network.to_csv(network_csv_path, index=False)
    
    # ä¿å­˜æ¨¡æ‹Ÿé…ç½®
    config_dict = vars(sim.config)
    config_data = []
    for key, value in config_dict.items():
        # è·³è¿‡æ— æ³•åºåˆ—åŒ–çš„å¤æ‚å¯¹è±¡
        if isinstance(value, (int, float, str, bool)) or value is None:
            config_data.append({'parameter': key, 'value': value})
    
    df_config = pd.DataFrame(config_data)
    config_csv_path = os.path.join(output_dir, f"{prefix}_config.csv")
    df_config.to_csv(config_csv_path, index=False)
    
    return {
        'trajectory': trajectory_csv_path,
        'final_state': final_csv_path,
        'network': network_csv_path,
        'config': config_csv_path
    }


class ExperimentDataManager:
    """
    å®éªŒæ•°æ®ç®¡ç†å™¨
    
    ä¸“é—¨ç”¨äºzealot_morality_analysiså®éªŒçš„æ•°æ®å­˜å‚¨å’Œè¯»å–ï¼Œ
    ä¼˜åŒ–å­˜å‚¨ç©ºé—´å’ŒåŠ è½½é€Ÿåº¦çš„å¹³è¡¡ã€‚
    
    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨Parquetæ ¼å¼ï¼Œå¹³è¡¡å‹ç¼©ç‡å’Œè¯»å–é€Ÿåº¦
    - æ”¯æŒæ‰¹æ¬¡ç®¡ç†å’Œæ•°æ®ç´¯ç§¯
    - ä¸ºå¹¶è¡Œè®¡ç®—é¢„ç•™æ¥å£
    - æ”¯æŒfuture variance per identityè®¡ç®—éœ€æ±‚
    """
    
    def __init__(self, base_dir: str = "results/zealot_morality_analysis"):
        """
        åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        
        Args:
            base_dir: åŸºç¡€å­˜å‚¨ç›®å½•
        """
        self.base_dir = Path(base_dir)
        self.data_dir = self.base_dir / "experiment_data"
        self.metadata_dir = self.base_dir / "metadata"
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.metadata_dir.mkdir(parents=True, exist_ok=True)
        
        # æ•°æ®æ–‡ä»¶è·¯å¾„
        self.zealot_numbers_file = self.data_dir / "zealot_numbers_data.parquet"
        self.morality_ratios_file = self.data_dir / "morality_ratios_data.parquet"
        
        # å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        self.batch_metadata_file = self.metadata_dir / "batch_metadata.json"
        self.experiment_config_file = self.metadata_dir / "experiment_config.json"
    
    def save_batch_results(self, 
                          plot_type: str,
                          batch_data: Dict[str, Any],
                          batch_metadata: Dict[str, Any]) -> None:
        """
        ä¿å­˜æ‰¹æ¬¡å®éªŒç»“æœ
        
        Args:
            plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
            batch_data: æ‰¹æ¬¡æ•°æ® {combination_label: {x_values: [], results: {}}}
            batch_metadata: æ‰¹æ¬¡å…ƒæ•°æ®
        """
        # å°†åµŒå¥—çš„ç»“æœæ•°æ®è½¬æ¢ä¸ºæ‰å¹³çš„DataFrameæ ¼å¼
        rows = []
        batch_id = batch_metadata.get('batch_id', f"batch_{int(time.time())}")
        timestamp = batch_metadata.get('timestamp', datetime.now().isoformat())
        
        for combination_label, combo_data in batch_data.items():
            x_values = combo_data['x_values']
            results = combo_data['results']  # {metric: [[run1, run2, ...], [run1, run2, ...], ...]}
            
            for x_idx, x_value in enumerate(x_values):
                for metric_name, metric_results in results.items():
                    if x_idx < len(metric_results):
                        for run_idx, run_value in enumerate(metric_results[x_idx]):
                            rows.append({
                                'batch_id': batch_id,
                                'timestamp': timestamp,
                                'combination': combination_label,
                                'x_value': x_value,
                                'metric': metric_name,
                                'run_index': run_idx,
                                'value': run_value
                            })
        
        # åˆ›å»ºDataFrame
        new_df = pd.DataFrame(rows)
        
        # ç¡®å®šç›®æ ‡æ–‡ä»¶
        target_file = self.zealot_numbers_file if plot_type == 'zealot_numbers' else self.morality_ratios_file
        
        # è¿½åŠ æˆ–åˆ›å»ºæ•°æ®æ–‡ä»¶
        if target_file.exists():
            # è¯»å–ç°æœ‰æ•°æ®å¹¶åˆå¹¶
            existing_df = pd.read_parquet(target_file)
            combined_df = pd.concat([existing_df, new_df], ignore_index=True)
        else:
            combined_df = new_df
        
        # ä¿å­˜ä¸ºParquetæ ¼å¼ï¼ˆè‡ªåŠ¨å‹ç¼©ï¼‰
        combined_df.to_parquet(target_file, compression='snappy', index=False)
        
        # æ›´æ–°æ‰¹æ¬¡å…ƒæ•°æ®
        self._update_batch_metadata(batch_metadata)
        
        print(f"ğŸ’¾ Saved batch data: {len(rows)} records to {target_file.name}")
    
    def load_experiment_data(self, plot_type: str) -> Optional[pd.DataFrame]:
        """
        åŠ è½½å®éªŒæ•°æ®
        
        Args:
            plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
        
        Returns:
            DataFrame æˆ– None
        """
        target_file = self.zealot_numbers_file if plot_type == 'zealot_numbers' else self.morality_ratios_file
        
        if not target_file.exists():
            return None
        
        df = pd.read_parquet(target_file)
        print(f"ğŸ“‚ Loaded {len(df)} records from {target_file.name}")
        return df
    
    def get_experiment_summary(self, plot_type: str) -> Dict[str, Any]:
        """
        è·å–å®éªŒæ•°æ®æ‘˜è¦ç»Ÿè®¡
        
        Args:
            plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
        
        Returns:
            æ‘˜è¦ç»Ÿè®¡å­—å…¸
        """
        df = self.load_experiment_data(plot_type)
        if df is None or df.empty:
            return {'total_records': 0, 'combinations': [], 'batches': [], 'metrics': []}
        
        summary = {
            'total_records': len(df),
            'combinations': sorted(df['combination'].unique().tolist()),
            'batches': sorted(df['batch_id'].unique().tolist()),
            'metrics': sorted(df['metric'].unique().tolist()),
            'x_value_range': (df['x_value'].min(), df['x_value'].max()),
            'total_runs_per_combination': {}
        }
        
        # è®¡ç®—æ¯ä¸ªç»„åˆçš„æ€»è¿è¡Œæ¬¡æ•°
        for combo in summary['combinations']:
            combo_data = df[df['combination'] == combo]
            if not combo_data.empty:
                # è®¡ç®—æ€»è¿è¡Œæ¬¡æ•° = æ€»è®°å½•æ•° / (xå€¼æ•°é‡ * æŒ‡æ ‡æ•°é‡)
                unique_x_values = len(combo_data['x_value'].unique())
                unique_metrics = len(combo_data['metric'].unique())
                total_runs = len(combo_data) // (unique_x_values * unique_metrics) if unique_x_values > 0 and unique_metrics > 0 else 0
                summary['total_runs_per_combination'][combo] = total_runs
        
        return summary
    
    def convert_to_plotting_format(self, plot_type: str) -> Tuple[Dict[str, Dict[str, List[List[float]]]], List[float], Dict[str, int]]:
        """
        å°†å­˜å‚¨çš„æ•°æ®è½¬æ¢ä¸ºç»˜å›¾æ ¼å¼
        
        Args:
            plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
        
        Returns:
            (all_results, x_values, total_runs_per_combination)
        """
        df = self.load_experiment_data(plot_type)
        if df is None or df.empty:
            return {}, [], {}
        
        # è·å–æ‰€æœ‰å”¯ä¸€å€¼
        combinations = sorted(df['combination'].unique())
        x_values = sorted(df['x_value'].unique())
        metrics = sorted(df['metric'].unique())
        
        # åˆå§‹åŒ–ç»“æœç»“æ„
        all_results = {}
        total_runs_per_combination = {}
        
        for combination in combinations:
            combo_data = df[df['combination'] == combination]
            
            # è®¡ç®—æ€»è¿è¡Œæ¬¡æ•°
            unique_x_values = len(combo_data['x_value'].unique())
            unique_metrics = len(combo_data['metric'].unique())
            total_runs = len(combo_data) // (unique_x_values * unique_metrics) if unique_x_values > 0 and unique_metrics > 0 else 0
            total_runs_per_combination[combination] = total_runs
            
            # ç»„ç»‡æ•°æ®ä¸ºç»˜å›¾æ ¼å¼
            combo_results = {}
            
            for metric in metrics:
                metric_results = []
                metric_data = combo_data[combo_data['metric'] == metric]
                
                for x_val in x_values:
                    x_data = metric_data[metric_data['x_value'] == x_val]
                    run_values = x_data['value'].tolist()
                    metric_results.append(run_values)
                
                combo_results[metric] = metric_results
            
            all_results[combination] = combo_results
        
        return all_results, x_values, total_runs_per_combination
    
    def _update_batch_metadata(self, batch_metadata: Dict[str, Any]) -> None:
        """
        æ›´æ–°æ‰¹æ¬¡å…ƒæ•°æ®
        
        Args:
            batch_metadata: æ‰¹æ¬¡å…ƒæ•°æ®
        """
        # è¯»å–ç°æœ‰å…ƒæ•°æ®
        if self.batch_metadata_file.exists():
            with open(self.batch_metadata_file, 'r', encoding='utf-8') as f:
                all_metadata = json.load(f)
        else:
            all_metadata = {'batches': []}
        
        # æ·»åŠ æ–°æ‰¹æ¬¡
        all_metadata['batches'].append(batch_metadata)
        
        # ä¿å­˜å…ƒæ•°æ®
        with open(self.batch_metadata_file, 'w', encoding='utf-8') as f:
            json.dump(all_metadata, f, indent=2, ensure_ascii=False)
    
    def get_batch_metadata(self) -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰æ‰¹æ¬¡å…ƒæ•°æ®
        
        Returns:
            æ‰¹æ¬¡å…ƒæ•°æ®å­—å…¸
        """
        if not self.batch_metadata_file.exists():
            return {'batches': []}
        
        with open(self.batch_metadata_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def save_experiment_config(self, config: Dict[str, Any]) -> None:
        """
        ä¿å­˜å®éªŒé…ç½®
        
        Args:
            config: å®éªŒé…ç½®å­—å…¸
        """
        config['saved_at'] = datetime.now().isoformat()
        
        with open(self.experiment_config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    def load_experiment_config(self) -> Dict[str, Any]:
        """
        åŠ è½½å®éªŒé…ç½®
        
        Returns:
            å®éªŒé…ç½®å­—å…¸
        """
        if not self.experiment_config_file.exists():
            return {}
        
        with open(self.experiment_config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def clean_old_data(self, keep_batches: int = 10) -> None:
        """
        æ¸…ç†æ—§æ•°æ®ï¼Œä¿ç•™æœ€è¿‘çš„æ‰¹æ¬¡
        
        Args:
            keep_batches: ä¿ç•™çš„æ‰¹æ¬¡æ•°é‡
        """
        # TODO: å®ç°æ•°æ®æ¸…ç†é€»è¾‘
        # è¿™ä¸ªåŠŸèƒ½å¯ä»¥åœ¨å°†æ¥éœ€è¦æ—¶å®ç°
        pass
    
    def export_summary_report(self) -> str:
        """
        å¯¼å‡ºå®éªŒæ‘˜è¦æŠ¥å‘Š
        
        Returns:
            æ‘˜è¦æŠ¥å‘Šå­—ç¬¦ä¸²
        """
        zealot_summary = self.get_experiment_summary('zealot_numbers')
        morality_summary = self.get_experiment_summary('morality_ratios')
        batch_metadata = self.get_batch_metadata()
        
        report = []
        report.append("=" * 60)
        report.append("å®éªŒæ•°æ®æ‘˜è¦æŠ¥å‘Š")
        report.append("=" * 60)
        
        report.append(f"\nğŸ“Š Zealot Numbers å®éªŒ:")
        report.append(f"   æ€»è®°å½•æ•°: {zealot_summary['total_records']}")
        report.append(f"   å‚æ•°ç»„åˆæ•°: {len(zealot_summary['combinations'])}")
        report.append(f"   æ‰¹æ¬¡æ•°: {len(zealot_summary['batches'])}")
        
        report.append(f"\nï¿½ï¿½ Morality Ratios å®éªŒ:")
        report.append(f"   æ€»è®°å½•æ•°: {morality_summary['total_records']}")
        report.append(f"   å‚æ•°ç»„åˆæ•°: {len(morality_summary['combinations'])}")
        report.append(f"   æ‰¹æ¬¡æ•°: {len(morality_summary['batches'])}")
        
        report.append(f"\nğŸ“… æ‰¹æ¬¡å†å²: {len(batch_metadata.get('batches', []))} ä¸ªæ‰¹æ¬¡")
        
        # å­˜å‚¨ç©ºé—´ä¿¡æ¯
        zealot_size = self.zealot_numbers_file.stat().st_size if self.zealot_numbers_file.exists() else 0
        morality_size = self.morality_ratios_file.stat().st_size if self.morality_ratios_file.exists() else 0
        total_size = zealot_size + morality_size
        
        report.append(f"\nğŸ’¾ å­˜å‚¨ç©ºé—´:")
        report.append(f"   Zealot Numbers: {zealot_size / 1024:.1f} KB")
        report.append(f"   Morality Ratios: {morality_size / 1024:.1f} KB")
        report.append(f"   æ€»è®¡: {total_size / 1024:.1f} KB")
        
        return "\n".join(report)
