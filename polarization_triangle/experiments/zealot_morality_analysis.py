"""
Zealot and Morality Analysis Experiment

This experiment analyzes the effects of zealot numbers and morality ratios on various system metrics.
It generates two types of plots:
1. X-axis: Number of zealots
2. X-axis: Morality ratio

For each plot type, it generates 4 different Y-axis metrics:
- Mean opinion
- Variance 
- Variance per identity
- Polarization index

Total: 8 plots (2 types Ã— 4 metrics)
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import copy
import time
from tqdm import tqdm
from typing import Dict, List, Tuple, Any
import itertools

from polarization_triangle.core.config import SimulationConfig, high_polarization_config
from polarization_triangle.core.simulation import Simulation
from polarization_triangle.analysis.statistics import (
    calculate_mean_opinion,
    calculate_variance_metrics,
    calculate_identity_statistics,
    get_polarization_index
)


def create_config_combinations():
    """
    åˆ›å»ºå‚æ•°ç»„åˆ
    
    Returns:
    dict: åŒ…å«ä¸¤ç±»å›¾çš„å‚æ•°ç»„åˆ
    """
    # åŸºç¡€é…ç½®
    base_config = copy.deepcopy(high_polarization_config)
    base_config.steps = 300  # è®¾ç½®è¿è¡Œæ­¥æ•°
    
    combinations = {
        'zealot_numbers': [],  # å›¾1ï¼šxè½´ä¸ºzealot numbers
        'morality_ratios': []  # å›¾2ï¼šxè½´ä¸ºmorality ratio
    }
    
    # å›¾1ï¼šxè½´ä¸ºzealot numbersçš„ç»„åˆ
    # æ¯”è¾ƒ "clustering zealots or not" å’Œ morality ratio
    zealot_clustering_options = ['random', 'clustered']
    morality_ratios_for_zealot_plot = [0.0, 0.3]  # ä¸¤ä¸ªä¸åŒçš„morality ratioè¿›è¡Œæ¯”è¾ƒ
    
    for clustering in zealot_clustering_options:
        for morality_ratio in morality_ratios_for_zealot_plot:
            combo = {
                'zealot_mode': clustering,
                'morality_rate': morality_ratio,
                'zealot_identity_allocation': True,  # å›ºå®šä¸ºTrue
                'cluster_identity': False,  # å›ºå®šä¸ºrandom identity distribution
                'label': f'{clustering.capitalize()} Zealots, Morality={morality_ratio}',
                'steps': base_config.steps
            }
            combinations['zealot_numbers'].append(combo)
    
    # å›¾2ï¼šxè½´ä¸ºmorality ratioçš„ç»„åˆ
    # æ¯”è¾ƒ "clustering zealots or not", "zealots aligned with identity", "identity distribution"
    zealot_modes = ['random', 'clustered']
    zealot_identity_alignments = [True, False]  # zealots aligned with identity
    identity_distributions = [False, True]  # random vs clustered identity distribution
    
    # å›ºå®šzealotæ•°é‡ä¸º20ï¼ˆä¸­ç­‰æ•°é‡ï¼‰
    fixed_zealot_count = 20
    
    for zealot_mode in zealot_modes:
        for zealot_identity in zealot_identity_alignments:
            for identity_dist in identity_distributions:
                combo = {
                    'zealot_count': fixed_zealot_count,
                    'zealot_mode': zealot_mode,
                    'zealot_identity_allocation': zealot_identity,
                    'cluster_identity': identity_dist,
                    'label': f'{zealot_mode.capitalize()}, ID-align={zealot_identity}, ID-cluster={identity_dist}',
                    'steps': base_config.steps
                }
                combinations['morality_ratios'].append(combo)
    
    return combinations


def run_single_simulation(config: SimulationConfig, steps: int = 500) -> Dict[str, float]:
    """
    è¿è¡Œå•æ¬¡æ¨¡æ‹Ÿå¹¶è·å–æœ€ç»ˆçŠ¶æ€çš„ç»Ÿè®¡æŒ‡æ ‡
    
    Args:
    config: æ¨¡æ‹Ÿé…ç½®
    steps: è¿è¡Œæ­¥æ•°
    
    Returns:
    dict: åŒ…å«å„é¡¹ç»Ÿè®¡æŒ‡æ ‡çš„å­—å…¸
    """
    sim = Simulation(config)
    
    # è¿è¡Œæ¨¡æ‹Ÿ
    for _ in range(steps):
        sim.step()
    
    # è·å–ç»Ÿè®¡æŒ‡æ ‡
    mean_stats = calculate_mean_opinion(sim, exclude_zealots=True)
    variance_stats = calculate_variance_metrics(sim, exclude_zealots=True)
    identity_stats = calculate_identity_statistics(sim, exclude_zealots=True)
    polarization = get_polarization_index(sim)
    
    # è®¡ç®—variance per identity (èº«ä»½é—´æ–¹å·®)
    variance_per_identity = 0.0
    if 'identity_difference' in identity_stats:
        variance_per_identity = identity_stats['identity_difference']['abs_mean_opinion_difference']
    else:
        # å¦‚æœæ²¡æœ‰identity_differenceï¼Œè®¡ç®—æ‰€æœ‰èº«ä»½çš„æ–¹å·®å‡å€¼
        identity_variances = []
        for key, values in identity_stats.items():
            if key.startswith('identity_') and key != 'identity_difference':
                identity_variances.append(values['variance'])
        if identity_variances:
            variance_per_identity = np.mean(identity_variances)
    
    return {
        'mean_opinion': mean_stats['mean_opinion'],
        'variance': variance_stats['overall_variance'],
        'variance_per_identity': variance_per_identity,
        'polarization_index': polarization
    }


def run_parameter_sweep(plot_type: str, combination: Dict[str, Any], 
                       x_values: List[float], num_runs: int = 5) -> Dict[str, List[List[float]]]:
    """
    å¯¹ç‰¹å®šå‚æ•°ç»„åˆè¿›è¡Œå‚æ•°æ‰«æ
    
    Args:
    plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
    combination: å‚æ•°ç»„åˆå­—å…¸
    x_values: xè½´çš„å–å€¼åˆ—è¡¨
    num_runs: æ¯ä¸ªå‚æ•°ç‚¹è¿è¡Œçš„æ¬¡æ•°
    
    Returns:
    dict: åŒ…å«å„æŒ‡æ ‡çš„æ•°æ®çŸ©é˜µ {metric: [runs_for_x1, runs_for_x2, ...]}
    """
    results = {
        'mean_opinion': [],
        'variance': [],
        'variance_per_identity': [],
        'polarization_index': []
    }
    
    base_config = copy.deepcopy(high_polarization_config)
    # base_config.steps = 500
    
    # è®¾ç½®å›ºå®šå‚æ•°
    if plot_type == 'zealot_numbers':
        base_config.morality_rate = combination['morality_rate']
        base_config.zealot_identity_allocation = combination['zealot_identity_allocation']
        base_config.cluster_identity = combination['cluster_identity']
        base_config.enable_zealots = True
        base_config.steps = combination['steps']
    else:  # morality_ratios
        base_config.zealot_count = combination['zealot_count']
        base_config.zealot_mode = combination['zealot_mode']
        base_config.zealot_identity_allocation = combination['zealot_identity_allocation']
        base_config.cluster_identity = combination['cluster_identity']
        base_config.enable_zealots = True
        base_config.steps = combination['steps']
    
    # å¯¹æ¯ä¸ªxå€¼è¿›è¡Œå¤šæ¬¡è¿è¡Œ
    for x_val in tqdm(x_values, desc=f"Running {combination['label']}"):
        runs_data = {
            'mean_opinion': [],
            'variance': [],
            'variance_per_identity': [],
            'polarization_index': []
        }
        
        # è®¾ç½®å½“å‰xå€¼å¯¹åº”çš„å‚æ•°
        current_config = copy.deepcopy(base_config)
        if plot_type == 'zealot_numbers':
            current_config.zealot_count = int(x_val)
            current_config.zealot_mode = combination['zealot_mode']
            if x_val == 0:
                current_config.enable_zealots = False
        else:  # morality_ratios
            current_config.morality_rate = x_val / 100.0  # è½¬æ¢ä¸º0-1èŒƒå›´
        
        # è¿è¡Œå¤šæ¬¡æ¨¡æ‹Ÿ
        for run in range(num_runs):
            try:
                stats = run_single_simulation(current_config)
                for metric in runs_data.keys():
                    runs_data[metric].append(stats[metric])
            except Exception as e:
                print(f"Warning: Simulation failed for x={x_val}, run={run}: {e}")
                # ä½¿ç”¨NaNå¡«å……å¤±è´¥çš„è¿è¡Œ
                for metric in runs_data.keys():
                    runs_data[metric].append(np.nan)
        
        # å°†å½“å‰xå€¼çš„æ‰€æœ‰è¿è¡Œç»“æœæ·»åŠ åˆ°æ€»ç»“æœä¸­
        for metric in results.keys():
            results[metric].append(runs_data[metric])
    
    return results


def plot_results(plot_type: str, x_values: List[float], all_results: Dict[str, Dict[str, List[List[float]]]], 
                output_dir: str):
    """
    ç»˜åˆ¶ç»“æœå›¾è¡¨
    
    Args:
    plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
    x_values: xè½´å–å€¼
    all_results: æ‰€æœ‰ç»„åˆçš„ç»“æœæ•°æ®
    output_dir: è¾“å‡ºç›®å½•
    """
    metrics = ['mean_opinion', 'variance', 'variance_per_identity', 'polarization_index']
    metric_labels = {
        'mean_opinion': 'Mean Opinion',
        'variance': 'Opinion Variance',
        'variance_per_identity': 'Variance per Identity',
        'polarization_index': 'Polarization Index'
    }
    
    x_label = 'Number of Zealots' if plot_type == 'zealot_numbers' else 'Morality Ratio (%)'
    
    # ä¸ºæ¯ä¸ªæŒ‡æ ‡åˆ›å»ºä¸€ä¸ªå›¾
    for metric in metrics:
        plt.figure(figsize=(12, 8))
        
        # ä¸ºæ¯ä¸ªå‚æ•°ç»„åˆç»˜åˆ¶æ›²çº¿
        for combo_label, results in all_results.items():
            metric_data = results[metric]  # List[List[float]], æ¯ä¸ªå†…å±‚listæ˜¯ä¸€ä¸ªxå€¼çš„å¤šæ¬¡è¿è¡Œç»“æœ
            
            means = []
            stds = []
            
            for x_runs in metric_data:
                # è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼Œå¿½ç•¥NaNå€¼
                valid_runs = [val for val in x_runs if not np.isnan(val)]
                if valid_runs:
                    means.append(np.mean(valid_runs))
                    stds.append(np.std(valid_runs))
                else:
                    means.append(np.nan)
                    stds.append(np.nan)
            
            means = np.array(means)
            stds = np.array(stds)
            
            # ç»˜åˆ¶å¸¦è¯¯å·®æ¡çš„æ›²çº¿
            plt.errorbar(x_values, means, yerr=stds, label=combo_label, 
                        marker='o', linewidth=2, capsize=3, alpha=0.8)
        
        plt.xlabel(x_label, fontsize=12)
        plt.ylabel(metric_labels[metric], fontsize=12)
        plt.title(f'{metric_labels[metric]} vs {x_label}', fontsize=14, fontweight='bold')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        filename = f"{plot_type}_{metric}.png"
        filepath = os.path.join(output_dir, filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"Saved plot: {filepath}")


def save_raw_data(plot_type: str, x_values: List[float], 
                 all_results: Dict[str, Dict[str, List[List[float]]]], 
                 output_dir: str):
    """
    ä¿å­˜åŸå§‹æ•°æ®åˆ°CSVæ–‡ä»¶
    
    Args:
    plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
    x_values: xè½´å–å€¼
    all_results: æ‰€æœ‰ç»„åˆçš„ç»“æœæ•°æ®
    output_dir: è¾“å‡ºç›®å½•
    """
    # ä¸ºæ¯ä¸ªå‚æ•°ç»„åˆä¿å­˜æ•°æ®
    for combo_label, results in all_results.items():
        # åˆ›å»ºæ•°æ®æ¡†
        data_rows = []
        
        for i, x_val in enumerate(x_values):
            for metric in ['mean_opinion', 'variance', 'variance_per_identity', 'polarization_index']:
                for run_idx, value in enumerate(results[metric][i]):
                    data_rows.append({
                        'x_value': x_val,
                        'metric': metric,
                        'run': run_idx,
                        'value': value,
                        'combination': combo_label
                    })
        
        df = pd.DataFrame(data_rows)
        
        # ä¿å­˜åˆ°CSV
        safe_label = combo_label.replace('/', '_').replace(' ', '_').replace('=', '_').replace(',', '_')
        filename = f"{plot_type}_{safe_label}_raw_data.csv"
        filepath = os.path.join(output_dir, filename)
        df.to_csv(filepath, index=False)
        print(f"Saved raw data: {filepath}")


def run_zealot_morality_analysis(output_dir: str = "results/zealot_morality_analysis", 
                                num_runs: int = 5, max_zealots: int = 50, max_morality: int = 30):
    """
    è¿è¡Œzealotå’Œmoralityåˆ†æå®éªŒ
    
    Args:
    output_dir: è¾“å‡ºç›®å½•
    num_runs: æ¯ä¸ªå‚æ•°ç‚¹çš„è¿è¡Œæ¬¡æ•°
    max_zealots: æœ€å¤§zealotæ•°é‡
    max_morality: æœ€å¤§morality ratio (%)
    """
    print("ğŸ”¬ Starting Zealot and Morality Analysis Experiment")
    print("=" * 70)
    
    start_time = time.time()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–å‚æ•°ç»„åˆ
    combinations = create_config_combinations()
    
    print(f"ğŸ“Š Experiment Configuration:")
    print(f"   Number of runs per parameter point: {num_runs}")
    print(f"   Max zealots: {max_zealots}")
    print(f"   Max morality ratio: {max_morality}%")
    print(f"   Output directory: {output_dir}")
    print()
    
    # === å›¾1ï¼šxè½´ä¸ºzealot numbers ===
    print("ğŸ“ˆ Generating Plot Type 1: Zealot Numbers Analysis")
    print("-" * 50)
    
    plot1_start_time = time.time()
    
    zealot_x_values = list(range(0, max_zealots + 1, 2))  # 0, 2, 4, ..., 50
    zealot_results = {}
    
    for combo in combinations['zealot_numbers']:
        print(f"Running combination: {combo['label']}")
        results = run_parameter_sweep('zealot_numbers', combo, zealot_x_values, num_runs)
        zealot_results[combo['label']] = results
    
    # ç»˜åˆ¶zealot numbersçš„å›¾
    plot_results('zealot_numbers', zealot_x_values, zealot_results, output_dir)
    save_raw_data('zealot_numbers', zealot_x_values, zealot_results, output_dir)
    
    plot1_end_time = time.time()
    plot1_duration = plot1_end_time - plot1_start_time
    hours1, remainder1 = divmod(plot1_duration, 3600)
    minutes1, seconds1 = divmod(remainder1, 60)
    
    print(f"â±ï¸  Plot Type 1 completed in: {int(hours1)}h {int(minutes1)}m {seconds1:.2f}s")
    print()
    
    # === å›¾2ï¼šxè½´ä¸ºmorality ratio ===
    print("ğŸ“ˆ Generating Plot Type 2: Morality Ratio Analysis")
    print("-" * 50)
    
    plot2_start_time = time.time()
    
    morality_x_values = list(range(0, max_morality + 1, 2))  # 0, 2, 4, ..., 30
    morality_results = {}
    
    for combo in combinations['morality_ratios']:
        print(f"Running combination: {combo['label']}")
        results = run_parameter_sweep('morality_ratios', combo, morality_x_values, num_runs)
        morality_results[combo['label']] = results
    
    # ç»˜åˆ¶morality ratioçš„å›¾
    plot_results('morality_ratios', morality_x_values, morality_results, output_dir)
    save_raw_data('morality_ratios', morality_x_values, morality_results, output_dir)
    
    plot2_end_time = time.time()
    plot2_duration = plot2_end_time - plot2_start_time
    hours2, remainder2 = divmod(plot2_duration, 3600)
    minutes2, seconds2 = divmod(remainder2, 60)
    
    print(f"â±ï¸  Plot Type 2 completed in: {int(hours2)}h {int(minutes2)}m {seconds2:.2f}s")
    print()
    
    # è®¡ç®—æ€»è€—æ—¶
    end_time = time.time()
    elapsed_time = end_time - start_time
    hours, remainder = divmod(elapsed_time, 3600)
    minutes, seconds = divmod(remainder, 60)
    
    print("\n" + "=" * 70)
    print("ğŸ‰ Experiment Completed Successfully!")
    print(f"ğŸ“Š Generated 8 plots (2 types Ã— 4 metrics)")
    print()
    print("â±ï¸  Timing Summary:")
    print(f"   Plot Type 1 (Zealot Numbers): {int(hours1)}h {int(minutes1)}m {seconds1:.2f}s")
    print(f"   Plot Type 2 (Morality Ratios): {int(hours2)}h {int(minutes2)}m {seconds2:.2f}s")
    print(f"   Total execution time: {int(hours)}h {int(minutes)}m {seconds:.2f}s")
    print(f"ğŸ“ Results saved to: {output_dir}")
    
    # ä¿å­˜å®éªŒä¿¡æ¯ï¼ˆåŒ…å«è¯¦ç»†çš„è€—æ—¶ç»Ÿè®¡ï¼‰
    info_file = os.path.join(output_dir, "experiment_info.txt")
    with open(info_file, "w") as f:
        f.write("Zealot and Morality Analysis Experiment\n")
        f.write("=" * 50 + "\n\n")
        
        f.write("Timing Summary:\n")
        f.write(f"Plot Type 1 (Zealot Numbers): {int(hours1)}h {int(minutes1)}m {seconds1:.2f}s\n")
        f.write(f"Plot Type 2 (Morality Ratios): {int(hours2)}h {int(minutes2)}m {seconds2:.2f}s\n")
        f.write(f"Total execution time: {int(hours)}h {int(minutes)}m {seconds:.2f}s\n\n")
        
        f.write("Configuration:\n")
        f.write(f"Number of runs per parameter point: {num_runs}\n")
        f.write(f"Max zealots: {max_zealots}\n")
        f.write(f"Max morality ratio: {max_morality}%\n\n")
        
        f.write("Plot Type 1 - Zealot Numbers Analysis:\n")
        for combo in combinations['zealot_numbers']:
            f.write(f"  - {combo['label']}\n")
        
        f.write("\nPlot Type 2 - Morality Ratio Analysis:\n")
        for combo in combinations['morality_ratios']:
            f.write(f"  - {combo['label']}\n")
        
        f.write(f"\nGenerated plots:\n")
        for plot_type in ['zealot_numbers', 'morality_ratios']:
            for metric in ['mean_opinion', 'variance', 'variance_per_identity', 'polarization_index']:
                f.write(f"  - {plot_type}_{metric}.png\n")
        
        # æ·»åŠ æ€§èƒ½ç»Ÿè®¡
        f.write(f"\nPerformance Statistics:\n")
        f.write(f"Average time per zealot combination: {plot1_duration/len(combinations['zealot_numbers']):.2f}s\n")
        f.write(f"Average time per morality combination: {plot2_duration/len(combinations['morality_ratios']):.2f}s\n")
        f.write(f"Total parameter points processed: {len(zealot_x_values) * len(combinations['zealot_numbers']) + len(morality_x_values) * len(combinations['morality_ratios'])}\n")
        f.write(f"Average time per parameter point: {elapsed_time/(len(zealot_x_values) * len(combinations['zealot_numbers']) + len(morality_x_values) * len(combinations['morality_ratios'])):.2f}s\n")


if __name__ == "__main__":
    # è¿è¡Œå®éªŒ
    run_zealot_morality_analysis(
        output_dir="results/zealot_morality_analysis",
        num_runs=20,  # å¯ä»¥è°ƒæ•´è¿è¡Œæ¬¡æ•°ä»¥å¹³è¡¡é€Ÿåº¦å’Œç²¾åº¦
        max_zealots=30,  # å¯ä»¥è°ƒæ•´æœ€å¤§zealotæ•°é‡
        max_morality=30  # å¯ä»¥è°ƒæ•´æœ€å¤§morality ratio
    ) 