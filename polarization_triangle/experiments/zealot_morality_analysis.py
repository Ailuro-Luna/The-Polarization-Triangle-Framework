"""
Zealot and Morality Analysis Experiment

This experiment analyzes the effects of zealot numbers and morality ratios on various system metrics.
It generates two types of plots:
1. X-axis: Number of zealots
2. X-axis: Morality ratio

For each plot type, it generates 7 different Y-axis metrics:
- Mean opinion
- Variance 
- Identity opinion difference (between identity groups)
- Polarization index
- Variance per identity (+1) - variance within identity group +1
- Variance per identity (-1) - variance within identity group -1
- Variance per identity (combined) - both identity groups on same plot

Total: 14 plots (2 types Ã— 7 metrics)
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import copy
import time
import multiprocessing
from tqdm import tqdm
from typing import Dict, List, Tuple, Any
import itertools
from glob import glob

from polarization_triangle.core.config import SimulationConfig, high_polarization_config
from polarization_triangle.core.simulation import Simulation
from polarization_triangle.analysis.statistics import (
    calculate_mean_opinion,
    calculate_variance_metrics,
    calculate_identity_statistics,
    get_polarization_index
)
from polarization_triangle.utils.data_manager import ExperimentDataManager


# =====================================
# æ•°æ®å¹³æ»‘å’Œé‡é‡‡æ ·å‡½æ•°
# =====================================

def resample_and_smooth_data(x_values, y_values, target_step=2, smooth_window=3):
    """
    å¯¹æ•°æ®è¿›è¡Œé‡é‡‡æ ·å’Œå¹³æ»‘å¤„ç†
    
    Args:
        x_values: åŸå§‹xå€¼æ•°ç»„ï¼Œå¦‚[0,1,2,3,4,5,6,7,8,9,10,...]
        y_values: åŸå§‹yå€¼æ•°ç»„
        target_step: ç›®æ ‡æ­¥é•¿ï¼Œå¦‚2è¡¨ç¤ºä»[0,1,2,3,4,5,...]å˜ä¸º[0,2,4,6,8,10,...]
        smooth_window: å¹³æ»‘çª—å£å¤§å°
    
    Returns:
        new_x_values, new_y_values: é‡é‡‡æ ·å’Œå¹³æ»‘åçš„æ•°æ®
    """
    # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
    x_values = np.array(x_values)
    y_values = np.array(y_values)
    
    # ç§»é™¤NaNå€¼
    valid_mask = ~np.isnan(y_values)
    x_clean = x_values[valid_mask]
    y_clean = y_values[valid_mask]
    
    if len(x_clean) < 2:
        return x_values, y_values
    
    # 1. é¦–å…ˆè¿›è¡Œå±€éƒ¨å¹³æ»‘ï¼ˆå‡å°‘å™ªå£°ï¼‰
    if smooth_window >= 3 and len(y_clean) >= smooth_window:
        # ä½¿ç”¨ç§»åŠ¨å¹³å‡è¿›è¡Œåˆæ­¥å¹³æ»‘
        kernel = np.ones(smooth_window) / smooth_window
        y_smoothed = np.convolve(y_clean, kernel, mode='same')
        
        # å¤„ç†è¾¹ç•Œæ•ˆåº”
        half_window = smooth_window // 2
        y_smoothed[:half_window] = y_clean[:half_window]
        y_smoothed[-half_window:] = y_clean[-half_window:]
    else:
        y_smoothed = y_clean
    
    # 2. åˆ›å»ºç›®æ ‡xå€¼ï¼ˆé‡é‡‡æ ·ï¼‰
    x_min, x_max = x_clean[0], x_clean[-1]
    new_x_values = np.arange(x_min, x_max + target_step, target_step)
    
    # 3. å¯¹æ¯ä¸ªæ–°çš„xå€¼ï¼Œä½¿ç”¨é™„è¿‘çš„æ•°æ®ç‚¹è¿›è¡ŒåŠ æƒå¹³å‡
    new_y_values = []
    
    for new_x in new_x_values:
        # æ‰¾åˆ°é™„è¿‘çš„ç‚¹è¿›è¡ŒåŠ æƒå¹³å‡
        distances = np.abs(x_clean - new_x)
        
        # ä½¿ç”¨é«˜æ–¯æƒé‡ï¼Œè·ç¦»è¶Šè¿‘æƒé‡è¶Šå¤§
        weights = np.exp(-distances**2 / (2 * (target_step/2)**2))
        
        # åªè€ƒè™‘è·ç¦»åœ¨target_stepèŒƒå›´å†…çš„ç‚¹
        nearby_mask = distances <= target_step
        if np.sum(nearby_mask) > 0:
            nearby_weights = weights[nearby_mask]
            nearby_y = y_smoothed[nearby_mask]
            
            # åŠ æƒå¹³å‡
            weighted_y = np.average(nearby_y, weights=nearby_weights)
            new_y_values.append(weighted_y)
        else:
            # å¦‚æœæ²¡æœ‰é™„è¿‘çš„ç‚¹ï¼Œä½¿ç”¨æœ€è¿‘çš„ç‚¹
            closest_idx = np.argmin(distances)
            new_y_values.append(y_smoothed[closest_idx])
    
    return new_x_values, np.array(new_y_values)


def apply_final_smooth(y_values, method='savgol', window=5):
    """
    å¯¹é‡é‡‡æ ·åçš„æ•°æ®è¿›è¡Œæœ€ç»ˆå¹³æ»‘
    
    Args:
        y_values: é‡é‡‡æ ·åçš„yå€¼
        method: å¹³æ»‘æ–¹æ³• ('savgol', 'moving_avg', 'none')
        window: å¹³æ»‘çª—å£
    
    Returns:
        å¹³æ»‘åçš„yå€¼
    """
    if len(y_values) < window or method == 'none':
        return y_values
    
    if method == 'moving_avg':
        # ç§»åŠ¨å¹³å‡
        kernel = np.ones(window) / window
        smoothed = np.convolve(y_values, kernel, mode='same')
    elif method == 'savgol':
        # Savitzky-Golayæ»¤æ³¢ï¼ˆéœ€è¦scipyï¼‰
        try:
            from scipy.signal import savgol_filter
            # ç¡®ä¿windowæ˜¯å¥‡æ•°ä¸”å°äºæ•°æ®é•¿åº¦
            actual_window = min(window if window % 2 == 1 else window-1, len(y_values)-1)
            if actual_window >= 3:
                smoothed = savgol_filter(y_values, actual_window, 2)
            else:
                smoothed = y_values
        except ImportError:
            # å¦‚æœæ²¡æœ‰scipyï¼Œä½¿ç”¨ç§»åŠ¨å¹³å‡
            kernel = np.ones(window) / window
            smoothed = np.convolve(y_values, kernel, mode='same')
    else:
        smoothed = y_values
    
    return smoothed


# =====================================
# å·¥å…·å‡½æ•°
# =====================================

def format_duration(duration: float) -> str:
    """
    æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
    
    Args:
    duration: æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    
    Returns:
    str: æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
    """
    hours, remainder = divmod(duration, 3600)
    minutes, seconds = divmod(remainder, 60)
    return f"{int(hours)}h {int(minutes)}m {seconds:.2f}s"


# æ³¨ï¼šsave_batch_info å‡½æ•°å·²è¢« ExperimentDataManager çš„æ‰¹æ¬¡å…ƒæ•°æ®åŠŸèƒ½æ›¿ä»£


# =====================================
# å¹¶è¡Œè®¡ç®—æ”¯æŒå‡½æ•°
# =====================================

def run_single_simulation_task(task_params):
    """
    å•ä¸ªæ¨¡æ‹Ÿä»»åŠ¡çš„åŒ…è£…å‡½æ•°ï¼Œç”¨äºå¤šè¿›ç¨‹å¹¶è¡Œè®¡ç®—
    
    Args:
        task_params: åŒ…å«ä»»åŠ¡å‚æ•°çš„å…ƒç»„
            (plot_type, combination, x_val, run_idx, steps, process_id, batch_seed)
    
    Returns:
        tuple: (x_val, run_idx, results_dict, success, error_msg)
    """
    try:
        plot_type, combination, x_val, run_idx, steps, process_id, batch_seed = task_params
        
        # è®¾ç½®è¿›ç¨‹ç‰¹å®šçš„éšæœºç§å­ï¼ŒåŠ å…¥æ‰¹æ¬¡æ ‡è¯†ç¡®ä¿ä¸åŒæ‰¹æ¬¡äº§ç”Ÿä¸åŒç»“æœ
        np.random.seed((int(x_val * 1000) + run_idx + process_id + batch_seed) % (2**32))
        
        # æ„å»ºé…ç½®
        base_config = copy.deepcopy(high_polarization_config)
        
        # è®¾ç½®å›ºå®šå‚æ•°
        if plot_type == 'zealot_numbers':
            base_config.morality_rate = combination['morality_rate']
            base_config.zealot_identity_allocation = combination['zealot_identity_allocation']
            base_config.cluster_identity = combination['cluster_identity']
            base_config.enable_zealots = True
            base_config.steps = combination['steps']
            # è®¾ç½®å½“å‰xå€¼å¯¹åº”çš„å‚æ•°
            base_config.zealot_count = int(x_val)
            base_config.zealot_mode = combination['zealot_mode']
            if x_val == 0:
                base_config.enable_zealots = False
        else:  # morality_ratios
            base_config.zealot_count = combination['zealot_count']
            base_config.zealot_mode = combination['zealot_mode']
            base_config.zealot_identity_allocation = combination['zealot_identity_allocation']
            base_config.cluster_identity = combination['cluster_identity']
            base_config.enable_zealots = combination['zealot_mode'] != 'none'
            base_config.steps = combination['steps']
            # è®¾ç½®å½“å‰xå€¼å¯¹åº”çš„å‚æ•°
            base_config.morality_rate = x_val / 100.0  # è½¬æ¢ä¸º0-1èŒƒå›´
        
        # è¿è¡Œå•æ¬¡æ¨¡æ‹Ÿ
        results = run_single_simulation(base_config, steps)
        
        return (x_val, run_idx, results, True, None)
        
    except Exception as e:
        error_msg = f"Process {process_id}: Simulation failed for x={x_val}, run={run_idx}: {str(e)}"
        return (x_val, run_idx, None, False, error_msg)


# =====================================
# æ ¸å¿ƒå®éªŒé€»è¾‘å‡½æ•°
# =====================================

def create_config_combinations():
    """
    åˆ›å»ºå®éªŒå‚æ•°ç»„åˆé…ç½®
    
    è¯¥å‡½æ•°ç”Ÿæˆä¸¤ç±»å®éªŒçš„æ‰€æœ‰å‚æ•°ç»„åˆï¼š
    
    1. zealot_numberså®éªŒï¼šæµ‹è¯•ä¸åŒzealotæ•°é‡å¯¹ç³»ç»Ÿçš„å½±å“
       - å˜é‡ï¼šzealotæ•°é‡ (xè½´)
       - å›ºå®šï¼šzealotèº«ä»½åˆ†é…=True, èº«ä»½åˆ†å¸ƒ=random
       - æ¯”è¾ƒï¼šzealotåˆ†å¸ƒæ¨¡å¼(random/clustered) Ã— moralityæ¯”ä¾‹(0.0/0.3) = 4ä¸ªç»„åˆ
    
    2. morality_ratioså®éªŒï¼šæµ‹è¯•ä¸åŒmoralityæ¯”ä¾‹å¯¹ç³»ç»Ÿçš„å½±å“
       - å˜é‡ï¼šmoralityæ¯”ä¾‹ (xè½´)
       - å›ºå®šï¼šzealotæ•°é‡=20
       - æ¯”è¾ƒï¼šzealotæ¨¡å¼(random/clustered/none) Ã— zealotèº«ä»½å¯¹é½(True/False) Ã— 
               èº«ä»½åˆ†å¸ƒ(random/clustered) = 10ä¸ªç»„åˆ
    
    Returns:
        dict: åŒ…å«ä¸¤ç±»å®éªŒé…ç½®çš„å­—å…¸
            - 'zealot_numbers': 4ä¸ªå‚æ•°ç»„åˆï¼Œç”¨äºzealotæ•°é‡å®éªŒ
            - 'morality_ratios': 10ä¸ªå‚æ•°ç»„åˆï¼Œç”¨äºmoralityæ¯”ä¾‹å®éªŒ
    """
    # åŸºç¡€é…ç½®ï¼šä½¿ç”¨é«˜æåŒ–é…ç½®ä½œä¸ºæ¨¡æ¿
    base_config = copy.deepcopy(high_polarization_config)
    base_config.steps = 300  # æ¯æ¬¡æ¨¡æ‹Ÿè¿è¡Œ300æ­¥
    
    # åˆå§‹åŒ–ä¸¤ç±»å®éªŒçš„å‚æ•°ç»„åˆå®¹å™¨
    combinations = {
        'zealot_numbers': [],   # å®éªŒ1ï¼šxè½´ä¸ºzealotæ•°é‡çš„å‚æ•°ç»„åˆ
        'morality_ratios': []   # å®éªŒ2ï¼šxè½´ä¸ºmoralityæ¯”ä¾‹çš„å‚æ•°ç»„åˆ
    }
    
    # ===== å®éªŒ1ï¼šzealotæ•°é‡æ‰«æå®éªŒ =====
    # æ¯”è¾ƒzealotåˆ†å¸ƒæ¨¡å¼å’Œmoralityæ¯”ä¾‹å¯¹ç³»ç»Ÿçš„å½±å“
    # å›ºå®šå‚æ•°ï¼šzealotèº«ä»½åˆ†é…=True, èº«ä»½åˆ†å¸ƒ=random
    zealot_clustering_options = ['random', 'clustered']  # zealotåˆ†å¸ƒæ¨¡å¼ï¼šéšæœºåˆ†å¸ƒ vs èšé›†åˆ†å¸ƒ
    morality_ratios_for_zealot_plot = [0.0, 0.3]  # ä¸¤ä¸ªmoralityæ°´å¹³ï¼šæ— é“å¾·çº¦æŸ vs ä¸­ç­‰é“å¾·çº¦æŸ
    
    for clustering in zealot_clustering_options:
        for morality_ratio in morality_ratios_for_zealot_plot:
            combo = {
                'zealot_mode': clustering,                    # zealotåˆ†å¸ƒæ¨¡å¼
                'morality_rate': morality_ratio,              # moralityçº¦æŸå¼ºåº¦
                'zealot_identity_allocation': True,           # zealotæŒ‰èº«ä»½åˆ†é…ï¼ˆå›ºå®šï¼‰
                'cluster_identity': False,                    # èº«ä»½éšæœºåˆ†å¸ƒï¼ˆå›ºå®šï¼‰
                'label': f'{clustering.capitalize()} Zealots, Morality={morality_ratio}',
                'steps': base_config.steps
            }
            combinations['zealot_numbers'].append(combo)
    
    # ===== å®éªŒ2ï¼šmoralityæ¯”ä¾‹æ‰«æå®éªŒ =====
    # æ¯”è¾ƒä¸‰ä¸ªå…³é”®å› ç´ çš„äº¤äº’å½±å“ï¼šzealotåˆ†å¸ƒã€zealotèº«ä»½å¯¹é½ã€èº«ä»½åˆ†å¸ƒ
    # å›ºå®šå‚æ•°ï¼šzealotæ•°é‡=20ï¼ˆä¸­ç­‰æ°´å¹³ï¼‰
    zealot_modes = ['random', 'clustered', 'none']     # zealotæ¨¡å¼ï¼šéšæœº/èšé›†/æ— zealot
    zealot_identity_alignments = [True, False]         # zealotæ˜¯å¦æŒ‰èº«ä»½åˆ†é…
    identity_distributions = [False, True]             # èº«ä»½åˆ†å¸ƒï¼šéšæœº vs èšé›†
    
    # å›ºå®šzealotæ•°é‡ä¸º20ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸­ç­‰æ°´å¹³ï¼Œæ—¢ä¸ä¼šè¿‡åº¦å½±å“ç³»ç»Ÿï¼Œä¹Ÿèƒ½è§‚å¯Ÿåˆ°æ•ˆæœ
    fixed_zealot_count = 20
    
    for zealot_mode in zealot_modes:
        if zealot_mode == 'none':
            # æ— zealotæƒ…å†µï¼šåªéœ€è¦åŒºåˆ†èº«ä»½åˆ†å¸ƒæ–¹å¼ï¼Œzealotç›¸å…³å‚æ•°æ— æ„ä¹‰
            for identity_dist in identity_distributions:
                combo = {
                    'zealot_count': 0,                           # æ— zealot
                    'zealot_mode': zealot_mode,                  # æ ‡è®°ä¸º'none'
                    'zealot_identity_allocation': True,          # é»˜è®¤å€¼ï¼ˆä¸å½±å“ç»“æœï¼‰
                    'cluster_identity': identity_dist,           # èº«ä»½åˆ†å¸ƒæ–¹å¼
                    'label': f'{zealot_mode.capitalize()}, ID-cluster={identity_dist}',
                    'steps': base_config.steps
                }
                combinations['morality_ratios'].append(combo)
        else:
            # æœ‰zealotæƒ…å†µï¼šéœ€è¦è€ƒè™‘zealotèº«ä»½å¯¹é½æ–¹å¼å’Œèº«ä»½åˆ†å¸ƒæ–¹å¼çš„ç»„åˆæ•ˆåº”
            for zealot_identity in zealot_identity_alignments:
                for identity_dist in identity_distributions:
                    combo = {
                        'zealot_count': fixed_zealot_count,          # å›ºå®šzealotæ•°é‡
                        'zealot_mode': zealot_mode,                  # zealotåˆ†å¸ƒæ¨¡å¼
                        'zealot_identity_allocation': zealot_identity,  # zealotèº«ä»½å¯¹é½æ–¹å¼
                        'cluster_identity': identity_dist,           # èº«ä»½åˆ†å¸ƒæ–¹å¼
                        'label': f'{zealot_mode.capitalize()}, ID-align={zealot_identity}, ID-cluster={identity_dist}',
                        'steps': base_config.steps
                    }
                    combinations['morality_ratios'].append(combo)
    
    return combinations


def run_single_simulation(config: SimulationConfig, steps: int = 500) -> Dict[str, float]:
    """
    è¿è¡Œå•æ¬¡æ¨¡æ‹Ÿå¹¶è·å–æœ€ç»ˆçŠ¶æ€çš„ç»Ÿè®¡æŒ‡æ ‡
    
    è¯¥å‡½æ•°åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿå®ä¾‹ï¼Œè¿è¡ŒæŒ‡å®šæ­¥æ•°ï¼Œç„¶åè®¡ç®—å…­ä¸ªå…³é”®æŒ‡æ ‡ï¼š
    - Mean Opinion: ç³»ç»Ÿä¸­ézealot agentçš„å¹³å‡æ„è§å€¼
    - Variance: æ„è§åˆ†å¸ƒçš„æ–¹å·®ï¼Œè¡¡é‡æ„è§åˆ†åŒ–ç¨‹åº¦
    - Identity Opinion Difference: ä¸åŒèº«ä»½ç¾¤ä½“é—´çš„å¹³å‡æ„è§å·®å¼‚
    - Polarization Index: æåŒ–æŒ‡æ•°ï¼Œè¡¡é‡ç³»ç»Ÿçš„æåŒ–ç¨‹åº¦
    - Variance per Identity: æ¯ä¸ªèº«ä»½ç¾¤ä½“å†…éƒ¨çš„æ„è§æ–¹å·®ï¼ˆä¸¤ä¸ªèº«ä»½ç¾¤ä½“åˆ†åˆ«è®¡ç®—ï¼‰
    
    Args:
        config (SimulationConfig): æ¨¡æ‹Ÿé…ç½®å¯¹è±¡ï¼ŒåŒ…å«ç½‘ç»œã€agentã€zealotç­‰å‚æ•°
        steps (int, optional): æ¨¡æ‹Ÿè¿è¡Œçš„æ­¥æ•°. Defaults to 500.
    
    Returns:
        Dict[str, Any]: åŒ…å«ç»Ÿè®¡æŒ‡æ ‡çš„å­—å…¸
            - 'mean_opinion': å¹³å‡æ„è§å€¼ (float)
            - 'variance': æ„è§æ–¹å·® (float)
            - 'identity_opinion_difference': èº«ä»½é—´æ„è§å·®å¼‚ (float)
            - 'polarization_index': æåŒ–æŒ‡æ•° (float)
            - 'variance_per_identity': æ¯ä¸ªèº«ä»½ç»„çš„æ–¹å·® (dict)
                - 'identity_1': identity=1ç»„çš„æ–¹å·®
                - 'identity_-1': identity=-1ç»„çš„æ–¹å·®
    
    Raises:
        Exception: å½“æ¨¡æ‹Ÿè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯æ—¶æŠ›å‡ºå¼‚å¸¸
    """
    # åˆ›å»ºæ¨¡æ‹Ÿå®ä¾‹
    sim = Simulation(config)
    
    # é€æ­¥è¿è¡Œæ¨¡æ‹Ÿè‡³ç¨³å®šçŠ¶æ€
    for _ in range(steps):
        sim.step()
    
    # ä»æœ€ç»ˆçŠ¶æ€è®¡ç®—å„é¡¹ç»Ÿè®¡æŒ‡æ ‡
    mean_stats = calculate_mean_opinion(sim, exclude_zealots=True)
    variance_stats = calculate_variance_metrics(sim, exclude_zealots=True)
    identity_stats = calculate_identity_statistics(sim, exclude_zealots=True)
    polarization = get_polarization_index(sim)
    
    # è®¡ç®—identity opinion difference (èº«ä»½é—´æ„è§å·®å¼‚)
    identity_opinion_difference = 0.0
    if 'identity_difference' in identity_stats:
        identity_opinion_difference = identity_stats['identity_difference']['abs_mean_opinion_difference']
    else:
        # ç†è®ºä¸Šåœ¨æ­£å¸¸æƒ…å†µä¸‹ä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œï¼ˆzealotæ•°é‡è¶³å¤Ÿå°æ—¶ï¼‰
        print("Warning: identity_difference not found, this should not happen under normal conditions")
        identity_opinion_difference = 0.0
    
    # è®¡ç®— variance per identity (æ¯ä¸ªèº«ä»½ç»„å†…çš„æ–¹å·®)
    variance_per_identity = {'identity_1': 0.0, 'identity_-1': 0.0}
    
    # è·å–ézealotèŠ‚ç‚¹çš„æ„è§å’Œèº«ä»½
    # åˆ›å»º zealot maskï¼šå¦‚æœä¸€ä¸ªagentçš„IDåœ¨ zealot_ids ä¸­ï¼Œåˆ™ä¸ºTrue
    zealot_mask = np.zeros(sim.num_agents, dtype=bool)
    if sim.enable_zealots and sim.zealot_ids:
        zealot_mask[sim.zealot_ids] = True
    
    non_zealot_mask = ~zealot_mask
    non_zealot_opinions = sim.opinions[non_zealot_mask]
    non_zealot_identities = sim.identities[non_zealot_mask]
    
    # åˆ†åˆ«è®¡ç®—æ¯ä¸ªèº«ä»½ç»„çš„æ–¹å·®
    for identity_val in [1, -1]:
        identity_mask = non_zealot_identities == identity_val
        if np.sum(identity_mask) > 1:  # è‡³å°‘éœ€è¦2ä¸ªèŠ‚ç‚¹æ‰èƒ½è®¡ç®—æ–¹å·®
            identity_opinions = non_zealot_opinions[identity_mask]
            variance_per_identity[f'identity_{identity_val}'] = float(np.var(identity_opinions))
        else:
            variance_per_identity[f'identity_{identity_val}'] = 0.0
    
    return {
        'mean_opinion': mean_stats['mean_opinion'],
        'variance': variance_stats['overall_variance'],
        'identity_opinion_difference': identity_opinion_difference,
        'polarization_index': polarization,
        'variance_per_identity': variance_per_identity
    }


def run_parameter_sweep(plot_type: str, combination: Dict[str, Any], 
                       x_values: List[float], num_runs: int = 5, num_processes: int = 1, 
                       batch_seed: int = 0) -> Dict[str, List[List[float]]]:
    """
    å¯¹ç‰¹å®šå‚æ•°ç»„åˆè¿›è¡Œå‚æ•°æ‰«æå®éªŒ
    
    è¯¥å‡½æ•°é’ˆå¯¹ç»™å®šçš„å‚æ•°ç»„åˆï¼Œåœ¨xè½´çš„æ¯ä¸ªå–å€¼ç‚¹è¿è¡Œå¤šæ¬¡æ¨¡æ‹Ÿï¼Œæ”¶é›†ç»Ÿè®¡æ•°æ®ã€‚
    è¿™æ˜¯å®éªŒçš„æ ¸å¿ƒæ‰§è¡Œå‡½æ•°ï¼Œæ”¯æŒä¸¤ç§ç±»å‹çš„æ‰«æï¼š
    - zealot_numbers: å›ºå®šmoralityæ¯”ä¾‹ï¼Œæ‰«æä¸åŒçš„zealotæ•°é‡
    - morality_ratios: å›ºå®šzealotæ•°é‡ï¼Œæ‰«æä¸åŒçš„moralityæ¯”ä¾‹
    
    Args:
        plot_type (str): å®éªŒç±»å‹
            - 'zealot_numbers': xè½´ä¸ºzealotæ•°é‡çš„å®éªŒ
            - 'morality_ratios': xè½´ä¸ºmoralityæ¯”ä¾‹çš„å®éªŒ
        combination (Dict[str, Any]): å‚æ•°ç»„åˆå­—å…¸ï¼ŒåŒ…å«ï¼š
            - zealot_mode: zealotåˆ†å¸ƒæ¨¡å¼ ('random', 'clustered', 'none')
            - morality_rate: moralityæ¯”ä¾‹ (0.0-1.0)
            - zealot_identity_allocation: æ˜¯å¦æŒ‰èº«ä»½åˆ†é…zealot
            - cluster_identity: æ˜¯å¦èšç±»èº«ä»½åˆ†å¸ƒ
            - label: ç»„åˆæ ‡ç­¾
            - steps: æ¨¡æ‹Ÿæ­¥æ•°
        x_values (List[float]): xè½´æ‰«æçš„å–å€¼åˆ—è¡¨ï¼Œå¦‚ [0, 1, 2, ...]
        num_runs (int, optional): æ¯ä¸ªxå€¼ç‚¹é‡å¤è¿è¡Œæ¬¡æ•°. Defaults to 5.
        num_processes (int, optional): å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œ1è¡¨ç¤ºä¸²è¡Œæ‰§è¡Œ. Defaults to 1.
        batch_seed (int, optional): æ‰¹æ¬¡ç§å­ï¼Œç¡®ä¿ä¸åŒæ‰¹æ¬¡äº§ç”Ÿä¸åŒç»“æœ. Defaults to 0.
    
    Returns:
        Dict[str, List[List[float]]]: åµŒå¥—çš„ç»“æœæ•°æ®ç»“æ„
            æ ¼å¼: {metric_name: [x1_runs, x2_runs, ...]}
            å…¶ä¸­ x1_runs = [run1_value, run2_value, ...]
            
            åŒ…å«çš„æŒ‡æ ‡:
            - 'mean_opinion': å¹³å‡æ„è§å€¼çš„å¤šæ¬¡è¿è¡Œç»“æœ
            - 'variance': æ„è§æ–¹å·®çš„å¤šæ¬¡è¿è¡Œç»“æœ  
            - 'identity_opinion_difference': èº«ä»½é—´æ„è§å·®å¼‚çš„å¤šæ¬¡è¿è¡Œç»“æœ
            - 'polarization_index': æåŒ–æŒ‡æ•°çš„å¤šæ¬¡è¿è¡Œç»“æœ
            - 'variance_per_identity_1': identity=1ç»„å†…æ–¹å·®çš„å¤šæ¬¡è¿è¡Œç»“æœ
            - 'variance_per_identity_-1': identity=-1ç»„å†…æ–¹å·®çš„å¤šæ¬¡è¿è¡Œç»“æœ
    """
    # é€‰æ‹©ä¸²è¡Œæˆ–å¹¶è¡Œæ‰§è¡Œ
    if num_processes == 1:
        return run_parameter_sweep_serial(plot_type, combination, x_values, num_runs, batch_seed)
    else:
        return run_parameter_sweep_parallel(plot_type, combination, x_values, num_runs, num_processes, batch_seed)


def run_parameter_sweep_serial(plot_type: str, combination: Dict[str, Any], 
                              x_values: List[float], num_runs: int = 5, batch_seed: int = 0) -> Dict[str, List[List[float]]]:
    """
    ä¸²è¡Œç‰ˆæœ¬çš„å‚æ•°æ‰«æï¼ˆåŸæœ‰é€»è¾‘ï¼‰
    """
    results = {
        'mean_opinion': [],
        'variance': [],
        'identity_opinion_difference': [],
        'polarization_index': [],
        'variance_per_identity_1': [],
        'variance_per_identity_-1': []
    }
    
    base_config = copy.deepcopy(high_polarization_config)
    
    # è®¾ç½®å›ºå®šå‚æ•°
    if plot_type == 'zealot_numbers':
        base_config.morality_rate = combination['morality_rate']
        base_config.zealot_identity_allocation = combination['zealot_identity_allocation']
        base_config.cluster_identity = combination['cluster_identity']
        base_config.enable_zealots = True
        base_config.steps = combination['steps']
    else:  # morality_ratios
        base_config.zealot_count = combination['zealot_count']
        base_config.zealot_mode = combination['zealot_mode']
        base_config.zealot_identity_allocation = combination['zealot_identity_allocation']
        base_config.cluster_identity = combination['cluster_identity']
        base_config.enable_zealots = combination['zealot_mode'] != 'none'
        base_config.steps = combination['steps']
    
    # å¯¹æ¯ä¸ªxå€¼è¿›è¡Œå¤šæ¬¡è¿è¡Œ
    for x_val in tqdm(x_values, desc=f"Running {combination['label']}"):
        runs_data = {
            'mean_opinion': [],
            'variance': [],
            'identity_opinion_difference': [],
            'polarization_index': [],
            'variance_per_identity_1': [],
            'variance_per_identity_-1': []
        }
        
        # è®¾ç½®å½“å‰xå€¼å¯¹åº”çš„å‚æ•°
        current_config = copy.deepcopy(base_config)
        if plot_type == 'zealot_numbers':
            current_config.zealot_count = int(x_val)
            current_config.zealot_mode = combination['zealot_mode']
            if x_val == 0:
                current_config.enable_zealots = False
        else:  # morality_ratios
            current_config.morality_rate = x_val / 100.0  # è½¬æ¢ä¸º0-1èŒƒå›´
        
        # è¿è¡Œå¤šæ¬¡æ¨¡æ‹Ÿ
        for run in range(num_runs):
            try:
                # è®¾ç½®éšæœºç§å­ï¼ŒåŠ å…¥æ‰¹æ¬¡æ ‡è¯†ç¡®ä¿ä¸åŒæ‰¹æ¬¡äº§ç”Ÿä¸åŒç»“æœ
                np.random.seed((int(x_val * 1000) + run + batch_seed) % (2**32))
                
                stats = run_single_simulation(current_config)
                # å¤„ç†åŸºç¡€æŒ‡æ ‡
                for metric in ['mean_opinion', 'variance', 'identity_opinion_difference', 'polarization_index']:
                    runs_data[metric].append(stats[metric])
                # å¤„ç† variance per identity æŒ‡æ ‡
                variance_per_identity = stats['variance_per_identity']
                runs_data['variance_per_identity_1'].append(variance_per_identity['identity_1'])
                runs_data['variance_per_identity_-1'].append(variance_per_identity['identity_-1'])
            except Exception as e:
                print(f"Warning: Simulation failed for x={x_val}, run={run}: {e}")
                # ä½¿ç”¨NaNå¡«å……å¤±è´¥çš„è¿è¡Œ
                for metric in runs_data.keys():
                    runs_data[metric].append(np.nan)
        
        # å°†å½“å‰xå€¼çš„æ‰€æœ‰è¿è¡Œç»“æœæ·»åŠ åˆ°æ€»ç»“æœä¸­
        for metric in results.keys():
            results[metric].append(runs_data[metric])
    
    return results


def run_parameter_sweep_parallel(plot_type: str, combination: Dict[str, Any], 
                                x_values: List[float], num_runs: int = 5, num_processes: int = 4, 
                                batch_seed: int = 0) -> Dict[str, List[List[float]]]:
    """
    å¹¶è¡Œç‰ˆæœ¬çš„å‚æ•°æ‰«æ
    """
    print(f"ğŸš€ ä½¿ç”¨ {num_processes} ä¸ªè¿›ç¨‹è¿›è¡Œå¹¶è¡Œè®¡ç®—...")
    
    # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
    tasks = []
    for x_val in x_values:
        for run_idx in range(num_runs):
            process_id = len(tasks) % num_processes  # ç®€å•çš„è¿›ç¨‹IDåˆ†é…
            task = (plot_type, combination, x_val, run_idx, combination['steps'], process_id, batch_seed)
            tasks.append(task)
    
    print(f"ğŸ“Š æ€»ä»»åŠ¡æ•°: {len(tasks)} (x_values: {len(x_values)}, runs_per_x: {num_runs})")
    
    # æ‰§è¡Œå¹¶è¡Œè®¡ç®—
    try:
        with multiprocessing.Pool(num_processes) as pool:
            # ä½¿ç”¨ imap æ¥æ˜¾ç¤ºè¿›åº¦
            results_list = []
            with tqdm(total=len(tasks), desc=f"Running {combination['label']} (parallel)") as pbar:
                for result in pool.imap(run_single_simulation_task, tasks):
                    results_list.append(result)
                    pbar.update(1)
    except Exception as e:
        print(f"âŒ å¹¶è¡Œè®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°ä¸²è¡Œæ¨¡å¼: {e}")
        return run_parameter_sweep_serial(plot_type, combination, x_values, num_runs, batch_seed)
    
    # æ•´ç†ç»“æœ
    return organize_parallel_results(results_list, x_values, num_runs)


def organize_parallel_results(results_list: List[Tuple], x_values: List[float], num_runs: int) -> Dict[str, List[List[float]]]:
    """
    å°†å¹¶è¡Œè®¡ç®—ç»“æœé‡æ–°ç»„ç»‡ä¸ºåŸæœ‰çš„æ•°æ®ç»“æ„
    """
    # åˆå§‹åŒ–ç»“æœç»“æ„
    organized_results = {
        'mean_opinion': [],
        'variance': [],
        'identity_opinion_difference': [],
        'polarization_index': [],
        'variance_per_identity_1': [],
        'variance_per_identity_-1': []
    }
    
    # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥çš„ä»»åŠ¡
    success_count = 0
    failure_count = 0
    
    # æŒ‰ x_value åˆ†ç»„æ•´ç†ç»“æœ
    for x_val in x_values:
        runs_data = {
            'mean_opinion': [],
            'variance': [],
            'identity_opinion_difference': [],
            'polarization_index': [],
            'variance_per_identity_1': [],
            'variance_per_identity_-1': []
        }
        
        # æ”¶é›†å½“å‰ x_val çš„æ‰€æœ‰è¿è¡Œç»“æœ
        for run_idx in range(num_runs):
            # åœ¨ç»“æœåˆ—è¡¨ä¸­æŸ¥æ‰¾å¯¹åº”çš„ç»“æœ
            found_result = None
            for result in results_list:
                result_x_val, result_run_idx, result_data, success, error_msg = result
                if result_x_val == x_val and result_run_idx == run_idx:
                    found_result = result
                    break
            
            if found_result and found_result[3]:  # success = True
                result_data = found_result[2]
                # å¤„ç†åŸºç¡€æŒ‡æ ‡
                for metric in ['mean_opinion', 'variance', 'identity_opinion_difference', 'polarization_index']:
                    runs_data[metric].append(result_data[metric])
                # å¤„ç† variance per identity æŒ‡æ ‡
                variance_per_identity = result_data['variance_per_identity']
                runs_data['variance_per_identity_1'].append(variance_per_identity['identity_1'])
                runs_data['variance_per_identity_-1'].append(variance_per_identity['identity_-1'])
                success_count += 1
            else:
                # å¤„ç†å¤±è´¥çš„ä»»åŠ¡
                if found_result:
                    print(f"âš ï¸  {found_result[4]}")  # æ‰“å°é”™è¯¯ä¿¡æ¯
                else:
                    print(f"âš ï¸  Missing result for x={x_val}, run={run_idx}")
                
                # ä½¿ç”¨NaNå¡«å……å¤±è´¥çš„è¿è¡Œ
                for metric in runs_data.keys():
                    runs_data[metric].append(np.nan)
                failure_count += 1
        
        # å°†å½“å‰xå€¼çš„æ‰€æœ‰è¿è¡Œç»“æœæ·»åŠ åˆ°æ€»ç»“æœä¸­
        for metric in organized_results.keys():
            organized_results[metric].append(runs_data[metric])
    
    print(f"âœ… å¹¶è¡Œè®¡ç®—å®Œæˆ: {success_count} æˆåŠŸ, {failure_count} å¤±è´¥")
    
    return organized_results


# =====================================
# æ•°æ®ç®¡ç†å‡½æ•° (å·²é‡æ„ä¸ºä½¿ç”¨ ExperimentDataManager)
# =====================================

def save_data_with_manager(data_manager: ExperimentDataManager, 
                          plot_type: str, 
                          x_values: List[float], 
                          all_results: Dict[str, Dict[str, List[List[float]]]], 
                          batch_metadata: Dict[str, Any]) -> None:
    """
    ä½¿ç”¨æ–°çš„æ•°æ®ç®¡ç†å™¨ä¿å­˜å®éªŒæ•°æ®
    
    Args:
        data_manager: æ•°æ®ç®¡ç†å™¨å®ä¾‹
        plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
        x_values: xè½´å–å€¼
        all_results: æ‰€æœ‰ç»„åˆçš„ç»“æœæ•°æ®
        batch_metadata: æ‰¹æ¬¡å…ƒæ•°æ®
    """
    # è½¬æ¢æ•°æ®æ ¼å¼ä»¥é€‚é…æ–°çš„æ•°æ®ç®¡ç†å™¨
    batch_data = {}
    
    for combination_label, results in all_results.items():
        batch_data[combination_label] = {
            'x_values': x_values,
            'results': results
        }
    
    # ä½¿ç”¨æ•°æ®ç®¡ç†å™¨ä¿å­˜æ•°æ®
    data_manager.save_batch_results(plot_type, batch_data, batch_metadata)


# =====================================
# ç»˜å›¾ç›¸å…³å‡½æ•°
# =====================================

def get_enhanced_style_config(combo_labels: List[str], plot_type: str) -> Dict[str, Dict[str, Any]]:
    """
    ä¸ºç»„åˆæ ‡ç­¾ç”Ÿæˆå¢å¼ºçš„æ ·å¼é…ç½®ï¼Œç‰¹åˆ«é’ˆå¯¹morality_ratiosçš„10æ¡çº¿è¿›è¡Œä¼˜åŒ–
    
    Args:
    combo_labels: ç»„åˆæ ‡ç­¾åˆ—è¡¨
    plot_type: å›¾è¡¨ç±»å‹ ('zealot_numbers' æˆ– 'morality_ratios')
    
    Returns:
    dict: æ ·å¼é…ç½®å­—å…¸
    """
    # å®šä¹‰æ‰©å±•çš„é¢œè‰²è°ƒè‰²æ¿
    colors = [
        '#1f77b4',  # è“è‰²
        '#ff7f0e',  # æ©™è‰²  
        '#2ca02c',  # ç»¿è‰²
        '#d62728',  # çº¢è‰²
        '#9467bd',  # ç´«è‰²
        '#8c564b',  # æ£•è‰²
        '#e377c2',  # ç²‰è‰²
        '#7f7f7f',  # ç°è‰²
        '#bcbd22',  # æ©„æ¦„è‰²
        '#17becf',  # é’è‰²
        '#aec7e8',  # æµ…è“è‰²
        '#ffbb78'   # æµ…æ©™è‰²
    ]
    
    # å®šä¹‰å¤šç§çº¿å‹
    linestyles = ['-', '--', '-.', ':', (0, (3, 1, 1, 1)), (0, (5, 5)), (0, (3, 3)), (0, (1, 1))]
    
    # å®šä¹‰å¤šç§æ ‡è®°
    markers = ['o', 's', '^', 'v', 'D', 'p', '*', 'h', 'H', 'X', '+', 'x']
    
    style_config = {}
    
    if plot_type == 'morality_ratios':
        # å®šä¹‰é¢œè‰²æ˜ å°„ï¼šæŒ‰zealotæ¨¡å¼å’ŒID-alignåˆ†ç»„
        zealot_mode_colors = {
            'None': {
                'base': '#505050',      # æ·±ç°è‰² (ID-cluster=True)
                'light': '#c0c0c0'      # æµ…ç°è‰² (ID-cluster=False)
            },
            'Random': {
                'base': '#ff4500',      # æ·±æ©™çº¢è‰² (ID-align=True)
                'light': '#ff8080'      # æµ…ç²‰çº¢è‰² (ID-align=False)  
            },
            'Clustered': {
                'base': '#0066cc',      # æ·±è“è‰² (ID-align=True)
                'light': '#00cc66'      # äº®ç»¿è‰² (ID-align=False)
            }
        }
        
        # å®šä¹‰æ ‡è®°æ˜ å°„ï¼šæŒ‰ID-clusteråˆ†ç»„
        id_cluster_markers = {
            'True': 'o',      # åœ†å½¢è¡¨ç¤ºID-cluster=True
            'False': '^'      # ä¸‰è§’å½¢è¡¨ç¤ºID-cluster=False
        }
        
        # å®šä¹‰æ ‡è®°å¤§å°æ˜ å°„ï¼šæŒ‰ID-alignåˆ†ç»„
        id_align_sizes = {
            'True': 10,        # å¤§æ ‡è®°è¡¨ç¤ºID-align=True
            'False': 5         # å°æ ‡è®°è¡¨ç¤ºID-align=False
        }
        
        for label in combo_labels:
            # è§£ææ ‡ç­¾ä¸­çš„é…ç½®ä¿¡æ¯
            if 'None' in label:
                zealot_mode = 'None'
                if 'ID-cluster=True' in label:
                    id_cluster = 'True'
                    color = zealot_mode_colors[zealot_mode]['base']
                    marker = id_cluster_markers[id_cluster]
                    markersize = 8
                else:
                    id_cluster = 'False'
                    color = zealot_mode_colors[zealot_mode]['light']
                    marker = id_cluster_markers[id_cluster]
                    markersize = 8
                
                style_config[label] = {
                    'color': color,
                    'linestyle': '-',
                    'marker': marker,
                    'markersize': markersize,
                    'group': 'None'
                }
                
            elif 'Random' in label:
                zealot_mode = 'Random'
                id_align = 'True' if 'ID-align=True' in label else 'False'
                id_cluster = 'True' if 'ID-cluster=True' in label else 'False'
                
                color = zealot_mode_colors[zealot_mode]['base'] if id_align == 'True' else zealot_mode_colors[zealot_mode]['light']
                marker = id_cluster_markers[id_cluster]
                markersize = id_align_sizes[id_align]
                
                style_config[label] = {
                    'color': color,
                    'linestyle': '-',
                    'marker': marker,
                    'markersize': markersize,
                    'group': 'Random'
                }
                
            elif 'Clustered' in label:
                zealot_mode = 'Clustered'
                id_align = 'True' if 'ID-align=True' in label else 'False'
                id_cluster = 'True' if 'ID-cluster=True' in label else 'False'
                
                color = zealot_mode_colors[zealot_mode]['base'] if id_align == 'True' else zealot_mode_colors[zealot_mode]['light']
                marker = id_cluster_markers[id_cluster]
                markersize = id_align_sizes[id_align]
                
                style_config[label] = {
                    'color': color,
                    'linestyle': '-',
                    'marker': marker,
                    'markersize': markersize,
                    'group': 'Clustered'
                }
    else:
        # å¯¹äºzealot_numbersï¼Œä½¿ç”¨ç®€å•é…ç½®
        for i, label in enumerate(combo_labels):
            style_config[label] = {
                'color': colors[i % len(colors)],
                'linestyle': linestyles[i % len(linestyles)],
                'marker': markers[i % len(markers)],
                'markersize': 7,
                'group': 'Default'
            }
    
    return style_config


def get_variance_per_identity_style(identity_label: str, plot_type: str) -> Dict[str, Any]:
    """
    ä¸º variance per identity å›¾è¡¨ç”Ÿæˆç‰¹æ®Šçš„æ ·å¼é…ç½®
    
    Args:
        identity_label: å¸¦èº«ä»½æ ‡è¯†çš„æ ‡ç­¾ï¼Œå¦‚ "Random, ID-align=True (ID=1)"
        plot_type: å›¾è¡¨ç±»å‹
    
    Returns:
        dict: æ ·å¼é…ç½®
    """
    # æ‰©å±•é¢œè‰²è°ƒè‰²æ¿ï¼ˆå»é‡å¹¶ç¡®ä¿è¶³å¤Ÿçš„é¢œè‰²ï¼‰
    colors = [
        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b',
        '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#aec7e8', '#ffbb78',
        '#ff9896', '#c5b0d5', '#c49c94', '#f7b6d3', '#c7c7c7', '#dbdb8d',
        '#9edae5', '#ff1744', '#00e676', '#ffea00', '#651fff', '#ff6f00',
        '#00bcd4', '#795548', '#607d8b', '#e91e63', '#4caf50', '#ffc107'
    ]
    
    # é¢„å®šä¹‰çš„æ ‡ç­¾åˆ°é¢œè‰²ç´¢å¼•çš„æ˜ å°„ï¼ˆé¿å…å“ˆå¸Œå†²çªï¼‰
    label_color_mapping = {
        # morality_ratios å®éªŒçš„10ä¸ªåŸºç¡€æ ‡ç­¾
        'Random, ID-align=True, ID-cluster=False': 0,
        'Random, ID-align=True, ID-cluster=True': 1,
        'Random, ID-align=False, ID-cluster=False': 2,
        'Random, ID-align=False, ID-cluster=True': 3,
        'Clustered, ID-align=True, ID-cluster=False': 4,
        'Clustered, ID-align=True, ID-cluster=True': 5,
        'Clustered, ID-align=False, ID-cluster=False': 6,
        'Clustered, ID-align=False, ID-cluster=True': 7,
        'None, ID-cluster=False': 8,
        'None, ID-cluster=True': 9,
        # zealot_numbers å®éªŒçš„4ä¸ªåŸºç¡€æ ‡ç­¾
        'Random Zealots, Morality=0.0': 10,
        'Random Zealots, Morality=0.3': 11,
        'Clustered Zealots, Morality=0.0': 12,
        'Clustered Zealots, Morality=0.3': 13,
    }
    
    # çº¿å‹ç»„åˆï¼šå®çº¿ç”¨äº ID=1ï¼Œè™šçº¿ç”¨äº ID=-1
    linestyles = {
        '1': '-',      # å®çº¿ç”¨äº identity=1
        '-1': '--'     # è™šçº¿ç”¨äº identity=-1
    }
    
    # æ ‡è®°å½¢çŠ¶ï¼šåœ†å½¢ç”¨äº ID=1ï¼Œæ–¹å½¢ç”¨äº ID=-1
    markers = {
        '1': 'o',      # åœ†å½¢ç”¨äº identity=1
        '-1': 's'      # æ–¹å½¢ç”¨äº identity=-1
    }
    
    # æå–èº«ä»½å€¼
    identity_val = identity_label.split('(ID=')[-1].rstrip(')')
    
    # æå–åŸå§‹ç»„åˆæ ‡ç­¾
    base_label = identity_label.split(' (ID=')[0]
    
    # ä½¿ç”¨é¢„å®šä¹‰çš„æ˜ å°„æˆ–å›é€€åˆ°å“ˆå¸Œæ–¹æ³•
    if base_label in label_color_mapping:
        base_color_index = label_color_mapping[base_label]
    else:
        # å›é€€åˆ°å“ˆå¸Œæ–¹æ³•ï¼ˆç”¨äºæœªé¢„å®šä¹‰çš„æ ‡ç­¾ï¼‰
        base_color_index = abs(hash(base_label)) % len(colors)
    
    # ä¸ºID=-1ç»„é€‰æ‹©ä¸åŒçš„é¢œè‰²ï¼ˆç¡®ä¿æ— å†²çªï¼‰
    if identity_val == '-1':
        # å¯¹äºID=-1ï¼Œä½¿ç”¨ä¸€ä¸ªå›ºå®šçš„åç§»é‡ç¡®ä¿ä¸é‡å¤
        color_index = (base_color_index + 15) % len(colors)
    else:
        color_index = base_color_index
    
    return {
        'color': colors[color_index],
        'linestyle': linestyles.get(identity_val, '-'),
        'marker': markers.get(identity_val, 'o'),
        'markersize': 8 if identity_val == '1' else 6,  # ID=1 ç¨å¤§çš„æ ‡è®°
        'group': f'identity_{identity_val}'
    }


def get_combined_variance_per_identity_style(identity_label: str, plot_type: str) -> Dict[str, Any]:
    """
    ä¸ºåˆå¹¶çš„ variance per identity å›¾è¡¨ç”Ÿæˆæ ·å¼é…ç½®
    
    ç›¸åŒé…ç½®çš„ä¸¤æ¡çº¿ä½¿ç”¨ç›¸åŒé¢œè‰²å’Œæ ‡è®°ï¼Œä½†ç”¨å®çº¿/è™šçº¿åŒºåˆ†èº«ä»½ç»„
    
    Args:
        identity_label: å¸¦èº«ä»½æ ‡è¯†çš„æ ‡ç­¾ï¼Œå¦‚ "Random, ID-align=True (ID=+1)"
        plot_type: å›¾è¡¨ç±»å‹
    
    Returns:
        dict: æ ·å¼é…ç½®
    """
    # ä½¿ç”¨ä¸å•ç‹¬å‡½æ•°ç›¸åŒçš„æ‰©å±•é¢œè‰²è°ƒè‰²æ¿ï¼ˆå»é‡å¹¶ç¡®ä¿è¶³å¤Ÿçš„é¢œè‰²ï¼‰
    colors = [
        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b',
        '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#aec7e8', '#ffbb78',
        '#ff9896', '#c5b0d5', '#c49c94', '#f7b6d3', '#c7c7c7', '#dbdb8d',
        '#9edae5', '#ff1744', '#00e676', '#ffea00', '#651fff', '#ff6f00',
        '#00bcd4', '#795548', '#607d8b', '#e91e63', '#4caf50', '#ffc107'
    ]
    
    # ä½¿ç”¨ä¸å•ç‹¬å‡½æ•°ç›¸åŒçš„é¢„å®šä¹‰æ˜ å°„
    label_color_mapping = {
        # morality_ratios å®éªŒçš„10ä¸ªåŸºç¡€æ ‡ç­¾
        'Random, ID-align=True, ID-cluster=False': 0,
        'Random, ID-align=True, ID-cluster=True': 1,
        'Random, ID-align=False, ID-cluster=False': 2,
        'Random, ID-align=False, ID-cluster=True': 3,
        'Clustered, ID-align=True, ID-cluster=False': 4,
        'Clustered, ID-align=True, ID-cluster=True': 5,
        'Clustered, ID-align=False, ID-cluster=False': 6,
        'Clustered, ID-align=False, ID-cluster=True': 7,
        'None, ID-cluster=False': 8,
        'None, ID-cluster=True': 9,
        # zealot_numbers å®éªŒçš„4ä¸ªåŸºç¡€æ ‡ç­¾
        'Random Zealots, Morality=0.0': 10,
        'Random Zealots, Morality=0.3': 11,
        'Clustered Zealots, Morality=0.0': 12,
        'Clustered Zealots, Morality=0.3': 13,
    }
    
    # æå–èº«ä»½å€¼ï¼ˆ+1 æˆ– -1ï¼‰
    identity_val = identity_label.split('(ID=')[-1].rstrip(')')
    
    # æå–åŸå§‹ç»„åˆæ ‡ç­¾
    base_label = identity_label.split(' (ID=')[0]
    
    # ä½¿ç”¨é¢„å®šä¹‰çš„æ˜ å°„æˆ–å›é€€åˆ°å“ˆå¸Œæ–¹æ³•
    if base_label in label_color_mapping:
        color_index = label_color_mapping[base_label]
    else:
        # å›é€€åˆ°å“ˆå¸Œæ–¹æ³•ï¼ˆç”¨äºæœªé¢„å®šä¹‰çš„æ ‡ç­¾ï¼‰
        color_index = abs(hash(base_label)) % len(colors)
    
    # çº¿å‹ï¼š+1 ç”¨å®çº¿ï¼Œ-1 ç”¨è™šçº¿
    linestyle = '-' if identity_val == '+1' else '--'
    
    # æ ‡è®°ï¼šä½¿ç”¨é¢„å®šä¹‰æ˜ å°„ç¡®ä¿ä¸€è‡´æ€§
    markers = ['o', 's', '^', 'v', 'D', 'p', '*', 'h', 'H', 'X', '+', 'x']
    if base_label in label_color_mapping:
        marker_index = label_color_mapping[base_label] % len(markers)
    else:
        marker_index = abs(hash(base_label)) % len(markers)
    marker = markers[marker_index]
    
    # æ ‡è®°å¤§å°ï¼š+1 ç¨å¤§ï¼Œ-1 ç¨å°
    markersize = 8 if identity_val == '+1' else 6
    
    return {
        'color': colors[color_index],
        'linestyle': linestyle,
        'marker': marker,
        'markersize': markersize,
        'group': f'combined_identity_{identity_val}'
    }


def simplify_label(combo_label: str) -> str:
    """
    ç®€åŒ–ç»„åˆæ ‡ç­¾ï¼ˆå½“å‰ä¿æŒåŸå§‹æ ‡ç­¾ä»¥ç¡®ä¿å®Œæ•´å«ä¹‰ï¼‰
    
    Args:
    combo_label: åŸå§‹ç»„åˆæ ‡ç­¾
    
    Returns:
    str: ç®€åŒ–åçš„æ ‡ç­¾
    """
    return combo_label


def plot_results_with_manager(data_manager: ExperimentDataManager, 
                            plot_type: str,
                            enable_smoothing: bool = True,
                            target_step: int = 2,
                            smooth_method: str = 'savgol') -> None:
    """
    ä½¿ç”¨æ•°æ®ç®¡ç†å™¨ç»˜åˆ¶å®éªŒç»“æœå›¾è¡¨
    
    Args:
        data_manager: æ•°æ®ç®¡ç†å™¨å®ä¾‹  
        plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
        enable_smoothing: æ˜¯å¦å¯ç”¨å¹³æ»‘å’Œé‡é‡‡æ ·
        target_step: é‡é‡‡æ ·çš„ç›®æ ‡æ­¥é•¿ï¼ˆæ¯”å¦‚ä»æ­¥é•¿1å˜ä¸ºæ­¥é•¿2ï¼‰
        smooth_method: å¹³æ»‘æ–¹æ³• ('savgol', 'moving_avg', 'none')
    """
    # ä»æ•°æ®ç®¡ç†å™¨è·å–ç»˜å›¾æ•°æ®
    all_results, x_values, total_runs_per_combination = data_manager.convert_to_plotting_format(plot_type)
    
    if not all_results:
        print(f"âŒ No data found for {plot_type} plotting")
        return
    
    output_dir = str(data_manager.base_dir)
    metrics = ['mean_opinion', 'variance', 'identity_opinion_difference', 'polarization_index', 
               'variance_per_identity_1', 'variance_per_identity_-1', 'variance_per_identity_combined']
    metric_labels = {
        'mean_opinion': 'Mean Opinion',
        'variance': 'Opinion Variance',
        'identity_opinion_difference': 'Identity Opinion Difference',
        'polarization_index': 'Polarization Index',
        'variance_per_identity_1': 'Variance per Identity (+1)',
        'variance_per_identity_-1': 'Variance per Identity (-1)',
        'variance_per_identity_combined': 'Variance per Identity (Both Groups)'
    }
    
    x_label = 'Number of Zealots' if plot_type == 'zealot_numbers' else 'Morality Ratio (%)'
    
    # è®¡ç®—æ€»è¿è¡Œæ¬¡æ•°èŒƒå›´ï¼ˆç”¨äºæ–‡ä»¶åï¼‰
    min_runs = min(total_runs_per_combination.values()) if total_runs_per_combination else 0
    max_runs = max(total_runs_per_combination.values()) if total_runs_per_combination else 0
    
    if min_runs == max_runs:
        runs_suffix = f"_{min_runs}runs"
    else:
        runs_suffix = f"_{min_runs}-{max_runs}runs"
    
    # åˆ›å»º mean_plots æ–‡ä»¶å¤¹
    plot_folders = {
        'mean': os.path.join(output_dir, 'mean_plots')
    }
    
    os.makedirs(plot_folders['mean'], exist_ok=True)

    # è·å–æ ·å¼é…ç½®
    combo_labels = list(all_results.keys())
    style_config = get_enhanced_style_config(combo_labels, plot_type)
    
    print(f"\nğŸ“ Style Configuration for {plot_type}: {len(combo_labels)} combinations")
    print(f"âœ… Style configuration completed successfully")
    
    # ä¸ºæ¯ä¸ªæŒ‡æ ‡ç”Ÿæˆé«˜è´¨é‡çš„ mean plots
    for metric in metrics:
        if enable_smoothing:
            print(f"  Generating smoothed plot for {metric_labels[metric]} (step={target_step}, method={smooth_method})...")
        else:
            print(f"  Generating high-quality mean plot for {metric_labels[metric]}...")
        
        # é¢„å¤„ç†æ•°æ®ï¼šè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆä¸ºerror bandsåšå‡†å¤‡ï¼‰
        processed_data = {}
        
        if metric == 'variance_per_identity_combined':
            # å¯¹äºåˆå¹¶çš„ variance per identity å›¾è¡¨ï¼Œä¸ºæ¯ä¸ªç»„åˆåˆ›å»ºä¸¤æ¡çº¿
            for combo_label, results in all_results.items():
                # å¤„ç† identity=1 çš„æ•°æ®
                metric_data_1 = results['variance_per_identity_1']
                means_1, stds_1 = [], []
                for i, x_runs in enumerate(metric_data_1):
                    valid_runs = [val for val in x_runs if not np.isnan(val)]
                    if valid_runs:
                        means_1.append(np.mean(valid_runs))
                        stds_1.append(np.std(valid_runs, ddof=1) if len(valid_runs) > 1 else 0.0)
                    else:
                        means_1.append(np.nan)
                        stds_1.append(np.nan)
                
                # å¤„ç† identity=-1 çš„æ•°æ®
                metric_data_neg1 = results['variance_per_identity_-1']
                means_neg1, stds_neg1 = [], []
                for i, x_runs in enumerate(metric_data_neg1):
                    valid_runs = [val for val in x_runs if not np.isnan(val)]
                    if valid_runs:
                        means_neg1.append(np.mean(valid_runs))
                        stds_neg1.append(np.std(valid_runs, ddof=1) if len(valid_runs) > 1 else 0.0)
                    else:
                        means_neg1.append(np.nan)
                        stds_neg1.append(np.nan)
                
                # åˆ›å»ºä¸¤æ¡çº¿çš„æ•°æ®
                processed_data[f"{combo_label} (ID=+1)"] = {
                    'means': np.array(means_1),
                    'stds': np.array(stds_1),
                    'identity': '+1',
                    'base_combo': combo_label
                }
                processed_data[f"{combo_label} (ID=-1)"] = {
                    'means': np.array(means_neg1),
                    'stds': np.array(stds_neg1),
                    'identity': '-1',
                    'base_combo': combo_label
                }
        elif metric.startswith('variance_per_identity') and metric != 'variance_per_identity_combined':
            # å¯¹äºå•ç‹¬çš„ variance per identity æŒ‡æ ‡ï¼Œæ¯ä¸ªç»„åˆæ ‡ç­¾ä¼šè¢«æ‹†åˆ†ä¸ºä¸¤æ¡çº¿
            identity_suffix = metric.split('_')[-1]  # '1' or '-1'
            
            for combo_label, results in all_results.items():
                metric_data = results[metric]
                means, stds = [], []
                
                for i, x_runs in enumerate(metric_data):
                    valid_runs = [val for val in x_runs if not np.isnan(val)]
                    if valid_runs:
                        means.append(np.mean(valid_runs))
                        stds.append(np.std(valid_runs, ddof=1) if len(valid_runs) > 1 else 0.0)
                    else:
                        means.append(np.nan)
                        stds.append(np.nan)
                
                # ä¸º variance per identity åˆ›å»ºå¸¦èº«ä»½æ ‡è¯†çš„æ ‡ç­¾
                identity_label = f"{combo_label} (ID={identity_suffix})"
                processed_data[identity_label] = {
                    'means': np.array(means),
                    'stds': np.array(stds)
                }
        else:
            # å¯¹äºå…¶ä»–æŒ‡æ ‡ï¼Œè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
            for combo_label, results in all_results.items():
                metric_data = results[metric]
                means, stds = [], []
                
                for i, x_runs in enumerate(metric_data):
                    valid_runs = [val for val in x_runs if not np.isnan(val)]
                    if valid_runs:
                        means.append(np.mean(valid_runs))
                        stds.append(np.std(valid_runs, ddof=1) if len(valid_runs) > 1 else 0.0)
                    else:
                        means.append(np.nan)
                        stds.append(np.nan)
                
                processed_data[combo_label] = {
                    'means': np.array(means),
                    'stds': np.array(stds)
                }
        
        # æ·»åŠ è¿è¡Œæ¬¡æ•°ä¿¡æ¯åˆ°æ ‡é¢˜ï¼ˆæ˜¾ç¤ºæ€»runæ•°ï¼‰
        if plot_type == 'zealot_numbers':
            title_suffix = f" with Error Bands ({min_runs}-{max_runs} total runs)" if min_runs != max_runs else f" with Error Bands ({min_runs} total runs)"
        else:
            title_suffix = f" ({min_runs}-{max_runs} total runs)" if min_runs != max_runs else f" ({min_runs} total runs)"
        
        # é«˜è´¨é‡å‡å€¼æ›²çº¿å›¾
        # å¯¹äº variance per identityï¼Œä½¿ç”¨æ›´å¤§çš„å›¾è¡¨ä»¥å®¹çº³æ›´å¤šçº¿æ¡
        if metric.startswith('variance_per_identity'):
            plt.figure(figsize=(24, 14) if plot_type == 'morality_ratios' else (20, 12))
        else:
            plt.figure(figsize=(20, 12) if plot_type == 'morality_ratios' else (18, 10))
            
        for display_label, data in processed_data.items():
            # å¯¹äº variance per identityï¼Œéœ€è¦ä»æ˜¾ç¤ºæ ‡ç­¾ä¸­æå–åŸå§‹ç»„åˆæ ‡ç­¾æ¥è·å–runsä¿¡æ¯
            if metric.startswith('variance_per_identity'):
                # ä» "Original Label (ID=1)" ä¸­æå– "Original Label"
                if metric == 'variance_per_identity_combined':
                    # å¯¹äºåˆå¹¶å›¾è¡¨ï¼Œä½¿ç”¨ base_combo å­—æ®µ
                    original_combo_label = data.get('base_combo', display_label.split(' (ID=')[0])
                else:
                    original_combo_label = display_label.split(' (ID=')[0]
                runs_info = total_runs_per_combination.get(original_combo_label, 0)
            else:
                original_combo_label = display_label
                runs_info = total_runs_per_combination.get(display_label, 0)
            
            # åº”ç”¨å¹³æ»‘å’Œé‡é‡‡æ ·
            if enable_smoothing:
                smoothed_x, smoothed_means = resample_and_smooth_data(
                    np.array(x_values), data['means'], 
                    target_step=target_step, 
                    smooth_window=3
                )
                
                # æœ€ç»ˆå¹³æ»‘
                final_means = apply_final_smooth(smoothed_means, method=smooth_method, window=5)
                
                # ä½¿ç”¨å¹³æ»‘åçš„æ•°æ®
                plot_x, plot_y = smoothed_x, final_means
                
                # åŒæ—¶æ›´æ–°æ ‡ç­¾æ˜¾ç¤ºå¹³æ»‘ä¿¡æ¯
                short_label = simplify_label(display_label)
                label_with_runs = f"{short_label} (n={runs_info}, smoothed)"
            else:
                plot_x, plot_y = np.array(x_values), data['means']
                short_label = simplify_label(display_label)
                label_with_runs = f"{short_label} (n={runs_info})"
            
            # ä¸ºä¸åŒç±»å‹çš„ variance per identity å›¾è¡¨é€‰æ‹©åˆé€‚çš„æ ·å¼é…ç½®å‡½æ•°
            if metric == 'variance_per_identity_combined':
                style = get_combined_variance_per_identity_style(display_label, plot_type)
            elif metric.startswith('variance_per_identity'):
                style = get_variance_per_identity_style(display_label, plot_type)
            else:
                style = style_config.get(display_label, {})
            
            # è·å–é¢œè‰²å’Œæ ·å¼
            line_color = style.get('color', 'blue')
            
            # ç»˜åˆ¶ä¸»è¦çš„å‡å€¼æ›²çº¿
            plt.plot(plot_x, plot_y, label=label_with_runs, 
                    color=line_color,
                    linestyle=style.get('linestyle', '-'),
                    marker=style.get('marker', 'o'), 
                    linewidth=3.5, markersize=style.get('markersize', 10), alpha=0.85,
                    markeredgewidth=2, markeredgecolor='white')
            
            # ä¸º zealot_numbers æ·»åŠ  error bandsï¼ˆæ ‡å‡†å·®èŒƒå›´ï¼‰
            if plot_type == 'zealot_numbers' and 'stds' in data and not enable_smoothing:
                means = data['means']
                stds = data['stds']
                
                # è®¡ç®—ä¸Šä¸‹è¾¹ç•Œ
                upper_bound = means + stds
                lower_bound = means - stds
                
                # ç»˜åˆ¶ error bandsï¼ˆä½¿ç”¨ç›¸åŒé¢œè‰²ä½†é€æ˜åº¦è¾ƒä½ï¼‰
                plt.fill_between(x_values, lower_bound, upper_bound, 
                               color=line_color, alpha=0.2, 
                               linewidth=0, interpolate=True)
        
        plt.xlabel(x_label, fontsize=16)
        plt.ylabel(metric_labels[metric], fontsize=16)
        plt.title(f'{metric_labels[metric]} vs {x_label}{title_suffix}', fontsize=18, fontweight='bold')
        
        # æ ¹æ®æŒ‡æ ‡ç±»å‹å’Œçº¿æ¡æ•°é‡è°ƒæ•´å›¾ä¾‹å¸ƒå±€
        if metric == 'variance_per_identity_combined':
            # åˆå¹¶çš„ variance per identity å›¾è¡¨ï¼šæ¯ä¸ªç»„åˆ2æ¡çº¿
            if plot_type == 'morality_ratios':
                # 20æ¡çº¿ï¼Œä½¿ç”¨4åˆ—
                plt.legend(bbox_to_anchor=(0.5, -0.20), loc='upper center', ncol=4, 
                          fontsize=10, frameon=True, fancybox=True, shadow=True)
            else:
                # 8æ¡çº¿ï¼Œä½¿ç”¨3åˆ—
                plt.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=3, fontsize=11)
        elif metric.startswith('variance_per_identity'):
            # å•ç‹¬çš„ variance per identity å›¾è¡¨æœ‰æ›´å¤šçº¿æ¡ï¼Œéœ€è¦æ›´å¤šåˆ—å’Œæ›´å°å­—ä½“
            if plot_type == 'morality_ratios':
                # 20æ¡çº¿ï¼Œä½¿ç”¨4åˆ—
                plt.legend(bbox_to_anchor=(0.5, -0.20), loc='upper center', ncol=4, 
                          fontsize=10, frameon=True, fancybox=True, shadow=True)
            else:
                # 8æ¡çº¿ï¼Œä½¿ç”¨3åˆ—
                plt.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=3, fontsize=11)
        else:
            # å…¶ä»–æŒ‡æ ‡ä¿æŒåŸæœ‰å¸ƒå±€
            if plot_type == 'morality_ratios':
                plt.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=3, 
                          fontsize=12, frameon=True, fancybox=True, shadow=True)
            else:
                plt.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=2, fontsize=12)
        
        plt.grid(True, alpha=0.3, linestyle='--')
        plt.tight_layout()
        
        # ä¸ºæ–‡ä»¶åæ·»åŠ å¹³æ»‘æ ‡è¯†
        if enable_smoothing:
            if plot_type == 'zealot_numbers':
                filename = f"{plot_type}_{metric}_smoothed_step{target_step}_{smooth_method}{runs_suffix}.png"
            else:
                filename = f"{plot_type}_{metric}_smoothed_step{target_step}_{smooth_method}{runs_suffix}.png"
        else:
            if plot_type == 'zealot_numbers':
                filename = f"{plot_type}_{metric}_mean_with_error_bands{runs_suffix}.png"
            else:
                filename = f"{plot_type}_{metric}_mean{runs_suffix}.png"
        filepath = os.path.join(plot_folders['mean'], filename)
        
        # é«˜è´¨é‡PNGä¿å­˜ (DPI 300)
        plt.savefig(filepath, dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='white', 
                   format='png', transparent=False, 
                   pad_inches=0.1, metadata={'Creator': 'Zealot Morality Analysis'})
        
        plt.close()
    
    print(f"  âœ… Generated high-quality mean plots for {plot_type}:")
    print(f"     - Mean line plots: {plot_folders['mean']}")


# =====================================
# é«˜çº§æ¥å£å‡½æ•°
# =====================================

def run_and_accumulate_data(output_dir: str = "results/zealot_morality_analysis", 
                           num_runs: int = 5, max_zealots: int = 50, max_morality: int = 30,
                           batch_name: str = "", num_processes: int = 1):
    """
    è¿è¡Œæµ‹è¯•å¹¶ä½¿ç”¨æ–°çš„æ•°æ®ç®¡ç†å™¨ä¿å­˜æ•°æ®ï¼ˆç¬¬ä¸€éƒ¨åˆ†ï¼‰
    
    Args:
    output_dir: è¾“å‡ºç›®å½•
    num_runs: æœ¬æ¬¡è¿è¡Œçš„æ¬¡æ•°
    max_zealots: æœ€å¤§zealotæ•°é‡
    max_morality: æœ€å¤§morality ratio (%)
    batch_name: æ‰¹æ¬¡åç§°ï¼Œç”¨äºæ ‡è¯†æœ¬æ¬¡è¿è¡Œ
    num_processes: å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œ1è¡¨ç¤ºä¸²è¡Œæ‰§è¡Œ
    """
    print("ğŸ”¬ Running Tests and Accumulating Data with New Data Manager")
    print("=" * 70)
    
    start_time = time.time()
    
    # åˆ›å»ºæ•°æ®ç®¡ç†å™¨
    data_manager = ExperimentDataManager(output_dir)
    
    # è·å–å‚æ•°ç»„åˆ
    combinations = create_config_combinations()
    
    if not batch_name:
        batch_name = time.strftime("%Y%m%d_%H%M%S")
    
    # ç”Ÿæˆæ‰¹æ¬¡ç§å­ï¼Œç¡®ä¿ä¸åŒæ‰¹æ¬¡äº§ç”Ÿä¸åŒçš„éšæœºç»“æœ
    batch_seed = int(time.time() * 1000) % (2**31)  # ä½¿ç”¨æ—¶é—´æˆ³ç”Ÿæˆç§å­
    
    print(f"ğŸ“Š Batch Configuration:")
    print(f"   Batch name: {batch_name}")
    print(f"   Number of runs this batch: {num_runs}")
    print(f"   Max zealots: {max_zealots}")
    print(f"   Max morality ratio: {max_morality}%")
    print(f"   Parallel processes: {num_processes} ({'Parallel' if num_processes > 1 else 'Serial'})")
    print(f"   Output directory: {output_dir}")
    print(f"   Storage format: Parquet (optimized for space and speed)")
    print()
    
    # # === å¤„ç†å›¾1ï¼šxè½´ä¸ºzealot numbers ===
    # print("ğŸ“ˆ Running Test Type 1: Zealot Numbers Analysis")
    # print("-" * 50)
    
    # plot1_start_time = time.time()
    
    # zealot_x_values = list(range(0, max_zealots + 1, 2))  # 0, 1, 2, ..., n
    # zealot_results = {}
    
    # for combo in combinations['zealot_numbers']:
    #     print(f"Running combination: {combo['label']}")
    #     results = run_parameter_sweep('zealot_numbers', combo, zealot_x_values, num_runs, num_processes, batch_seed)
    #     zealot_results[combo['label']] = results
    
    # # ä½¿ç”¨æ–°çš„æ•°æ®ç®¡ç†å™¨ä¿å­˜zealot numbersçš„æ•°æ®
    # zealot_batch_metadata = {
    #     'batch_id': batch_name,
    #     'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
    #     'experiment_type': 'zealot_numbers',
    #     'num_runs': num_runs,
    #     'max_zealots': max_zealots,
    #     'x_range': [0, max_zealots],
    #     'combinations_count': len(combinations['zealot_numbers'])
    # }
    
    # save_data_with_manager(data_manager, 'zealot_numbers', zealot_x_values, zealot_results, zealot_batch_metadata)
    
    # plot1_end_time = time.time()
    # plot1_duration = plot1_end_time - plot1_start_time
    
    # print(f"â±ï¸  Test Type 1 completed in: {format_duration(plot1_duration)}")
    # print()
    
    # === å¤„ç†å›¾2ï¼šxè½´ä¸ºmorality ratio ===
    print("ğŸ“ˆ Running Test Type 2: Morality Ratio Analysis")
    print("-" * 50)
    
    plot2_start_time = time.time()
    
    morality_x_values = list(range(0, max_morality + 1, 2))  # 0, 1, 2, ..., n
    morality_results = {}
    
    for combo in combinations['morality_ratios']:
        print(f"Running combination: {combo['label']}")
        results = run_parameter_sweep('morality_ratios', combo, morality_x_values, num_runs, num_processes, batch_seed)
        morality_results[combo['label']] = results
    
    # ä½¿ç”¨æ–°çš„æ•°æ®ç®¡ç†å™¨ä¿å­˜morality ratioçš„æ•°æ®
    morality_batch_metadata = {
        'batch_id': batch_name,
        'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
        'experiment_type': 'morality_ratios', 
        'num_runs': num_runs,
        'max_morality': max_morality,
        'x_range': [0, max_morality],
        'combinations_count': len(combinations['morality_ratios'])
    }
    
    save_data_with_manager(data_manager, 'morality_ratios', morality_x_values, morality_results, morality_batch_metadata)
    
    plot2_end_time = time.time()
    plot2_duration = plot2_end_time - plot2_start_time
    
    print(f"â±ï¸  Test Type 2 completed in: {format_duration(plot2_duration)}")
    print()
    
    # è®¡ç®—æ€»è€—æ—¶
    end_time = time.time()
    elapsed_time = end_time - start_time
    hours, remainder = divmod(elapsed_time, 3600)
    minutes, seconds = divmod(remainder, 60)
    
    print("\n" + "=" * 70)
    print("ğŸ‰ Data Collection Completed Successfully!")
    print(f"ğŸ“Š Batch '{batch_name}' with {num_runs} runs per parameter point")
    print()
    print("â±ï¸  Timing Summary:")
    # print(f"   Test Type 1 (Zealot Numbers): {format_duration(plot1_duration)}")
    print(f"   Test Type 2 (Morality Ratios): {format_duration(plot2_duration)}")
    print(f"   Total execution time: {format_duration(elapsed_time)}")
    print(f"ğŸ“ Data saved using Parquet format in: {output_dir}/")
    
    # ä¿å­˜å®éªŒé…ç½®åˆ°æ•°æ®ç®¡ç†å™¨
    experiment_config = {
        'batch_name': batch_name,
        'num_runs': num_runs,
        'max_zealots': max_zealots,
        'max_morality': max_morality,
        'elapsed_time': elapsed_time,
        'total_combinations': len(combinations['zealot_numbers']) + len(combinations['morality_ratios'])
    }
    data_manager.save_experiment_config(experiment_config)
    
    # æ˜¾ç¤ºæ•°æ®ç®¡ç†å™¨æ‘˜è¦
    print("\n" + data_manager.export_summary_report())


def plot_from_accumulated_data(output_dir: str = "results/zealot_morality_analysis",
                             enable_smoothing: bool = True,
                             target_step: int = 2,
                             smooth_method: str = 'savgol'):
    """
    ä»æ–°çš„æ•°æ®ç®¡ç†å™¨ä¸­è¯»å–æ•°æ®å¹¶ç”Ÿæˆå›¾è¡¨ï¼ˆç¬¬äºŒéƒ¨åˆ†ï¼‰
    
    æ³¨æ„ï¼šzealot_numberså›¾è¡¨å°†å¼ºåˆ¶å…³é—­å¹³æ»‘ä»¥æ˜¾ç¤ºerror bandsï¼Œ
         morality_ratioså›¾è¡¨å°†ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å¹³æ»‘è®¾ç½®
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        enable_smoothing: æ˜¯å¦å¯ç”¨å¹³æ»‘å¤„ç†ï¼ˆä»…å½±å“morality_ratioså›¾è¡¨ï¼‰
        target_step: é‡é‡‡æ ·æ­¥é•¿ï¼ˆ2è¡¨ç¤ºä»101ä¸ªç‚¹å˜ä¸º51ä¸ªç‚¹ï¼‰
        smooth_method: å¹³æ»‘æ–¹æ³• ('savgol', 'moving_avg', 'none')
    """
    print("ğŸ“Š Generating Plots from Data Manager")
    if enable_smoothing:
        print(f"ğŸ¯ Smoothing enabled: step={target_step}, method={smooth_method}")
    print("=" * 70)
    
    start_time = time.time()
    
    # åˆ›å»ºæ•°æ®ç®¡ç†å™¨
    data_manager = ExperimentDataManager(output_dir)
    
    # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
    print("\n" + data_manager.export_summary_report())
    
    # ç”Ÿæˆzealot numberså›¾è¡¨ï¼ˆå…³é—­å¹³æ»‘ä»¥æ˜¾ç¤ºerror bandsï¼‰
    print("\nğŸ“ˆ Generating Zealot Numbers Plots...")
    zealot_summary = data_manager.get_experiment_summary('zealot_numbers')
    if zealot_summary['total_records'] > 0:
        plot_results_with_manager(data_manager, 'zealot_numbers', 
                                False, target_step, smooth_method)  # å¼ºåˆ¶å…³é—­å¹³æ»‘
        print(f"âœ… Generated {len(zealot_summary['combinations'])} zealot numbers plots with error bands")
    else:
        print("âŒ No zealot numbers data found")
    
    # ç”Ÿæˆmorality ratioså›¾è¡¨ï¼ˆä¿æŒç”¨æˆ·è®¾ç½®çš„å¹³æ»‘é€‰é¡¹ï¼‰
    print("\nğŸ“ˆ Generating Morality Ratios Plots...")
    morality_summary = data_manager.get_experiment_summary('morality_ratios')
    if morality_summary['total_records'] > 0:
        plot_results_with_manager(data_manager, 'morality_ratios',
                                enable_smoothing, target_step, smooth_method)
        if enable_smoothing:
            print(f"âœ… Generated {len(morality_summary['combinations'])} morality ratios plots with smoothing")
        else:
            print(f"âœ… Generated {len(morality_summary['combinations'])} morality ratios plots without smoothing")
    else:
        print("âŒ No morality ratios data found")
    
    # è®¡ç®—æ€»è€—æ—¶
    end_time = time.time()
    elapsed_time = end_time - start_time
    
    print("\n" + "=" * 70)
    print("ğŸ‰ Plot Generation Completed Successfully!")
    print(f"ğŸ“Š Generated plots from Parquet data files")
    print(f"ğŸ“ˆ Zealot Numbers: Error bands enabled (smoothing disabled)")
    if enable_smoothing:
        print(f"ğŸ“ˆ Morality Ratios: Smoothing enabled (step {target_step}, {smooth_method})")
    else:
        print(f"ğŸ“ˆ Morality Ratios: Smoothing disabled")
    print(f"â±ï¸  Total plotting time: {format_duration(elapsed_time)}")
    print(f"ğŸ“ Plots saved to: {output_dir}/mean_plots/")


def run_zealot_morality_analysis(output_dir: str = "results/zealot_morality_analysis", 
                                num_runs: int = 5, max_zealots: int = 50, max_morality: int = 30, num_processes: int = 1):
    """
    è¿è¡Œå®Œæ•´çš„zealotå’Œmoralityåˆ†æå®éªŒï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    
    Args:
    output_dir: è¾“å‡ºç›®å½•
    num_runs: æ¯ä¸ªå‚æ•°ç‚¹çš„è¿è¡Œæ¬¡æ•°
    max_zealots: æœ€å¤§zealotæ•°é‡
    max_morality: æœ€å¤§morality ratio (%)
    num_processes: å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œ1è¡¨ç¤ºä¸²è¡Œæ‰§è¡Œ
    """
    print("ğŸ”¬ Starting Complete Zealot and Morality Analysis Experiment")
    print("=" * 70)
    
    # ç¬¬ä¸€æ­¥ï¼šè¿è¡Œæµ‹è¯•å¹¶ç´¯ç§¯æ•°æ®
    run_and_accumulate_data(output_dir, num_runs, max_zealots, max_morality, "", num_processes)
    
    # ç¬¬äºŒæ­¥ï¼šä»ç´¯ç§¯æ•°æ®ç”Ÿæˆå›¾è¡¨
    plot_from_accumulated_data(output_dir)


def run_no_zealot_morality_data(output_dir: str = "results/zealot_morality_analysis", 
                               num_runs: int = 5, max_morality: int = 30,
                               batch_name: str = "", num_processes: int = 1):
    """
    å•ç‹¬è¿è¡Œ no zealot çš„ morality ratio æ•°æ®æ”¶é›†ï¼ˆä½¿ç”¨æ–°æ•°æ®ç®¡ç†å™¨ï¼‰
    
    Args:
    output_dir: è¾“å‡ºç›®å½•
    num_runs: æ¯ä¸ªå‚æ•°ç‚¹çš„è¿è¡Œæ¬¡æ•°
    max_morality: æœ€å¤§ morality ratio (%)
    batch_name: æ‰¹æ¬¡åç§°
    num_processes: å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œ1è¡¨ç¤ºä¸²è¡Œæ‰§è¡Œ
    """
    print("ğŸ”¬ Running No Zealot Morality Ratio Data Collection with New Data Manager")
    print("=" * 70)
    
    start_time = time.time()
    
    # åˆ›å»ºæ•°æ®ç®¡ç†å™¨
    data_manager = ExperimentDataManager(output_dir)
    
    # è·å–æ‰€æœ‰å‚æ•°ç»„åˆ
    combinations = create_config_combinations()
    
    # åªé€‰æ‹© zealot_mode ä¸º 'none' çš„ç»„åˆ
    no_zealot_combinations = [combo for combo in combinations['morality_ratios'] 
                             if combo['zealot_mode'] == 'none']
    
    if not no_zealot_combinations:
        print("âŒ æ²¡æœ‰æ‰¾åˆ° zealot_mode='none' çš„ç»„åˆ")
        return
    
    if not batch_name:
        batch_name = f"no_zealot_{time.strftime('%Y%m%d_%H%M%S')}"
    
    # ç”Ÿæˆæ‰¹æ¬¡ç§å­ï¼Œç¡®ä¿ä¸åŒæ‰¹æ¬¡äº§ç”Ÿä¸åŒçš„éšæœºç»“æœ
    batch_seed = int(time.time() * 1000) % (2**31)  # ä½¿ç”¨æ—¶é—´æˆ³ç”Ÿæˆç§å­
    
    print(f"ğŸ“Š No Zealot Batch Configuration:")
    print(f"   Batch name: {batch_name}")
    print(f"   Number of runs this batch: {num_runs}")
    print(f"   Max morality ratio: {max_morality}%")
    print(f"   Number of no-zealot combinations: {len(no_zealot_combinations)}")
    print(f"   Output directory: {output_dir}")
    print(f"   Storage format: Parquet (optimized for space and speed)")
    print()
    
    # è®¾ç½® morality ratio çš„ x è½´å–å€¼
    morality_x_values = list(range(0, max_morality + 1, 2))  # 0, 2, 4, ..., max_morality
    morality_results = {}
    
    print("ğŸ“ˆ Running No Zealot Morality Ratio Analysis")
    print("-" * 50)
    
    for combo in no_zealot_combinations:
        print(f"Running no-zealot combination: {combo['label']}")
        results = run_parameter_sweep('morality_ratios', combo, morality_x_values, num_runs, num_processes, batch_seed)
        morality_results[combo['label']] = results
    
    # ä½¿ç”¨æ–°çš„æ•°æ®ç®¡ç†å™¨ä¿å­˜ no zealot morality ratio æ•°æ®
    no_zealot_batch_metadata = {
        'batch_id': batch_name,
        'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
        'experiment_type': 'morality_ratios_no_zealot',
        'num_runs': num_runs,
        'max_morality': max_morality,
        'x_range': [0, max_morality],
        'combinations_count': len(no_zealot_combinations),
        'special_conditions': 'no_zealot_only'
    }
    
    save_data_with_manager(data_manager, 'morality_ratios', morality_x_values, morality_results, no_zealot_batch_metadata)
    
    # è®¡ç®—è€—æ—¶
    end_time = time.time()
    elapsed_time = end_time - start_time
    
    print("\n" + "=" * 70)
    print("ğŸ‰ No Zealot Data Collection Completed Successfully!")
    print(f"ğŸ“Š Batch '{batch_name}' with {num_runs} runs per parameter point")
    print(f"â±ï¸  Total execution time: {format_duration(elapsed_time)}")
    print(f"ğŸ“ Data saved using Parquet format in: {output_dir}/")
    
    # ä¿å­˜å®éªŒé…ç½®åˆ°æ•°æ®ç®¡ç†å™¨
    experiment_config = {
        'batch_name': batch_name,
        'num_runs': num_runs,
        'max_morality': max_morality,
        'elapsed_time': elapsed_time,
        'total_combinations': len(no_zealot_combinations),
        'experiment_type': 'no_zealot_only'
    }
    data_manager.save_experiment_config(experiment_config)
    
    # æ˜¾ç¤ºæ•°æ®ç®¡ç†å™¨æ‘˜è¦
    print("\n" + data_manager.export_summary_report())


if __name__ == "__main__":
    # æ–°çš„åˆ†ç¦»å¼ä½¿ç”¨æ–¹æ³•ï¼š
    
    # å¼€å§‹è®¡æ—¶
    main_start_time = time.time()
    
    # æ–¹æ³•1ï¼šåˆ†ä¸¤æ­¥è¿è¡Œ
    # ç¬¬ä¸€æ­¥ï¼šè¿è¡Œæµ‹è¯•å¹¶ç§¯ç´¯æ•°æ®ï¼ˆå¯ä»¥å¤šæ¬¡è¿è¡Œä»¥ç§¯ç´¯æ›´å¤šæ•°æ®ï¼‰
    print("=" * 50)
    print("ğŸš€ ç¤ºä¾‹ï¼šåˆ†æ­¥éª¤è¿è¡Œå®éªŒ")
    print("=" * 50)
    
    # æ•°æ®æ”¶é›†é˜¶æ®µ
    data_collection_start_time = time.time()
    
    # å¯ä»¥å¤šæ¬¡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥ç§¯ç´¯æ•°æ®ï¼š
    run_and_accumulate_data(
        output_dir="results/zealot_morality_analysis",
        num_runs=200,  # æ¯æ¬¡è¿è¡Œ200è½®æµ‹è¯•
        max_zealots=100,  
        max_morality=100,
        # batch_name="batch_001"  # å¯é€‰ï¼šç»™æ‰¹æ¬¡å‘½å
        num_processes=8  # ä½¿ç”¨8ä¸ªè¿›ç¨‹è¿›è¡Œå¹¶è¡Œè®¡ç®—
    )
    
    data_collection_end_time = time.time()
    data_collection_duration = data_collection_end_time - data_collection_start_time
    

    # ç¬¬äºŒæ­¥ï¼šç»˜å›¾é˜¶æ®µ

    plotting_start_time = time.time()

    plot_from_accumulated_data(
        output_dir="results/zealot_morality_analysis",
        enable_smoothing=False,       # ä¸å¯ç”¨å¹³æ»‘
        target_step=2,             # ä»æ­¥é•¿1é‡é‡‡æ ·åˆ°æ­¥é•¿2ï¼ˆ101ä¸ªç‚¹â†’51ä¸ªç‚¹ï¼‰
        smooth_method='savgol'     # ä½¿ç”¨Savitzky-Golayå¹³æ»‘
    )
    
    plotting_end_time = time.time()
    plotting_duration = plotting_end_time - plotting_start_time
    
    # è®¡ç®—æ€»è€—æ—¶
    main_end_time = time.time()
    total_duration = main_end_time - main_start_time
    
    # æ˜¾ç¤ºè€—æ—¶æ€»ç»“
    print("\n" + "ğŸ•’" * 50)
    print("â±ï¸  å®Œæ•´å®éªŒè€—æ—¶æ€»ç»“")
    print("ğŸ•’" * 50)
    print(f"ğŸ“Š æ•°æ®æ”¶é›†é˜¶æ®µè€—æ—¶: {format_duration(data_collection_duration)}")
    print(f"ğŸ“ˆ å›¾è¡¨ç”Ÿæˆé˜¶æ®µè€—æ—¶: {format_duration(plotting_duration)}")
    print(f"ğŸ¯ æ€»è€—æ—¶: {format_duration(total_duration)}")
    print("ğŸ•’" * 50) 