"""
Zealot and Morality Analysis Experiment

This experiment analyzes the effects of zealot numbers and morality ratios on various system metrics.
It generates two types of plots:
1. X-axis: Number of zealots
2. X-axis: Morality ratio

For each plot type, it generates 4 different Y-axis metrics:
- Mean opinion
- Variance 
- Variance per identity
- Polarization index

Total: 8 plots (2 types Ã— 4 metrics)
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import copy
import time
from tqdm import tqdm
from typing import Dict, List, Tuple, Any
import itertools
from glob import glob

from polarization_triangle.core.config import SimulationConfig, high_polarization_config
from polarization_triangle.core.simulation import Simulation
from polarization_triangle.analysis.statistics import (
    calculate_mean_opinion,
    calculate_variance_metrics,
    calculate_identity_statistics,
    get_polarization_index
)


def create_config_combinations():
    """
    åˆ›å»ºå‚æ•°ç»„åˆ
    
    Returns:
    dict: åŒ…å«ä¸¤ç±»å›¾çš„å‚æ•°ç»„åˆ
    """
    # åŸºç¡€é…ç½®
    base_config = copy.deepcopy(high_polarization_config)
    base_config.steps = 300  # è®¾ç½®è¿è¡Œæ­¥æ•°
    
    combinations = {
        'zealot_numbers': [],  # å›¾1ï¼šxè½´ä¸ºzealot numbers
        'morality_ratios': []  # å›¾2ï¼šxè½´ä¸ºmorality ratio
    }
    
    # å›¾1ï¼šxè½´ä¸ºzealot numbersçš„ç»„åˆ
    # æ¯”è¾ƒ "clustering zealots or not" å’Œ morality ratio
    zealot_clustering_options = ['random', 'clustered']
    morality_ratios_for_zealot_plot = [0.0, 0.3]  # ä¸¤ä¸ªä¸åŒçš„morality ratioè¿›è¡Œæ¯”è¾ƒ
    
    for clustering in zealot_clustering_options:
        for morality_ratio in morality_ratios_for_zealot_plot:
            combo = {
                'zealot_mode': clustering,
                'morality_rate': morality_ratio,
                'zealot_identity_allocation': True,  # å›ºå®šä¸ºTrue
                'cluster_identity': False,  # å›ºå®šä¸ºrandom identity distribution
                'label': f'{clustering.capitalize()} Zealots, Morality={morality_ratio}',
                'steps': base_config.steps
            }
            combinations['zealot_numbers'].append(combo)
    
    # å›¾2ï¼šxè½´ä¸ºmorality ratioçš„ç»„åˆ
    # æ¯”è¾ƒ "clustering zealots or not", "zealots aligned with identity", "identity distribution"
    zealot_modes = ['random', 'clustered']
    zealot_identity_alignments = [True, False]  # zealots aligned with identity
    identity_distributions = [False, True]  # random vs clustered identity distribution
    
    # å›ºå®šzealotæ•°é‡ä¸º20ï¼ˆä¸­ç­‰æ•°é‡ï¼‰
    fixed_zealot_count = 20
    
    for zealot_mode in zealot_modes:
        for zealot_identity in zealot_identity_alignments:
            for identity_dist in identity_distributions:
                combo = {
                    'zealot_count': fixed_zealot_count,
                    'zealot_mode': zealot_mode,
                    'zealot_identity_allocation': zealot_identity,
                    'cluster_identity': identity_dist,
                    'label': f'{zealot_mode.capitalize()}, ID-align={zealot_identity}, ID-cluster={identity_dist}',
                    'steps': base_config.steps
                }
                combinations['morality_ratios'].append(combo)
    
    return combinations


def run_single_simulation(config: SimulationConfig, steps: int = 500) -> Dict[str, float]:
    """
    è¿è¡Œå•æ¬¡æ¨¡æ‹Ÿå¹¶è·å–æœ€ç»ˆçŠ¶æ€çš„ç»Ÿè®¡æŒ‡æ ‡
    
    Args:
    config: æ¨¡æ‹Ÿé…ç½®
    steps: è¿è¡Œæ­¥æ•°
    
    Returns:
    dict: åŒ…å«å„é¡¹ç»Ÿè®¡æŒ‡æ ‡çš„å­—å…¸
    """
    sim = Simulation(config)
    
    # è¿è¡Œæ¨¡æ‹Ÿ
    for _ in range(steps):
        sim.step()
    
    # è·å–ç»Ÿè®¡æŒ‡æ ‡
    mean_stats = calculate_mean_opinion(sim, exclude_zealots=True)
    variance_stats = calculate_variance_metrics(sim, exclude_zealots=True)
    identity_stats = calculate_identity_statistics(sim, exclude_zealots=True)
    polarization = get_polarization_index(sim)
    
    # è®¡ç®—variance per identity (èº«ä»½é—´æ–¹å·®)
    variance_per_identity = 0.0
    if 'identity_difference' in identity_stats:
        variance_per_identity = identity_stats['identity_difference']['abs_mean_opinion_difference']
    else:
        # å¦‚æœæ²¡æœ‰identity_differenceï¼Œè®¡ç®—æ‰€æœ‰èº«ä»½çš„æ–¹å·®å‡å€¼
        identity_variances = []
        for key, values in identity_stats.items():
            if key.startswith('identity_') and key != 'identity_difference':
                identity_variances.append(values['variance'])
        if identity_variances:
            variance_per_identity = np.mean(identity_variances)
    
    return {
        'mean_opinion': mean_stats['mean_opinion'],
        'variance': variance_stats['overall_variance'],
        'variance_per_identity': variance_per_identity,
        'polarization_index': polarization
    }


def run_parameter_sweep(plot_type: str, combination: Dict[str, Any], 
                       x_values: List[float], num_runs: int = 5) -> Dict[str, List[List[float]]]:
    """
    å¯¹ç‰¹å®šå‚æ•°ç»„åˆè¿›è¡Œå‚æ•°æ‰«æ
    
    Args:
    plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
    combination: å‚æ•°ç»„åˆå­—å…¸
    x_values: xè½´çš„å–å€¼åˆ—è¡¨
    num_runs: æ¯ä¸ªå‚æ•°ç‚¹è¿è¡Œçš„æ¬¡æ•°
    
    Returns:
    dict: åŒ…å«å„æŒ‡æ ‡çš„æ•°æ®çŸ©é˜µ {metric: [runs_for_x1, runs_for_x2, ...]}
    """
    results = {
        'mean_opinion': [],
        'variance': [],
        'variance_per_identity': [],
        'polarization_index': []
    }
    
    base_config = copy.deepcopy(high_polarization_config)
    # base_config.steps = 500
    
    # è®¾ç½®å›ºå®šå‚æ•°
    if plot_type == 'zealot_numbers':
        base_config.morality_rate = combination['morality_rate']
        base_config.zealot_identity_allocation = combination['zealot_identity_allocation']
        base_config.cluster_identity = combination['cluster_identity']
        base_config.enable_zealots = True
        base_config.steps = combination['steps']
    else:  # morality_ratios
        base_config.zealot_count = combination['zealot_count']
        base_config.zealot_mode = combination['zealot_mode']
        base_config.zealot_identity_allocation = combination['zealot_identity_allocation']
        base_config.cluster_identity = combination['cluster_identity']
        base_config.enable_zealots = True
        base_config.steps = combination['steps']
    
    # å¯¹æ¯ä¸ªxå€¼è¿›è¡Œå¤šæ¬¡è¿è¡Œ
    for x_val in tqdm(x_values, desc=f"Running {combination['label']}"):
        runs_data = {
            'mean_opinion': [],
            'variance': [],
            'variance_per_identity': [],
            'polarization_index': []
        }
        
        # è®¾ç½®å½“å‰xå€¼å¯¹åº”çš„å‚æ•°
        current_config = copy.deepcopy(base_config)
        if plot_type == 'zealot_numbers':
            current_config.zealot_count = int(x_val)
            current_config.zealot_mode = combination['zealot_mode']
            if x_val == 0:
                current_config.enable_zealots = False
        else:  # morality_ratios
            current_config.morality_rate = x_val / 100.0  # è½¬æ¢ä¸º0-1èŒƒå›´
        
        # è¿è¡Œå¤šæ¬¡æ¨¡æ‹Ÿ
        for run in range(num_runs):
            try:
                stats = run_single_simulation(current_config)
                for metric in runs_data.keys():
                    runs_data[metric].append(stats[metric])
            except Exception as e:
                print(f"Warning: Simulation failed for x={x_val}, run={run}: {e}")
                # ä½¿ç”¨NaNå¡«å……å¤±è´¥çš„è¿è¡Œ
                for metric in runs_data.keys():
                    runs_data[metric].append(np.nan)
        
        # å°†å½“å‰xå€¼çš„æ‰€æœ‰è¿è¡Œç»“æœæ·»åŠ åˆ°æ€»ç»“æœä¸­
        for metric in results.keys():
            results[metric].append(runs_data[metric])
    
    return results


def save_data_incrementally(plot_type: str, x_values: List[float], 
                           all_results: Dict[str, Dict[str, List[List[float]]]], 
                           output_dir: str, batch_info: str = ""):
    """
    ä»¥è¿½åŠ æ¨¡å¼ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶ï¼Œæ”¯æŒç´¯ç§¯å¤šæ¬¡è¿è¡Œçš„ç»“æœ
    
    Args:
    plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
    x_values: xè½´å–å€¼
    all_results: æ‰€æœ‰ç»„åˆçš„ç»“æœæ•°æ®
    output_dir: è¾“å‡ºç›®å½•
    batch_info: æ‰¹æ¬¡ä¿¡æ¯ï¼Œç”¨äºæ ‡è¯†æœ¬æ¬¡è¿è¡Œ
    """
    data_dir = os.path.join(output_dir, "accumulated_data")
    os.makedirs(data_dir, exist_ok=True)
    
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    if not batch_info:
        batch_info = timestamp
    
    # ä¸ºæ¯ä¸ªå‚æ•°ç»„åˆä¿å­˜æ•°æ®
    for combo_label, results in all_results.items():
        # å‡†å¤‡æ–°çš„æ•°æ®è¡Œ
        new_data_rows = []
        
        for i, x_val in enumerate(x_values):
            for metric in ['mean_opinion', 'variance', 'variance_per_identity', 'polarization_index']:
                for run_idx, value in enumerate(results[metric][i]):
                    new_data_rows.append({
                        'x_value': x_val,
                        'metric': metric,
                        'run': run_idx,
                        'value': value,
                        'combination': combo_label,
                        'batch_id': batch_info,
                        'timestamp': timestamp
                    })
        
        new_df = pd.DataFrame(new_data_rows)
        
        # ç”Ÿæˆæ–‡ä»¶å
        safe_label = combo_label.replace('/', '_').replace(' ', '_').replace('=', '_').replace(',', '_')
        filename = f"{plot_type}_{safe_label}_accumulated.csv"
        filepath = os.path.join(data_dir, filename)
        
        # è¿½åŠ æˆ–åˆ›å»ºæ–‡ä»¶
        if os.path.exists(filepath):
            # æ–‡ä»¶å­˜åœ¨ï¼Œè¿½åŠ æ•°æ®
            new_df.to_csv(filepath, mode='a', header=False, index=False)
            print(f"Appended data to: {filepath}")
        else:
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶
            new_df.to_csv(filepath, index=False)
            print(f"Created new data file: {filepath}")


def load_accumulated_data(output_dir: str) -> Dict[str, pd.DataFrame]:
    """
    è¯»å–ç´¯ç§¯çš„æ•°æ®æ–‡ä»¶
    
    Args:
    output_dir: è¾“å‡ºç›®å½•
    
    Returns:
    dict: æ–‡ä»¶åå¯¹åº”çš„DataFrameå­—å…¸
    """
    data_dir = os.path.join(output_dir, "accumulated_data")
    if not os.path.exists(data_dir):
        print(f"Data directory not found: {data_dir}")
        return {}
    
    # æŸ¥æ‰¾æ‰€æœ‰ç´¯ç§¯æ•°æ®æ–‡ä»¶
    pattern = os.path.join(data_dir, "*_accumulated.csv")
    files = glob(pattern)
    
    if not files:
        print(f"No accumulated data files found in: {data_dir}")
        return {}
    
    loaded_data = {}
    
    print("ğŸ“‚ Loading accumulated data files:")
    for filepath in files:
        filename = os.path.basename(filepath)
        try:
            df = pd.read_csv(filepath)
            loaded_data[filename] = df
            
            # è®¡ç®—æ€»è¿è¡Œæ¬¡æ•°ï¼ˆä¸process_accumulated_data_for_plottingä¸­çš„è®¡ç®—ä¿æŒä¸€è‡´ï¼‰
            total_data_points = len(df)
            unique_x_values = len(df['x_value'].unique()) if not df.empty else 0
            unique_metrics = len(df['metric'].unique()) if not df.empty else 0
            
            # è®¡ç®—æ€»è¿è¡Œæ¬¡æ•°ï¼šæ€»æ•°æ®ç‚¹ / (xå€¼æ•°é‡ * æŒ‡æ ‡æ•°é‡)
            total_runs = total_data_points // (unique_x_values * unique_metrics) if unique_x_values > 0 and unique_metrics > 0 else 0
            
            # ç»Ÿè®¡æ‰¹æ¬¡æ•°ï¼ˆç”¨äºå‚è€ƒï¼‰
            total_batches = len(df['batch_id'].unique()) if 'batch_id' in df.columns and not df.empty else 0
            
            print(f"  âœ… {filename}: {len(df)} records, {total_runs} total runs ({total_batches} batches)")
        except Exception as e:
            print(f"  âŒ Failed to load {filename}: {e}")
    
    return loaded_data


def process_accumulated_data_for_plotting(loaded_data: Dict[str, pd.DataFrame]) -> Tuple[Dict[str, Dict[str, List[List[float]]]], List[float], Dict[str, int]]:
    """
    å°†ç´¯ç§¯æ•°æ®å¤„ç†æˆç»˜å›¾æ‰€éœ€çš„æ ¼å¼
    
    Args:
    loaded_data: å·²åŠ è½½çš„æ•°æ®å­—å…¸
    
    Returns:
    tuple: (all_results, x_values, total_runs_per_combination)
    """
    if not loaded_data:
        return {}, [], {}
    
    # ç¡®å®šplot_typeï¼ˆä»æ–‡ä»¶åæ¨æ–­ï¼‰
    first_filename = list(loaded_data.keys())[0]
    if first_filename.startswith('zealot_numbers'):
        plot_type = 'zealot_numbers'
    elif first_filename.startswith('morality_ratios'):
        plot_type = 'morality_ratios'
    else:
        print("Warning: Cannot determine plot type from filename")
        plot_type = 'unknown'
    
    all_results = {}
    x_values_set = set()
    total_runs_per_combination = {}
    
    for filename, df in loaded_data.items():
        if df.empty:
            continue
            
        # æå–ç»„åˆæ ‡ç­¾ï¼ˆä»æ–‡ä»¶åï¼‰
        if plot_type == 'zealot_numbers':
            combo_label = filename.replace('zealot_numbers_', '').replace('_accumulated.csv', '').replace('_', ' ')
        elif plot_type == 'morality_ratios':
            combo_label = filename.replace('morality_ratios_', '').replace('_accumulated.csv', '').replace('_', ' ')
        else:
            combo_label = filename.replace('_accumulated.csv', '')
        
        # æ¢å¤åŸå§‹æ ‡ç­¾æ ¼å¼
        combo_label = combo_label.replace('Clustered', 'Clustered').replace('Random', 'Random')
        
        # ç»Ÿè®¡æ€»è¿è¡Œæ¬¡æ•°ï¼ˆè®¡ç®—å®é™…çš„æ•°æ®ç‚¹æ•°é‡ï¼Œè€Œä¸æ˜¯batchæ•°ï¼‰
        total_data_points = len(df)
        unique_x_values = len(df['x_value'].unique())
        unique_metrics = len(df['metric'].unique())
        
        # è®¡ç®—æ€»è¿è¡Œæ¬¡æ•°ï¼šæ€»æ•°æ®ç‚¹ / (xå€¼æ•°é‡ * æŒ‡æ ‡æ•°é‡)
        total_runs = total_data_points // (unique_x_values * unique_metrics) if unique_x_values > 0 and unique_metrics > 0 else 0
        
        total_runs_per_combination[combo_label] = total_runs
        
        # æ”¶é›†æ‰€æœ‰xå€¼
        x_values_set.update(df['x_value'].unique())
        
        # æŒ‰ç»„åˆå¤„ç†æ•°æ®
        combo_results = {
            'mean_opinion': [],
            'variance': [],
            'variance_per_identity': [],
            'polarization_index': []
        }
        
        # è·å–æ‰€æœ‰xå€¼å¹¶æ’åº
        combo_x_values = sorted(df['x_value'].unique())
        
        for x_val in combo_x_values:
            x_data = df[df['x_value'] == x_val]
            
            for metric in ['mean_opinion', 'variance', 'variance_per_identity', 'polarization_index']:
                metric_data = x_data[x_data['metric'] == metric]['value'].tolist()
                combo_results[metric].append(metric_data)
        
        all_results[combo_label] = combo_results
    
    x_values = sorted(list(x_values_set))
    
    return all_results, x_values, total_runs_per_combination


def plot_accumulated_results(plot_type: str, x_values: List[float], 
                           all_results: Dict[str, Dict[str, List[List[float]]]], 
                           total_runs_per_combination: Dict[str, int],
                           output_dir: str):
    """
    ç»˜åˆ¶ç´¯ç§¯æ•°æ®çš„ç»“æœå›¾è¡¨ï¼Œæ–‡ä»¶åä¸­åŒ…å«æ€»è¿è¡Œæ¬¡æ•°ä¿¡æ¯
    
    Args:
    plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
    x_values: xè½´å–å€¼
    all_results: æ‰€æœ‰ç»„åˆçš„ç»“æœæ•°æ®
    total_runs_per_combination: æ¯ä¸ªç»„åˆçš„æ€»è¿è¡Œæ¬¡æ•°
    output_dir: è¾“å‡ºç›®å½•
    """
    metrics = ['mean_opinion', 'variance', 'variance_per_identity', 'polarization_index']
    metric_labels = {
        'mean_opinion': 'Mean Opinion',
        'variance': 'Opinion Variance',
        'variance_per_identity': 'Variance per Identity',
        'polarization_index': 'Polarization Index'
    }
    
    x_label = 'Number of Zealots' if plot_type == 'zealot_numbers' else 'Morality Ratio (%)'
    
    # è®¡ç®—æ€»è¿è¡Œæ¬¡æ•°èŒƒå›´ï¼ˆç”¨äºæ–‡ä»¶åï¼‰
    min_runs = min(total_runs_per_combination.values()) if total_runs_per_combination else 0
    max_runs = max(total_runs_per_combination.values()) if total_runs_per_combination else 0
    
    if min_runs == max_runs:
        runs_suffix = f"_{min_runs}runs"
    else:
        runs_suffix = f"_{min_runs}-{max_runs}runs"
    
    # åˆ›å»ºå­æ–‡ä»¶å¤¹
    plot_folders = {
        'error_bar': os.path.join(output_dir, 'error_bar_plots'),
        'scatter': os.path.join(output_dir, 'scatter_plots'),
        'mean': os.path.join(output_dir, 'mean_plots'),
        'combined': os.path.join(output_dir, 'combined_plots')
    }
    
    for folder in plot_folders.values():
        os.makedirs(folder, exist_ok=True)
    
    # ç®€åŒ–æ ‡ç­¾å‡½æ•°
    def simplify_label(combo_label):
        """ç®€åŒ–ç»„åˆæ ‡ç­¾ï¼Œä½¿å…¶æ›´çŸ­"""
        # æ›¿æ¢å¸¸è§çš„é•¿è¯ä¸ºç¼©å†™
        # label = combo_label.replace('Clustered', 'Clust').replace('Random', 'Rand')
        # label = label.replace('Zealots', 'Z').replace('Morality', 'M')
        # label = label.replace('ID-align', 'Align').replace('ID-cluster', 'Clust')
        # label = label.replace('True', 'T').replace('False', 'F')
        # return label
        return combo_label
    
    # ä¸ºæ¯ä¸ªæŒ‡æ ‡åˆ›å»ºå¤šç§ç±»å‹çš„å›¾
    for metric in metrics:
        print(f"  Generating plots for {metric_labels[metric]}...")
        
        # é¢„å¤„ç†æ•°æ®ï¼šè®¡ç®—å‡å€¼ã€æ ‡å‡†å·®ï¼Œå¹¶å‡†å¤‡æ•£ç‚¹æ•°æ®
        processed_data = {}
        scatter_data = {}
        
        for combo_label, results in all_results.items():
            metric_data = results[metric]
            means = []
            stds = []
            all_points_x = []
            all_points_y = []
            
            for i, x_runs in enumerate(metric_data):
                valid_runs = [val for val in x_runs if not np.isnan(val)]
                if valid_runs:
                    means.append(np.mean(valid_runs))
                    stds.append(np.std(valid_runs))
                    # ä¸ºæ•£ç‚¹å›¾æ”¶é›†æ‰€æœ‰æ•°æ®ç‚¹
                    all_points_x.extend([x_values[i]] * len(valid_runs))
                    all_points_y.extend(valid_runs)
                else:
                    means.append(np.nan)
                    stds.append(np.nan)
            
            processed_data[combo_label] = {
                'means': np.array(means),
                'stds': np.array(stds)
            }
            scatter_data[combo_label] = {
                'x': all_points_x,
                'y': all_points_y
            }
        
        # ä¸ºæ¯ç§å›¾æ·»åŠ è¿è¡Œæ¬¡æ•°ä¿¡æ¯åˆ°æ ‡é¢˜ï¼ˆæ˜¾ç¤ºæ€»runæ•°ï¼‰
        title_suffix = f" ({min_runs}-{max_runs} total runs)" if min_runs != max_runs else f" ({min_runs} total runs)"
        
        # 1. å¸¦è¯¯å·®æ¡çš„å›¾
        plt.figure(figsize=(14, 8))  # ç¨å¾®å¢åŠ å®½åº¦
        for combo_label, data in processed_data.items():
            runs_info = total_runs_per_combination.get(combo_label, 0)
            short_label = simplify_label(combo_label)
            label_with_runs = f"{short_label} (n={runs_info})"
            plt.errorbar(x_values, data['means'], yerr=data['stds'], 
                        label=label_with_runs, marker='o', linewidth=2, capsize=3, alpha=0.8)
        
        plt.xlabel(x_label, fontsize=12)
        plt.ylabel(metric_labels[metric], fontsize=12)
        plt.title(f'{metric_labels[metric]} vs {x_label}{title_suffix}', fontsize=14, fontweight='bold')
        plt.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=2)  # å›¾ä¾‹æ”¾åœ¨ä¸‹æ–¹ï¼Œ2åˆ—
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        filename = f"{plot_type}_{metric}{runs_suffix}.png"
        filepath = os.path.join(plot_folders['error_bar'], filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. æ•£ç‚¹å›¾
        plt.figure(figsize=(14, 8))
        colors = plt.cm.tab10(np.linspace(0, 1, len(scatter_data)))
        
        for i, (combo_label, data) in enumerate(scatter_data.items()):
            runs_info = total_runs_per_combination.get(combo_label, 0)
            short_label = simplify_label(combo_label)
            label_with_runs = f"{short_label} (n={runs_info})"
            plt.scatter(data['x'], data['y'], label=label_with_runs, alpha=0.6, 
                       color=colors[i], s=30)
        
        plt.xlabel(x_label, fontsize=12)
        plt.ylabel(metric_labels[metric], fontsize=12)
        plt.title(f'{metric_labels[metric]} vs {x_label}{title_suffix}', fontsize=14, fontweight='bold')
        plt.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=2)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        filename = f"{plot_type}_{metric}_scatter{runs_suffix}.png"
        filepath = os.path.join(plot_folders['scatter'], filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. å‡å€¼æ›²çº¿å›¾
        plt.figure(figsize=(14, 8))
        for combo_label, data in processed_data.items():
            runs_info = total_runs_per_combination.get(combo_label, 0)
            short_label = simplify_label(combo_label)
            label_with_runs = f"{short_label} (n={runs_info})"
            plt.plot(x_values, data['means'], label=label_with_runs, marker='o', 
                    linewidth=2, markersize=6, alpha=0.8)
        
        plt.xlabel(x_label, fontsize=12)
        plt.ylabel(metric_labels[metric], fontsize=12)
        plt.title(f'{metric_labels[metric]} vs {x_label}{title_suffix}', fontsize=14, fontweight='bold')
        plt.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=2)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        filename = f"{plot_type}_{metric}_mean{runs_suffix}.png"
        filepath = os.path.join(plot_folders['mean'], filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        
        # 4. ç»„åˆå›¾
        plt.figure(figsize=(14, 8))
        colors = plt.cm.tab10(np.linspace(0, 1, len(scatter_data)))
        
        for i, (combo_label, scatter_pts) in enumerate(scatter_data.items()):
            color = colors[i]
            runs_info = total_runs_per_combination.get(combo_label, 0)
            short_label = simplify_label(combo_label)
            
            # ç»˜åˆ¶æ•£ç‚¹ï¼ˆè¾ƒæ·¡çš„é¢œè‰²ï¼‰
            plt.scatter(scatter_pts['x'], scatter_pts['y'], alpha=0.4, 
                       color=color, s=20, label=f'{short_label} raw (n={runs_info})')
            
            # ç»˜åˆ¶å‡å€¼æ›²çº¿ï¼ˆè¾ƒæ·±çš„é¢œè‰²ï¼‰
            mean_data = processed_data[combo_label]
            plt.plot(x_values, mean_data['means'], color=color, 
                    marker='o', linewidth=3, markersize=8, alpha=0.9,
                    label=f'{short_label} mean (n={runs_info})')
        
        plt.xlabel(x_label, fontsize=12)
        plt.ylabel(metric_labels[metric], fontsize=12)
        plt.title(f'{metric_labels[metric]} vs {x_label}{title_suffix}', fontsize=14, fontweight='bold')
        plt.legend(bbox_to_anchor=(0.5, -0.2), loc='upper center', ncol=2)  # ç»„åˆå›¾éœ€è¦æ›´å¤šç©ºé—´
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        filename = f"{plot_type}_{metric}_combined{runs_suffix}.png"
        filepath = os.path.join(plot_folders['combined'], filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
    
    print(f"  âœ… Generated 4 types of plots for {plot_type} with run count info:")
    print(f"     - Error bar plots: {plot_folders['error_bar']}")
    print(f"     - Scatter plots: {plot_folders['scatter']}")
    print(f"     - Mean line plots: {plot_folders['mean']}")
    print(f"     - Combined plots: {plot_folders['combined']}")


def run_and_accumulate_data(output_dir: str = "results/zealot_morality_analysis", 
                           num_runs: int = 5, max_zealots: int = 50, max_morality: int = 30,
                           batch_name: str = ""):
    """
    è¿è¡Œæµ‹è¯•å¹¶ä»¥è¿½åŠ æ¨¡å¼ä¿å­˜æ•°æ®ï¼ˆç¬¬ä¸€éƒ¨åˆ†ï¼‰
    
    Args:
    output_dir: è¾“å‡ºç›®å½•
    num_runs: æœ¬æ¬¡è¿è¡Œçš„æ¬¡æ•°
    max_zealots: æœ€å¤§zealotæ•°é‡
    max_morality: æœ€å¤§morality ratio (%)
    batch_name: æ‰¹æ¬¡åç§°ï¼Œç”¨äºæ ‡è¯†æœ¬æ¬¡è¿è¡Œ
    """
    print("ğŸ”¬ Running Tests and Accumulating Data")
    print("=" * 70)
    
    start_time = time.time()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–å‚æ•°ç»„åˆ
    combinations = create_config_combinations()
    
    if not batch_name:
        batch_name = time.strftime("%Y%m%d_%H%M%S")
    
    print(f"ğŸ“Š Batch Configuration:")
    print(f"   Batch name: {batch_name}")
    print(f"   Number of runs this batch: {num_runs}")
    print(f"   Max zealots: {max_zealots}")
    print(f"   Max morality ratio: {max_morality}%")
    print(f"   Output directory: {output_dir}")
    print()
    
    # === å¤„ç†å›¾1ï¼šxè½´ä¸ºzealot numbers ===
    print("ğŸ“ˆ Running Test Type 1: Zealot Numbers Analysis")
    print("-" * 50)
    
    plot1_start_time = time.time()
    
    zealot_x_values = list(range(0, max_zealots + 1, 2))  # 0, 2, 4, ..., 50
    zealot_results = {}
    
    for combo in combinations['zealot_numbers']:
        print(f"Running combination: {combo['label']}")
        results = run_parameter_sweep('zealot_numbers', combo, zealot_x_values, num_runs)
        zealot_results[combo['label']] = results
    
    # ä¿å­˜zealot numbersçš„æ•°æ®
    save_data_incrementally('zealot_numbers', zealot_x_values, zealot_results, output_dir, batch_name)
    
    plot1_end_time = time.time()
    plot1_duration = plot1_end_time - plot1_start_time
    hours1, remainder1 = divmod(plot1_duration, 3600)
    minutes1, seconds1 = divmod(remainder1, 60)
    
    print(f"â±ï¸  Test Type 1 completed in: {int(hours1)}h {int(minutes1)}m {seconds1:.2f}s")
    print()
    
    # === å¤„ç†å›¾2ï¼šxè½´ä¸ºmorality ratio ===
    print("ğŸ“ˆ Running Test Type 2: Morality Ratio Analysis")
    print("-" * 50)
    
    plot2_start_time = time.time()
    
    morality_x_values = list(range(0, max_morality + 1, 2))  # 0, 2, 4, ..., 30
    morality_results = {}
    
    for combo in combinations['morality_ratios']:
        print(f"Running combination: {combo['label']}")
        results = run_parameter_sweep('morality_ratios', combo, morality_x_values, num_runs)
        morality_results[combo['label']] = results
    
    # ä¿å­˜morality ratioçš„æ•°æ®
    save_data_incrementally('morality_ratios', morality_x_values, morality_results, output_dir, batch_name)
    
    plot2_end_time = time.time()
    plot2_duration = plot2_end_time - plot2_start_time
    hours2, remainder2 = divmod(plot2_duration, 3600)
    minutes2, seconds2 = divmod(remainder2, 60)
    
    print(f"â±ï¸  Test Type 2 completed in: {int(hours2)}h {int(minutes2)}m {seconds2:.2f}s")
    print()
    
    # è®¡ç®—æ€»è€—æ—¶
    end_time = time.time()
    elapsed_time = end_time - start_time
    hours, remainder = divmod(elapsed_time, 3600)
    minutes, seconds = divmod(remainder, 60)
    
    print("\n" + "=" * 70)
    print("ğŸ‰ Data Collection Completed Successfully!")
    print(f"ğŸ“Š Batch '{batch_name}' with {num_runs} runs per parameter point")
    print()
    print("â±ï¸  Timing Summary:")
    print(f"   Test Type 1 (Zealot Numbers): {int(hours1)}h {int(minutes1)}m {seconds1:.2f}s")
    print(f"   Test Type 2 (Morality Ratios): {int(hours2)}h {int(minutes2)}m {seconds2:.2f}s")
    print(f"   Total execution time: {int(hours)}h {int(minutes)}m {seconds:.2f}s")
    print(f"ğŸ“ Data accumulated in: {output_dir}/accumulated_data/")
    
    # ä¿å­˜æ‰¹æ¬¡ä¿¡æ¯
    batch_info_file = os.path.join(output_dir, "accumulated_data", f"batch_info_{batch_name}.txt")
    with open(batch_info_file, "w") as f:
        f.write(f"Batch Information\n")
        f.write(f"================\n\n")
        f.write(f"Batch name: {batch_name}\n")
        f.write(f"Number of runs: {num_runs}\n")
        f.write(f"Max zealots: {max_zealots}\n")
        f.write(f"Max morality ratio: {max_morality}%\n")
        f.write(f"Execution time: {int(hours)}h {int(minutes)}m {seconds:.2f}s\n")
        f.write(f"Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")


def plot_from_accumulated_data(output_dir: str = "results/zealot_morality_analysis"):
    """
    ä»ç´¯ç§¯æ•°æ®æ–‡ä»¶ä¸­è¯»å–æ•°æ®å¹¶ç”Ÿæˆå›¾è¡¨ï¼ˆç¬¬äºŒéƒ¨åˆ†ï¼‰
    
    Args:
    output_dir: è¾“å‡ºç›®å½•ï¼ˆåŒ…å«accumulated_dataå­æ–‡ä»¶å¤¹ï¼‰
    """
    print("ğŸ“Š Generating Plots from Accumulated Data")
    print("=" * 70)
    
    start_time = time.time()
    
    # åŠ è½½ç´¯ç§¯æ•°æ®
    loaded_data = load_accumulated_data(output_dir)
    if not loaded_data:
        print("âŒ No accumulated data found. Please run data collection first.")
        return
    
    # æŒ‰å›¾ç±»å‹åˆ†ç»„æ•°æ®æ–‡ä»¶
    zealot_files = {k: v for k, v in loaded_data.items() if k.startswith('zealot_numbers')}
    morality_files = {k: v for k, v in loaded_data.items() if k.startswith('morality_ratios')}
    
    # å¤„ç†zealot numbersæ•°æ®å¹¶ç»˜å›¾
    if zealot_files:
        print("\nğŸ“ˆ Processing Zealot Numbers Data...")
        zealot_results, zealot_x_values, zealot_runs_info = process_accumulated_data_for_plotting(zealot_files)
        if zealot_results:
            plot_accumulated_results('zealot_numbers', zealot_x_values, zealot_results, zealot_runs_info, output_dir)
    
    # å¤„ç†morality ratiosæ•°æ®å¹¶ç»˜å›¾
    if morality_files:
        print("\nğŸ“ˆ Processing Morality Ratios Data...")
        morality_results, morality_x_values, morality_runs_info = process_accumulated_data_for_plotting(morality_files)
        if morality_results:
            plot_accumulated_results('morality_ratios', morality_x_values, morality_results, morality_runs_info, output_dir)
    
    # è®¡ç®—æ€»è€—æ—¶
    end_time = time.time()
    elapsed_time = end_time - start_time
    hours, remainder = divmod(elapsed_time, 3600)
    minutes, seconds = divmod(remainder, 60)
    
    print("\n" + "=" * 70)
    print("ğŸ‰ Plot Generation Completed Successfully!")
    print(f"ğŸ“Š Generated plots from accumulated data")
    print(f"â±ï¸  Total plotting time: {int(hours)}h {int(minutes)}m {seconds:.2f}s")
    print(f"ğŸ“ Plots saved to: {output_dir}")


def run_zealot_morality_analysis(output_dir: str = "results/zealot_morality_analysis", 
                                num_runs: int = 5, max_zealots: int = 50, max_morality: int = 30):
    """
    è¿è¡Œå®Œæ•´çš„zealotå’Œmoralityåˆ†æå®éªŒï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    
    Args:
    output_dir: è¾“å‡ºç›®å½•
    num_runs: æ¯ä¸ªå‚æ•°ç‚¹çš„è¿è¡Œæ¬¡æ•°
    max_zealots: æœ€å¤§zealotæ•°é‡
    max_morality: æœ€å¤§morality ratio (%)
    """
    print("ğŸ”¬ Starting Complete Zealot and Morality Analysis Experiment")
    print("=" * 70)
    
    # ç¬¬ä¸€æ­¥ï¼šè¿è¡Œæµ‹è¯•å¹¶ç´¯ç§¯æ•°æ®
    run_and_accumulate_data(output_dir, num_runs, max_zealots, max_morality)
    
    # ç¬¬äºŒæ­¥ï¼šä»ç´¯ç§¯æ•°æ®ç”Ÿæˆå›¾è¡¨
    plot_from_accumulated_data(output_dir)


if __name__ == "__main__":
    # æ–°çš„åˆ†ç¦»å¼ä½¿ç”¨æ–¹æ³•ï¼š
    
    # å¼€å§‹è®¡æ—¶
    main_start_time = time.time()
    
    # æ–¹æ³•1ï¼šåˆ†ä¸¤æ­¥è¿è¡Œ
    # ç¬¬ä¸€æ­¥ï¼šè¿è¡Œæµ‹è¯•å¹¶ç§¯ç´¯æ•°æ®ï¼ˆå¯ä»¥å¤šæ¬¡è¿è¡Œä»¥ç§¯ç´¯æ›´å¤šæ•°æ®ï¼‰
    print("=" * 50)
    print("ğŸš€ ç¤ºä¾‹ï¼šåˆ†æ­¥éª¤è¿è¡Œå®éªŒ")
    print("=" * 50)
    
    # æ•°æ®æ”¶é›†é˜¶æ®µ
    data_collection_start_time = time.time()
    
    # å¯ä»¥å¤šæ¬¡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥ç§¯ç´¯æ•°æ®ï¼š
    run_and_accumulate_data(
        output_dir="results/zealot_morality_analysis",
        num_runs=100,  # æ¯æ¬¡è¿è¡Œ100è½®æµ‹è¯•
        max_zealots=100,  
        max_morality=100,
        # batch_name="batch_001"  # å¯é€‰ï¼šç»™æ‰¹æ¬¡å‘½å
    )
    
    data_collection_end_time = time.time()
    data_collection_duration = data_collection_end_time - data_collection_start_time
    

    # ç¬¬äºŒæ­¥ï¼šç»˜å›¾é˜¶æ®µ

    plotting_start_time = time.time()

    plot_from_accumulated_data("results/zealot_morality_analysis")
    
    plotting_end_time = time.time()
    plotting_duration = plotting_end_time - plotting_start_time
    
    # è®¡ç®—æ€»è€—æ—¶
    main_end_time = time.time()
    total_duration = main_end_time - main_start_time
    
    # æ ¼å¼åŒ–è€—æ—¶æ˜¾ç¤º
    def format_duration(duration):
        hours, remainder = divmod(duration, 3600)
        minutes, seconds = divmod(remainder, 60)
        return f"{int(hours)}h {int(minutes)}m {seconds:.2f}s"
    
    # æ˜¾ç¤ºè€—æ—¶æ€»ç»“
    print("\n" + "ğŸ•’" * 50)
    print("â±ï¸  å®Œæ•´å®éªŒè€—æ—¶æ€»ç»“")
    print("ğŸ•’" * 50)
    print(f"ğŸ“Š æ•°æ®æ”¶é›†é˜¶æ®µè€—æ—¶: {format_duration(data_collection_duration)}")
    print(f"ğŸ“ˆ å›¾è¡¨ç”Ÿæˆé˜¶æ®µè€—æ—¶: {format_duration(plotting_duration)}")
    print(f"ğŸ¯ æ€»è€—æ—¶: {format_duration(total_duration)}")
    print("ğŸ•’" * 50) 