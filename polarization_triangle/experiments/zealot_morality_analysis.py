"""
Zealot and Morality Analysis Experiment

This experiment analyzes the effects of zealot numbers and morality ratios on various system metrics.
It generates two types of plots:
1. X-axis: Number of zealots
2. X-axis: Morality ratio

For each plot type, it generates 7 different Y-axis metrics:
- Mean opinion
- Variance 
- Identity opinion difference (between identity groups)
- Polarization index
- Variance per identity (+1) - variance within identity group +1
- Variance per identity (-1) - variance within identity group -1
- Variance per identity (combined) - both identity groups on same plot

Total: 14 plots (2 types Ã— 7 metrics)
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import copy
import time
import multiprocessing
from tqdm import tqdm
from typing import Dict, List, Tuple, Any
import itertools
from glob import glob

from polarization_triangle.core.config import SimulationConfig, high_polarization_config
from polarization_triangle.core.simulation import Simulation
from polarization_triangle.analysis.statistics import (
    calculate_mean_opinion,
    calculate_variance_metrics,
    calculate_identity_statistics,
    get_polarization_index
)
from polarization_triangle.utils.data_manager import ExperimentDataManager


# =====================================
# å·¥å…·å‡½æ•°
# =====================================

def format_duration(duration: float) -> str:
    """
    æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
    
    Args:
    duration: æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    
    Returns:
    str: æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
    """
    hours, remainder = divmod(duration, 3600)
    minutes, seconds = divmod(remainder, 60)
    return f"{int(hours)}h {int(minutes)}m {seconds:.2f}s"


# æ³¨ï¼šsave_batch_info å‡½æ•°å·²è¢« ExperimentDataManager çš„æ‰¹æ¬¡å…ƒæ•°æ®åŠŸèƒ½æ›¿ä»£


# =====================================
# å¹¶è¡Œè®¡ç®—æ”¯æŒå‡½æ•°
# =====================================

def run_single_simulation_task(task_params):
    """
    å•ä¸ªæ¨¡æ‹Ÿä»»åŠ¡çš„åŒ…è£…å‡½æ•°ï¼Œç”¨äºŽå¤šè¿›ç¨‹å¹¶è¡Œè®¡ç®—
    
    Args:
        task_params: åŒ…å«ä»»åŠ¡å‚æ•°çš„å…ƒç»„
            (plot_type, combination, x_val, run_idx, steps, process_id)
    
    Returns:
        tuple: (x_val, run_idx, results_dict, success, error_msg)
    """
    try:
        plot_type, combination, x_val, run_idx, steps, process_id = task_params
        
        # è®¾ç½®è¿›ç¨‹ç‰¹å®šçš„éšæœºç§å­
        np.random.seed((int(x_val * 1000) + run_idx + process_id) % (2**32))
        
        # æž„å»ºé…ç½®
        base_config = copy.deepcopy(high_polarization_config)
        
        # è®¾ç½®å›ºå®šå‚æ•°
        if plot_type == 'zealot_numbers':
            base_config.morality_rate = combination['morality_rate']
            base_config.zealot_identity_allocation = combination['zealot_identity_allocation']
            base_config.cluster_identity = combination['cluster_identity']
            base_config.enable_zealots = True
            base_config.steps = combination['steps']
            # è®¾ç½®å½“å‰xå€¼å¯¹åº”çš„å‚æ•°
            base_config.zealot_count = int(x_val)
            base_config.zealot_mode = combination['zealot_mode']
            if x_val == 0:
                base_config.enable_zealots = False
        else:  # morality_ratios
            base_config.zealot_count = combination['zealot_count']
            base_config.zealot_mode = combination['zealot_mode']
            base_config.zealot_identity_allocation = combination['zealot_identity_allocation']
            base_config.cluster_identity = combination['cluster_identity']
            base_config.enable_zealots = combination['zealot_mode'] != 'none'
            base_config.steps = combination['steps']
            # è®¾ç½®å½“å‰xå€¼å¯¹åº”çš„å‚æ•°
            base_config.morality_rate = x_val / 100.0  # è½¬æ¢ä¸º0-1èŒƒå›´
        
        # è¿è¡Œå•æ¬¡æ¨¡æ‹Ÿ
        results = run_single_simulation(base_config, steps)
        
        return (x_val, run_idx, results, True, None)
        
    except Exception as e:
        error_msg = f"Process {process_id}: Simulation failed for x={x_val}, run={run_idx}: {str(e)}"
        return (x_val, run_idx, None, False, error_msg)


# =====================================
# æ ¸å¿ƒå®žéªŒé€»è¾‘å‡½æ•°
# =====================================

def create_config_combinations():
    """
    åˆ›å»ºå®žéªŒå‚æ•°ç»„åˆé…ç½®
    
    è¯¥å‡½æ•°ç”Ÿæˆä¸¤ç±»å®žéªŒçš„æ‰€æœ‰å‚æ•°ç»„åˆï¼š
    
    1. zealot_numberså®žéªŒï¼šæµ‹è¯•ä¸åŒzealotæ•°é‡å¯¹ç³»ç»Ÿçš„å½±å“
       - å˜é‡ï¼šzealotæ•°é‡ (xè½´)
       - å›ºå®šï¼šzealotèº«ä»½åˆ†é…=True, èº«ä»½åˆ†å¸ƒ=random
       - æ¯”è¾ƒï¼šzealotåˆ†å¸ƒæ¨¡å¼(random/clustered) Ã— moralityæ¯”ä¾‹(0.0/0.3) = 4ä¸ªç»„åˆ
    
    2. morality_ratioså®žéªŒï¼šæµ‹è¯•ä¸åŒmoralityæ¯”ä¾‹å¯¹ç³»ç»Ÿçš„å½±å“
       - å˜é‡ï¼šmoralityæ¯”ä¾‹ (xè½´)
       - å›ºå®šï¼šzealotæ•°é‡=20
       - æ¯”è¾ƒï¼šzealotæ¨¡å¼(random/clustered/none) Ã— zealotèº«ä»½å¯¹é½(True/False) Ã— 
               èº«ä»½åˆ†å¸ƒ(random/clustered) = 10ä¸ªç»„åˆ
    
    Returns:
        dict: åŒ…å«ä¸¤ç±»å®žéªŒé…ç½®çš„å­—å…¸
            - 'zealot_numbers': 4ä¸ªå‚æ•°ç»„åˆï¼Œç”¨äºŽzealotæ•°é‡å®žéªŒ
            - 'morality_ratios': 10ä¸ªå‚æ•°ç»„åˆï¼Œç”¨äºŽmoralityæ¯”ä¾‹å®žéªŒ
    """
    # åŸºç¡€é…ç½®ï¼šä½¿ç”¨é«˜æžåŒ–é…ç½®ä½œä¸ºæ¨¡æ¿
    base_config = copy.deepcopy(high_polarization_config)
    base_config.steps = 300  # æ¯æ¬¡æ¨¡æ‹Ÿè¿è¡Œ300æ­¥
    
    # åˆå§‹åŒ–ä¸¤ç±»å®žéªŒçš„å‚æ•°ç»„åˆå®¹å™¨
    combinations = {
        'zealot_numbers': [],   # å®žéªŒ1ï¼šxè½´ä¸ºzealotæ•°é‡çš„å‚æ•°ç»„åˆ
        'morality_ratios': []   # å®žéªŒ2ï¼šxè½´ä¸ºmoralityæ¯”ä¾‹çš„å‚æ•°ç»„åˆ
    }
    
    # ===== å®žéªŒ1ï¼šzealotæ•°é‡æ‰«æå®žéªŒ =====
    # æ¯”è¾ƒzealotåˆ†å¸ƒæ¨¡å¼å’Œmoralityæ¯”ä¾‹å¯¹ç³»ç»Ÿçš„å½±å“
    # å›ºå®šå‚æ•°ï¼šzealotèº«ä»½åˆ†é…=True, èº«ä»½åˆ†å¸ƒ=random
    zealot_clustering_options = ['random', 'clustered']  # zealotåˆ†å¸ƒæ¨¡å¼ï¼šéšæœºåˆ†å¸ƒ vs èšé›†åˆ†å¸ƒ
    morality_ratios_for_zealot_plot = [0.0, 0.3]  # ä¸¤ä¸ªmoralityæ°´å¹³ï¼šæ— é“å¾·çº¦æŸ vs ä¸­ç­‰é“å¾·çº¦æŸ
    
    for clustering in zealot_clustering_options:
        for morality_ratio in morality_ratios_for_zealot_plot:
            combo = {
                'zealot_mode': clustering,                    # zealotåˆ†å¸ƒæ¨¡å¼
                'morality_rate': morality_ratio,              # moralityçº¦æŸå¼ºåº¦
                'zealot_identity_allocation': True,           # zealotæŒ‰èº«ä»½åˆ†é…ï¼ˆå›ºå®šï¼‰
                'cluster_identity': False,                    # èº«ä»½éšæœºåˆ†å¸ƒï¼ˆå›ºå®šï¼‰
                'label': f'{clustering.capitalize()} Zealots, Morality={morality_ratio}',
                'steps': base_config.steps
            }
            combinations['zealot_numbers'].append(combo)
    
    # ===== å®žéªŒ2ï¼šmoralityæ¯”ä¾‹æ‰«æå®žéªŒ =====
    # æ¯”è¾ƒä¸‰ä¸ªå…³é”®å› ç´ çš„äº¤äº’å½±å“ï¼šzealotåˆ†å¸ƒã€zealotèº«ä»½å¯¹é½ã€èº«ä»½åˆ†å¸ƒ
    # å›ºå®šå‚æ•°ï¼šzealotæ•°é‡=20ï¼ˆä¸­ç­‰æ°´å¹³ï¼‰
    zealot_modes = ['random', 'clustered', 'none']     # zealotæ¨¡å¼ï¼šéšæœº/èšé›†/æ— zealot
    zealot_identity_alignments = [True, False]         # zealotæ˜¯å¦æŒ‰èº«ä»½åˆ†é…
    identity_distributions = [False, True]             # èº«ä»½åˆ†å¸ƒï¼šéšæœº vs èšé›†
    
    # å›ºå®šzealotæ•°é‡ä¸º20ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸­ç­‰æ°´å¹³ï¼Œæ—¢ä¸ä¼šè¿‡åº¦å½±å“ç³»ç»Ÿï¼Œä¹Ÿèƒ½è§‚å¯Ÿåˆ°æ•ˆæžœ
    fixed_zealot_count = 20
    
    for zealot_mode in zealot_modes:
        if zealot_mode == 'none':
            # æ— zealotæƒ…å†µï¼šåªéœ€è¦åŒºåˆ†èº«ä»½åˆ†å¸ƒæ–¹å¼ï¼Œzealotç›¸å…³å‚æ•°æ— æ„ä¹‰
            for identity_dist in identity_distributions:
                combo = {
                    'zealot_count': 0,                           # æ— zealot
                    'zealot_mode': zealot_mode,                  # æ ‡è®°ä¸º'none'
                    'zealot_identity_allocation': True,          # é»˜è®¤å€¼ï¼ˆä¸å½±å“ç»“æžœï¼‰
                    'cluster_identity': identity_dist,           # èº«ä»½åˆ†å¸ƒæ–¹å¼
                    'label': f'{zealot_mode.capitalize()}, ID-cluster={identity_dist}',
                    'steps': base_config.steps
                }
                combinations['morality_ratios'].append(combo)
        else:
            # æœ‰zealotæƒ…å†µï¼šéœ€è¦è€ƒè™‘zealotèº«ä»½å¯¹é½æ–¹å¼å’Œèº«ä»½åˆ†å¸ƒæ–¹å¼çš„ç»„åˆæ•ˆåº”
            for zealot_identity in zealot_identity_alignments:
                for identity_dist in identity_distributions:
                    combo = {
                        'zealot_count': fixed_zealot_count,          # å›ºå®šzealotæ•°é‡
                        'zealot_mode': zealot_mode,                  # zealotåˆ†å¸ƒæ¨¡å¼
                        'zealot_identity_allocation': zealot_identity,  # zealotèº«ä»½å¯¹é½æ–¹å¼
                        'cluster_identity': identity_dist,           # èº«ä»½åˆ†å¸ƒæ–¹å¼
                        'label': f'{zealot_mode.capitalize()}, ID-align={zealot_identity}, ID-cluster={identity_dist}',
                        'steps': base_config.steps
                    }
                    combinations['morality_ratios'].append(combo)
    
    return combinations


def run_single_simulation(config: SimulationConfig, steps: int = 500) -> Dict[str, float]:
    """
    è¿è¡Œå•æ¬¡æ¨¡æ‹Ÿå¹¶èŽ·å–æœ€ç»ˆçŠ¶æ€çš„ç»Ÿè®¡æŒ‡æ ‡
    
    è¯¥å‡½æ•°åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿå®žä¾‹ï¼Œè¿è¡ŒæŒ‡å®šæ­¥æ•°ï¼Œç„¶åŽè®¡ç®—å…­ä¸ªå…³é”®æŒ‡æ ‡ï¼š
    - Mean Opinion: ç³»ç»Ÿä¸­éžzealot agentçš„å¹³å‡æ„è§å€¼
    - Variance: æ„è§åˆ†å¸ƒçš„æ–¹å·®ï¼Œè¡¡é‡æ„è§åˆ†åŒ–ç¨‹åº¦
    - Identity Opinion Difference: ä¸åŒèº«ä»½ç¾¤ä½“é—´çš„å¹³å‡æ„è§å·®å¼‚
    - Polarization Index: æžåŒ–æŒ‡æ•°ï¼Œè¡¡é‡ç³»ç»Ÿçš„æžåŒ–ç¨‹åº¦
    - Variance per Identity: æ¯ä¸ªèº«ä»½ç¾¤ä½“å†…éƒ¨çš„æ„è§æ–¹å·®ï¼ˆä¸¤ä¸ªèº«ä»½ç¾¤ä½“åˆ†åˆ«è®¡ç®—ï¼‰
    
    Args:
        config (SimulationConfig): æ¨¡æ‹Ÿé…ç½®å¯¹è±¡ï¼ŒåŒ…å«ç½‘ç»œã€agentã€zealotç­‰å‚æ•°
        steps (int, optional): æ¨¡æ‹Ÿè¿è¡Œçš„æ­¥æ•°. Defaults to 500.
    
    Returns:
        Dict[str, Any]: åŒ…å«ç»Ÿè®¡æŒ‡æ ‡çš„å­—å…¸
            - 'mean_opinion': å¹³å‡æ„è§å€¼ (float)
            - 'variance': æ„è§æ–¹å·® (float)
            - 'identity_opinion_difference': èº«ä»½é—´æ„è§å·®å¼‚ (float)
            - 'polarization_index': æžåŒ–æŒ‡æ•° (float)
            - 'variance_per_identity': æ¯ä¸ªèº«ä»½ç»„çš„æ–¹å·® (dict)
                - 'identity_1': identity=1ç»„çš„æ–¹å·®
                - 'identity_-1': identity=-1ç»„çš„æ–¹å·®
    
    Raises:
        Exception: å½“æ¨¡æ‹Ÿè¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯æ—¶æŠ›å‡ºå¼‚å¸¸
    """
    # åˆ›å»ºæ¨¡æ‹Ÿå®žä¾‹
    sim = Simulation(config)
    
    # é€æ­¥è¿è¡Œæ¨¡æ‹Ÿè‡³ç¨³å®šçŠ¶æ€
    for _ in range(steps):
        sim.step()
    
    # ä»Žæœ€ç»ˆçŠ¶æ€è®¡ç®—å„é¡¹ç»Ÿè®¡æŒ‡æ ‡
    mean_stats = calculate_mean_opinion(sim, exclude_zealots=True)
    variance_stats = calculate_variance_metrics(sim, exclude_zealots=True)
    identity_stats = calculate_identity_statistics(sim, exclude_zealots=True)
    polarization = get_polarization_index(sim)
    
    # è®¡ç®—identity opinion difference (èº«ä»½é—´æ„è§å·®å¼‚)
    identity_opinion_difference = 0.0
    if 'identity_difference' in identity_stats:
        identity_opinion_difference = identity_stats['identity_difference']['abs_mean_opinion_difference']
    else:
        # ç†è®ºä¸Šåœ¨æ­£å¸¸æƒ…å†µä¸‹ä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œï¼ˆzealotæ•°é‡è¶³å¤Ÿå°æ—¶ï¼‰
        print("Warning: identity_difference not found, this should not happen under normal conditions")
        identity_opinion_difference = 0.0
    
    # è®¡ç®— variance per identity (æ¯ä¸ªèº«ä»½ç»„å†…çš„æ–¹å·®)
    variance_per_identity = {'identity_1': 0.0, 'identity_-1': 0.0}
    
    # èŽ·å–éžzealotèŠ‚ç‚¹çš„æ„è§å’Œèº«ä»½
    # åˆ›å»º zealot maskï¼šå¦‚æžœä¸€ä¸ªagentçš„IDåœ¨ zealot_ids ä¸­ï¼Œåˆ™ä¸ºTrue
    zealot_mask = np.zeros(sim.num_agents, dtype=bool)
    if sim.enable_zealots and sim.zealot_ids:
        zealot_mask[sim.zealot_ids] = True
    
    non_zealot_mask = ~zealot_mask
    non_zealot_opinions = sim.opinions[non_zealot_mask]
    non_zealot_identities = sim.identities[non_zealot_mask]
    
    # åˆ†åˆ«è®¡ç®—æ¯ä¸ªèº«ä»½ç»„çš„æ–¹å·®
    for identity_val in [1, -1]:
        identity_mask = non_zealot_identities == identity_val
        if np.sum(identity_mask) > 1:  # è‡³å°‘éœ€è¦2ä¸ªèŠ‚ç‚¹æ‰èƒ½è®¡ç®—æ–¹å·®
            identity_opinions = non_zealot_opinions[identity_mask]
            variance_per_identity[f'identity_{identity_val}'] = float(np.var(identity_opinions))
        else:
            variance_per_identity[f'identity_{identity_val}'] = 0.0
    
    return {
        'mean_opinion': mean_stats['mean_opinion'],
        'variance': variance_stats['overall_variance'],
        'identity_opinion_difference': identity_opinion_difference,
        'polarization_index': polarization,
        'variance_per_identity': variance_per_identity
    }


def run_parameter_sweep(plot_type: str, combination: Dict[str, Any], 
                       x_values: List[float], num_runs: int = 5, num_processes: int = 1) -> Dict[str, List[List[float]]]:
    """
    å¯¹ç‰¹å®šå‚æ•°ç»„åˆè¿›è¡Œå‚æ•°æ‰«æå®žéªŒ
    
    è¯¥å‡½æ•°é’ˆå¯¹ç»™å®šçš„å‚æ•°ç»„åˆï¼Œåœ¨xè½´çš„æ¯ä¸ªå–å€¼ç‚¹è¿è¡Œå¤šæ¬¡æ¨¡æ‹Ÿï¼Œæ”¶é›†ç»Ÿè®¡æ•°æ®ã€‚
    è¿™æ˜¯å®žéªŒçš„æ ¸å¿ƒæ‰§è¡Œå‡½æ•°ï¼Œæ”¯æŒä¸¤ç§ç±»åž‹çš„æ‰«æï¼š
    - zealot_numbers: å›ºå®šmoralityæ¯”ä¾‹ï¼Œæ‰«æä¸åŒçš„zealotæ•°é‡
    - morality_ratios: å›ºå®šzealotæ•°é‡ï¼Œæ‰«æä¸åŒçš„moralityæ¯”ä¾‹
    
    Args:
        plot_type (str): å®žéªŒç±»åž‹
            - 'zealot_numbers': xè½´ä¸ºzealotæ•°é‡çš„å®žéªŒ
            - 'morality_ratios': xè½´ä¸ºmoralityæ¯”ä¾‹çš„å®žéªŒ
        combination (Dict[str, Any]): å‚æ•°ç»„åˆå­—å…¸ï¼ŒåŒ…å«ï¼š
            - zealot_mode: zealotåˆ†å¸ƒæ¨¡å¼ ('random', 'clustered', 'none')
            - morality_rate: moralityæ¯”ä¾‹ (0.0-1.0)
            - zealot_identity_allocation: æ˜¯å¦æŒ‰èº«ä»½åˆ†é…zealot
            - cluster_identity: æ˜¯å¦èšç±»èº«ä»½åˆ†å¸ƒ
            - label: ç»„åˆæ ‡ç­¾
            - steps: æ¨¡æ‹Ÿæ­¥æ•°
        x_values (List[float]): xè½´æ‰«æçš„å–å€¼åˆ—è¡¨ï¼Œå¦‚ [0, 1, 2, ...]
        num_runs (int, optional): æ¯ä¸ªxå€¼ç‚¹é‡å¤è¿è¡Œæ¬¡æ•°. Defaults to 5.
        num_processes (int, optional): å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œ1è¡¨ç¤ºä¸²è¡Œæ‰§è¡Œ. Defaults to 1.
    
    Returns:
        Dict[str, List[List[float]]]: åµŒå¥—çš„ç»“æžœæ•°æ®ç»“æž„
            æ ¼å¼: {metric_name: [x1_runs, x2_runs, ...]}
            å…¶ä¸­ x1_runs = [run1_value, run2_value, ...]
            
            åŒ…å«çš„æŒ‡æ ‡:
            - 'mean_opinion': å¹³å‡æ„è§å€¼çš„å¤šæ¬¡è¿è¡Œç»“æžœ
            - 'variance': æ„è§æ–¹å·®çš„å¤šæ¬¡è¿è¡Œç»“æžœ  
            - 'identity_opinion_difference': èº«ä»½é—´æ„è§å·®å¼‚çš„å¤šæ¬¡è¿è¡Œç»“æžœ
            - 'polarization_index': æžåŒ–æŒ‡æ•°çš„å¤šæ¬¡è¿è¡Œç»“æžœ
            - 'variance_per_identity_1': identity=1ç»„å†…æ–¹å·®çš„å¤šæ¬¡è¿è¡Œç»“æžœ
            - 'variance_per_identity_-1': identity=-1ç»„å†…æ–¹å·®çš„å¤šæ¬¡è¿è¡Œç»“æžœ
    """
    # é€‰æ‹©ä¸²è¡Œæˆ–å¹¶è¡Œæ‰§è¡Œ
    if num_processes == 1:
        return run_parameter_sweep_serial(plot_type, combination, x_values, num_runs)
    else:
        return run_parameter_sweep_parallel(plot_type, combination, x_values, num_runs, num_processes)


def run_parameter_sweep_serial(plot_type: str, combination: Dict[str, Any], 
                              x_values: List[float], num_runs: int = 5) -> Dict[str, List[List[float]]]:
    """
    ä¸²è¡Œç‰ˆæœ¬çš„å‚æ•°æ‰«æï¼ˆåŽŸæœ‰é€»è¾‘ï¼‰
    """
    results = {
        'mean_opinion': [],
        'variance': [],
        'identity_opinion_difference': [],
        'polarization_index': [],
        'variance_per_identity_1': [],
        'variance_per_identity_-1': []
    }
    
    base_config = copy.deepcopy(high_polarization_config)
    
    # è®¾ç½®å›ºå®šå‚æ•°
    if plot_type == 'zealot_numbers':
        base_config.morality_rate = combination['morality_rate']
        base_config.zealot_identity_allocation = combination['zealot_identity_allocation']
        base_config.cluster_identity = combination['cluster_identity']
        base_config.enable_zealots = True
        base_config.steps = combination['steps']
    else:  # morality_ratios
        base_config.zealot_count = combination['zealot_count']
        base_config.zealot_mode = combination['zealot_mode']
        base_config.zealot_identity_allocation = combination['zealot_identity_allocation']
        base_config.cluster_identity = combination['cluster_identity']
        base_config.enable_zealots = combination['zealot_mode'] != 'none'
        base_config.steps = combination['steps']
    
    # å¯¹æ¯ä¸ªxå€¼è¿›è¡Œå¤šæ¬¡è¿è¡Œ
    for x_val in tqdm(x_values, desc=f"Running {combination['label']}"):
        runs_data = {
            'mean_opinion': [],
            'variance': [],
            'identity_opinion_difference': [],
            'polarization_index': [],
            'variance_per_identity_1': [],
            'variance_per_identity_-1': []
        }
        
        # è®¾ç½®å½“å‰xå€¼å¯¹åº”çš„å‚æ•°
        current_config = copy.deepcopy(base_config)
        if plot_type == 'zealot_numbers':
            current_config.zealot_count = int(x_val)
            current_config.zealot_mode = combination['zealot_mode']
            if x_val == 0:
                current_config.enable_zealots = False
        else:  # morality_ratios
            current_config.morality_rate = x_val / 100.0  # è½¬æ¢ä¸º0-1èŒƒå›´
        
        # è¿è¡Œå¤šæ¬¡æ¨¡æ‹Ÿ
        for run in range(num_runs):
            try:
                stats = run_single_simulation(current_config)
                # å¤„ç†åŸºç¡€æŒ‡æ ‡
                for metric in ['mean_opinion', 'variance', 'identity_opinion_difference', 'polarization_index']:
                    runs_data[metric].append(stats[metric])
                # å¤„ç† variance per identity æŒ‡æ ‡
                variance_per_identity = stats['variance_per_identity']
                runs_data['variance_per_identity_1'].append(variance_per_identity['identity_1'])
                runs_data['variance_per_identity_-1'].append(variance_per_identity['identity_-1'])
            except Exception as e:
                print(f"Warning: Simulation failed for x={x_val}, run={run}: {e}")
                # ä½¿ç”¨NaNå¡«å……å¤±è´¥çš„è¿è¡Œ
                for metric in runs_data.keys():
                    runs_data[metric].append(np.nan)
        
        # å°†å½“å‰xå€¼çš„æ‰€æœ‰è¿è¡Œç»“æžœæ·»åŠ åˆ°æ€»ç»“æžœä¸­
        for metric in results.keys():
            results[metric].append(runs_data[metric])
    
    return results


def run_parameter_sweep_parallel(plot_type: str, combination: Dict[str, Any], 
                                x_values: List[float], num_runs: int = 5, num_processes: int = 4) -> Dict[str, List[List[float]]]:
    """
    å¹¶è¡Œç‰ˆæœ¬çš„å‚æ•°æ‰«æ
    """
    print(f"ðŸš€ ä½¿ç”¨ {num_processes} ä¸ªè¿›ç¨‹è¿›è¡Œå¹¶è¡Œè®¡ç®—...")
    
    # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
    tasks = []
    for x_val in x_values:
        for run_idx in range(num_runs):
            process_id = len(tasks) % num_processes  # ç®€å•çš„è¿›ç¨‹IDåˆ†é…
            task = (plot_type, combination, x_val, run_idx, combination['steps'], process_id)
            tasks.append(task)
    
    print(f"ðŸ“Š æ€»ä»»åŠ¡æ•°: {len(tasks)} (x_values: {len(x_values)}, runs_per_x: {num_runs})")
    
    # æ‰§è¡Œå¹¶è¡Œè®¡ç®—
    try:
        with multiprocessing.Pool(num_processes) as pool:
            # ä½¿ç”¨ imap æ¥æ˜¾ç¤ºè¿›åº¦
            results_list = []
            with tqdm(total=len(tasks), desc=f"Running {combination['label']} (parallel)") as pbar:
                for result in pool.imap(run_single_simulation_task, tasks):
                    results_list.append(result)
                    pbar.update(1)
    except Exception as e:
        print(f"âŒ å¹¶è¡Œè®¡ç®—å¤±è´¥ï¼Œå›žé€€åˆ°ä¸²è¡Œæ¨¡å¼: {e}")
        return run_parameter_sweep_serial(plot_type, combination, x_values, num_runs)
    
    # æ•´ç†ç»“æžœ
    return organize_parallel_results(results_list, x_values, num_runs)


def organize_parallel_results(results_list: List[Tuple], x_values: List[float], num_runs: int) -> Dict[str, List[List[float]]]:
    """
    å°†å¹¶è¡Œè®¡ç®—ç»“æžœé‡æ–°ç»„ç»‡ä¸ºåŽŸæœ‰çš„æ•°æ®ç»“æž„
    """
    # åˆå§‹åŒ–ç»“æžœç»“æž„
    organized_results = {
        'mean_opinion': [],
        'variance': [],
        'identity_opinion_difference': [],
        'polarization_index': [],
        'variance_per_identity_1': [],
        'variance_per_identity_-1': []
    }
    
    # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥çš„ä»»åŠ¡
    success_count = 0
    failure_count = 0
    
    # æŒ‰ x_value åˆ†ç»„æ•´ç†ç»“æžœ
    for x_val in x_values:
        runs_data = {
            'mean_opinion': [],
            'variance': [],
            'identity_opinion_difference': [],
            'polarization_index': [],
            'variance_per_identity_1': [],
            'variance_per_identity_-1': []
        }
        
        # æ”¶é›†å½“å‰ x_val çš„æ‰€æœ‰è¿è¡Œç»“æžœ
        for run_idx in range(num_runs):
            # åœ¨ç»“æžœåˆ—è¡¨ä¸­æŸ¥æ‰¾å¯¹åº”çš„ç»“æžœ
            found_result = None
            for result in results_list:
                result_x_val, result_run_idx, result_data, success, error_msg = result
                if result_x_val == x_val and result_run_idx == run_idx:
                    found_result = result
                    break
            
            if found_result and found_result[3]:  # success = True
                result_data = found_result[2]
                # å¤„ç†åŸºç¡€æŒ‡æ ‡
                for metric in ['mean_opinion', 'variance', 'identity_opinion_difference', 'polarization_index']:
                    runs_data[metric].append(result_data[metric])
                # å¤„ç† variance per identity æŒ‡æ ‡
                variance_per_identity = result_data['variance_per_identity']
                runs_data['variance_per_identity_1'].append(variance_per_identity['identity_1'])
                runs_data['variance_per_identity_-1'].append(variance_per_identity['identity_-1'])
                success_count += 1
            else:
                # å¤„ç†å¤±è´¥çš„ä»»åŠ¡
                if found_result:
                    print(f"âš ï¸  {found_result[4]}")  # æ‰“å°é”™è¯¯ä¿¡æ¯
                else:
                    print(f"âš ï¸  Missing result for x={x_val}, run={run_idx}")
                
                # ä½¿ç”¨NaNå¡«å……å¤±è´¥çš„è¿è¡Œ
                for metric in runs_data.keys():
                    runs_data[metric].append(np.nan)
                failure_count += 1
        
        # å°†å½“å‰xå€¼çš„æ‰€æœ‰è¿è¡Œç»“æžœæ·»åŠ åˆ°æ€»ç»“æžœä¸­
        for metric in organized_results.keys():
            organized_results[metric].append(runs_data[metric])
    
    print(f"âœ… å¹¶è¡Œè®¡ç®—å®Œæˆ: {success_count} æˆåŠŸ, {failure_count} å¤±è´¥")
    
    return organized_results


# =====================================
# æ•°æ®ç®¡ç†å‡½æ•° (å·²é‡æž„ä¸ºä½¿ç”¨ ExperimentDataManager)
# =====================================

def save_data_with_manager(data_manager: ExperimentDataManager, 
                          plot_type: str, 
                          x_values: List[float], 
                          all_results: Dict[str, Dict[str, List[List[float]]]], 
                          batch_metadata: Dict[str, Any]) -> None:
    """
    ä½¿ç”¨æ–°çš„æ•°æ®ç®¡ç†å™¨ä¿å­˜å®žéªŒæ•°æ®
    
    Args:
        data_manager: æ•°æ®ç®¡ç†å™¨å®žä¾‹
        plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
        x_values: xè½´å–å€¼
        all_results: æ‰€æœ‰ç»„åˆçš„ç»“æžœæ•°æ®
        batch_metadata: æ‰¹æ¬¡å…ƒæ•°æ®
    """
    # è½¬æ¢æ•°æ®æ ¼å¼ä»¥é€‚é…æ–°çš„æ•°æ®ç®¡ç†å™¨
    batch_data = {}
    
    for combination_label, results in all_results.items():
        batch_data[combination_label] = {
            'x_values': x_values,
            'results': results
        }
    
    # ä½¿ç”¨æ•°æ®ç®¡ç†å™¨ä¿å­˜æ•°æ®
    data_manager.save_batch_results(plot_type, batch_data, batch_metadata)


# =====================================
# ç»˜å›¾ç›¸å…³å‡½æ•°
# =====================================

def get_enhanced_style_config(combo_labels: List[str], plot_type: str) -> Dict[str, Dict[str, Any]]:
    """
    ä¸ºç»„åˆæ ‡ç­¾ç”Ÿæˆå¢žå¼ºçš„æ ·å¼é…ç½®ï¼Œç‰¹åˆ«é’ˆå¯¹morality_ratiosçš„10æ¡çº¿è¿›è¡Œä¼˜åŒ–
    
    Args:
    combo_labels: ç»„åˆæ ‡ç­¾åˆ—è¡¨
    plot_type: å›¾è¡¨ç±»åž‹ ('zealot_numbers' æˆ– 'morality_ratios')
    
    Returns:
    dict: æ ·å¼é…ç½®å­—å…¸
    """
    # å®šä¹‰æ‰©å±•çš„é¢œè‰²è°ƒè‰²æ¿
    colors = [
        '#1f77b4',  # è“è‰²
        '#ff7f0e',  # æ©™è‰²  
        '#2ca02c',  # ç»¿è‰²
        '#d62728',  # çº¢è‰²
        '#9467bd',  # ç´«è‰²
        '#8c564b',  # æ£•è‰²
        '#e377c2',  # ç²‰è‰²
        '#7f7f7f',  # ç°è‰²
        '#bcbd22',  # æ©„æ¦„è‰²
        '#17becf',  # é’è‰²
        '#aec7e8',  # æµ…è“è‰²
        '#ffbb78'   # æµ…æ©™è‰²
    ]
    
    # å®šä¹‰å¤šç§çº¿åž‹
    linestyles = ['-', '--', '-.', ':', (0, (3, 1, 1, 1)), (0, (5, 5)), (0, (3, 3)), (0, (1, 1))]
    
    # å®šä¹‰å¤šç§æ ‡è®°
    markers = ['o', 's', '^', 'v', 'D', 'p', '*', 'h', 'H', 'X', '+', 'x']
    
    style_config = {}
    
    if plot_type == 'morality_ratios':
        # å®šä¹‰é¢œè‰²æ˜ å°„ï¼šæŒ‰zealotæ¨¡å¼å’ŒID-alignåˆ†ç»„
        zealot_mode_colors = {
            'None': {
                'base': '#505050',      # æ·±ç°è‰² (ID-cluster=True)
                'light': '#c0c0c0'      # æµ…ç°è‰² (ID-cluster=False)
            },
            'Random': {
                'base': '#ff4500',      # æ·±æ©™çº¢è‰² (ID-align=True)
                'light': '#ff8080'      # æµ…ç²‰çº¢è‰² (ID-align=False)  
            },
            'Clustered': {
                'base': '#0066cc',      # æ·±è“è‰² (ID-align=True)
                'light': '#00cc66'      # äº®ç»¿è‰² (ID-align=False)
            }
        }
        
        # å®šä¹‰æ ‡è®°æ˜ å°„ï¼šæŒ‰ID-clusteråˆ†ç»„
        id_cluster_markers = {
            'True': 'o',      # åœ†å½¢è¡¨ç¤ºID-cluster=True
            'False': '^'      # ä¸‰è§’å½¢è¡¨ç¤ºID-cluster=False
        }
        
        # å®šä¹‰æ ‡è®°å¤§å°æ˜ å°„ï¼šæŒ‰ID-alignåˆ†ç»„
        id_align_sizes = {
            'True': 10,        # å¤§æ ‡è®°è¡¨ç¤ºID-align=True
            'False': 5         # å°æ ‡è®°è¡¨ç¤ºID-align=False
        }
        
        for label in combo_labels:
            # è§£æžæ ‡ç­¾ä¸­çš„é…ç½®ä¿¡æ¯
            if 'None' in label:
                zealot_mode = 'None'
                if 'ID-cluster=True' in label:
                    id_cluster = 'True'
                    color = zealot_mode_colors[zealot_mode]['base']
                    marker = id_cluster_markers[id_cluster]
                    markersize = 8
                else:
                    id_cluster = 'False'
                    color = zealot_mode_colors[zealot_mode]['light']
                    marker = id_cluster_markers[id_cluster]
                    markersize = 8
                
                style_config[label] = {
                    'color': color,
                    'linestyle': '-',
                    'marker': marker,
                    'markersize': markersize,
                    'group': 'None'
                }
                
            elif 'Random' in label:
                zealot_mode = 'Random'
                id_align = 'True' if 'ID-align=True' in label else 'False'
                id_cluster = 'True' if 'ID-cluster=True' in label else 'False'
                
                color = zealot_mode_colors[zealot_mode]['base'] if id_align == 'True' else zealot_mode_colors[zealot_mode]['light']
                marker = id_cluster_markers[id_cluster]
                markersize = id_align_sizes[id_align]
                
                style_config[label] = {
                    'color': color,
                    'linestyle': '-',
                    'marker': marker,
                    'markersize': markersize,
                    'group': 'Random'
                }
                
            elif 'Clustered' in label:
                zealot_mode = 'Clustered'
                id_align = 'True' if 'ID-align=True' in label else 'False'
                id_cluster = 'True' if 'ID-cluster=True' in label else 'False'
                
                color = zealot_mode_colors[zealot_mode]['base'] if id_align == 'True' else zealot_mode_colors[zealot_mode]['light']
                marker = id_cluster_markers[id_cluster]
                markersize = id_align_sizes[id_align]
                
                style_config[label] = {
                    'color': color,
                    'linestyle': '-',
                    'marker': marker,
                    'markersize': markersize,
                    'group': 'Clustered'
                }
    else:
        # å¯¹äºŽzealot_numbersï¼Œä½¿ç”¨ç®€å•é…ç½®
        for i, label in enumerate(combo_labels):
            style_config[label] = {
                'color': colors[i % len(colors)],
                'linestyle': linestyles[i % len(linestyles)],
                'marker': markers[i % len(markers)],
                'markersize': 7,
                'group': 'Default'
            }
    
    return style_config


def get_variance_per_identity_style(identity_label: str, plot_type: str) -> Dict[str, Any]:
    """
    ä¸º variance per identity å›¾è¡¨ç”Ÿæˆç‰¹æ®Šçš„æ ·å¼é…ç½®
    
    Args:
        identity_label: å¸¦èº«ä»½æ ‡è¯†çš„æ ‡ç­¾ï¼Œå¦‚ "Random, ID-align=True (ID=1)"
        plot_type: å›¾è¡¨ç±»åž‹
    
    Returns:
        dict: æ ·å¼é…ç½®
    """
    # æ‰©å±•é¢œè‰²è°ƒè‰²æ¿ä»¥æ”¯æŒæ›´å¤šçº¿æ¡
    colors = [
        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b',
        '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#aec7e8', '#ffbb78',
        '#ff9896', '#c5b0d5', '#c49c94', '#f7b6d3', '#c7c7c7', '#dbdb8d',
        '#9edae5', '#c49c94', '#f7b6d3', '#c7c7c7', '#dbdb8d', '#9edae5'
    ]
    
    # çº¿åž‹ç»„åˆï¼šå®žçº¿ç”¨äºŽ ID=1ï¼Œè™šçº¿ç”¨äºŽ ID=-1
    linestyles = {
        '1': '-',      # å®žçº¿ç”¨äºŽ identity=1
        '-1': '--'     # è™šçº¿ç”¨äºŽ identity=-1
    }
    
    # æ ‡è®°å½¢çŠ¶ï¼šåœ†å½¢ç”¨äºŽ ID=1ï¼Œæ–¹å½¢ç”¨äºŽ ID=-1
    markers = {
        '1': 'o',      # åœ†å½¢ç”¨äºŽ identity=1
        '-1': 's'      # æ–¹å½¢ç”¨äºŽ identity=-1
    }
    
    # æå–èº«ä»½å€¼
    identity_val = identity_label.split('(ID=')[-1].rstrip(')')
    
    # æå–åŽŸå§‹ç»„åˆæ ‡ç­¾
    base_label = identity_label.split(' (ID=')[0]
    
    # è®¡ç®—é¢œè‰²ç´¢å¼•ï¼ˆåŸºäºŽåŽŸå§‹ç»„åˆæ ‡ç­¾çš„å“ˆå¸Œå€¼ï¼‰
    color_index = abs(hash(base_label)) % len(colors)
    
    # ä¸º ID=-1 ä½¿ç”¨ç¨å¾®ä¸åŒçš„é¢œè‰²ï¼ˆè°ƒæ•´äº®åº¦ï¼‰
    if identity_val == '-1':
        color_index = (color_index + len(colors) // 2) % len(colors)
    
    return {
        'color': colors[color_index],
        'linestyle': linestyles.get(identity_val, '-'),
        'marker': markers.get(identity_val, 'o'),
        'markersize': 8 if identity_val == '1' else 6,  # ID=1 ç¨å¤§çš„æ ‡è®°
        'group': f'identity_{identity_val}'
    }


def get_combined_variance_per_identity_style(identity_label: str, plot_type: str) -> Dict[str, Any]:
    """
    ä¸ºåˆå¹¶çš„ variance per identity å›¾è¡¨ç”Ÿæˆæ ·å¼é…ç½®
    
    ç›¸åŒé…ç½®çš„ä¸¤æ¡çº¿ä½¿ç”¨ç›¸åŒé¢œè‰²å’Œæ ‡è®°ï¼Œä½†ç”¨å®žçº¿/è™šçº¿åŒºåˆ†èº«ä»½ç»„
    
    Args:
        identity_label: å¸¦èº«ä»½æ ‡è¯†çš„æ ‡ç­¾ï¼Œå¦‚ "Random, ID-align=True (ID=+1)"
        plot_type: å›¾è¡¨ç±»åž‹
    
    Returns:
        dict: æ ·å¼é…ç½®
    """
    # æ‰©å±•é¢œè‰²è°ƒè‰²æ¿
    colors = [
        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b',
        '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#aec7e8', '#ffbb78',
        '#ff9896', '#c5b0d5', '#c49c94', '#f7b6d3', '#c7c7c7', '#dbdb8d',
        '#9edae5', '#c49c94', '#f7b6d3', '#c7c7c7', '#dbdb8d', '#9edae5'
    ]
    
    # æå–èº«ä»½å€¼ï¼ˆ+1 æˆ– -1ï¼‰
    identity_val = identity_label.split('(ID=')[-1].rstrip(')')
    
    # æå–åŽŸå§‹ç»„åˆæ ‡ç­¾
    base_label = identity_label.split(' (ID=')[0]
    
    # åŸºäºŽåŽŸå§‹ç»„åˆæ ‡ç­¾è®¡ç®—é¢œè‰²ç´¢å¼•ï¼ˆç¡®ä¿ç›¸åŒé…ç½®ä½¿ç”¨ç›¸åŒé¢œè‰²ï¼‰
    color_index = abs(hash(base_label)) % len(colors)
    
    # çº¿åž‹ï¼š+1 ç”¨å®žçº¿ï¼Œ-1 ç”¨è™šçº¿
    linestyle = '-' if identity_val == '+1' else '--'
    
    # æ ‡è®°ï¼šç›¸åŒé…ç½®ä½¿ç”¨ç›¸åŒæ ‡è®°
    markers = ['o', 's', '^', 'v', 'D', 'p', '*', 'h', 'H', 'X', '+', 'x']
    marker_index = abs(hash(base_label)) % len(markers)
    marker = markers[marker_index]
    
    # æ ‡è®°å¤§å°ï¼š+1 ç¨å¤§ï¼Œ-1 ç¨å°
    markersize = 8 if identity_val == '+1' else 6
    
    return {
        'color': colors[color_index],
        'linestyle': linestyle,
        'marker': marker,
        'markersize': markersize,
        'group': f'combined_identity_{identity_val}'
    }


def simplify_label(combo_label: str) -> str:
    """
    ç®€åŒ–ç»„åˆæ ‡ç­¾ï¼ˆå½“å‰ä¿æŒåŽŸå§‹æ ‡ç­¾ä»¥ç¡®ä¿å®Œæ•´å«ä¹‰ï¼‰
    
    Args:
    combo_label: åŽŸå§‹ç»„åˆæ ‡ç­¾
    
    Returns:
    str: ç®€åŒ–åŽçš„æ ‡ç­¾
    """
    return combo_label


def plot_results_with_manager(data_manager: ExperimentDataManager, 
                            plot_type: str) -> None:
    """
    ä½¿ç”¨æ•°æ®ç®¡ç†å™¨ç»˜åˆ¶å®žéªŒç»“æžœå›¾è¡¨
    
    Args:
        data_manager: æ•°æ®ç®¡ç†å™¨å®žä¾‹  
        plot_type: 'zealot_numbers' æˆ– 'morality_ratios'
    """
    # ä»Žæ•°æ®ç®¡ç†å™¨èŽ·å–ç»˜å›¾æ•°æ®
    all_results, x_values, total_runs_per_combination = data_manager.convert_to_plotting_format(plot_type)
    
    if not all_results:
        print(f"âŒ No data found for {plot_type} plotting")
        return
    
    output_dir = str(data_manager.base_dir)
    metrics = ['mean_opinion', 'variance', 'identity_opinion_difference', 'polarization_index', 
               'variance_per_identity_1', 'variance_per_identity_-1', 'variance_per_identity_combined']
    metric_labels = {
        'mean_opinion': 'Mean Opinion',
        'variance': 'Opinion Variance',
        'identity_opinion_difference': 'Identity Opinion Difference',
        'polarization_index': 'Polarization Index',
        'variance_per_identity_1': 'Variance per Identity (+1)',
        'variance_per_identity_-1': 'Variance per Identity (-1)',
        'variance_per_identity_combined': 'Variance per Identity (Both Groups)'
    }
    
    x_label = 'Number of Zealots' if plot_type == 'zealot_numbers' else 'Morality Ratio (%)'
    
    # è®¡ç®—æ€»è¿è¡Œæ¬¡æ•°èŒƒå›´ï¼ˆç”¨äºŽæ–‡ä»¶åï¼‰
    min_runs = min(total_runs_per_combination.values()) if total_runs_per_combination else 0
    max_runs = max(total_runs_per_combination.values()) if total_runs_per_combination else 0
    
    if min_runs == max_runs:
        runs_suffix = f"_{min_runs}runs"
    else:
        runs_suffix = f"_{min_runs}-{max_runs}runs"
    
    # åˆ›å»º mean_plots æ–‡ä»¶å¤¹
    plot_folders = {
        'mean': os.path.join(output_dir, 'mean_plots')
    }
    
    os.makedirs(plot_folders['mean'], exist_ok=True)

    # èŽ·å–æ ·å¼é…ç½®
    combo_labels = list(all_results.keys())
    style_config = get_enhanced_style_config(combo_labels, plot_type)
    
    print(f"\nðŸ“ Style Configuration for {plot_type}: {len(combo_labels)} combinations")
    print(f"âœ… Style configuration completed successfully")
    
    # ä¸ºæ¯ä¸ªæŒ‡æ ‡ç”Ÿæˆé«˜è´¨é‡çš„ mean plots
    for metric in metrics:
        print(f"  Generating high-quality mean plot for {metric_labels[metric]}...")
        
        # é¢„å¤„ç†æ•°æ®ï¼šè®¡ç®—å‡å€¼
        processed_data = {}
        
        if metric == 'variance_per_identity_combined':
            # å¯¹äºŽåˆå¹¶çš„ variance per identity å›¾è¡¨ï¼Œä¸ºæ¯ä¸ªç»„åˆåˆ›å»ºä¸¤æ¡çº¿
            for combo_label, results in all_results.items():
                # å¤„ç† identity=1 çš„æ•°æ®
                metric_data_1 = results['variance_per_identity_1']
                means_1 = []
                for i, x_runs in enumerate(metric_data_1):
                    valid_runs = [val for val in x_runs if not np.isnan(val)]
                    if valid_runs:
                        means_1.append(np.mean(valid_runs))
                    else:
                        means_1.append(np.nan)
                
                # å¤„ç† identity=-1 çš„æ•°æ®
                metric_data_neg1 = results['variance_per_identity_-1']
                means_neg1 = []
                for i, x_runs in enumerate(metric_data_neg1):
                    valid_runs = [val for val in x_runs if not np.isnan(val)]
                    if valid_runs:
                        means_neg1.append(np.mean(valid_runs))
                    else:
                        means_neg1.append(np.nan)
                
                # åˆ›å»ºä¸¤æ¡çº¿çš„æ•°æ®
                processed_data[f"{combo_label} (ID=+1)"] = {
                    'means': np.array(means_1),
                    'identity': '+1',
                    'base_combo': combo_label
                }
                processed_data[f"{combo_label} (ID=-1)"] = {
                    'means': np.array(means_neg1),
                    'identity': '-1',
                    'base_combo': combo_label
                }
        elif metric.startswith('variance_per_identity') and metric != 'variance_per_identity_combined':
            # å¯¹äºŽå•ç‹¬çš„ variance per identity æŒ‡æ ‡ï¼Œæ¯ä¸ªç»„åˆæ ‡ç­¾ä¼šè¢«æ‹†åˆ†ä¸ºä¸¤æ¡çº¿
            identity_suffix = metric.split('_')[-1]  # '1' or '-1'
            
            for combo_label, results in all_results.items():
                metric_data = results[metric]
                means = []
                
                for i, x_runs in enumerate(metric_data):
                    valid_runs = [val for val in x_runs if not np.isnan(val)]
                    if valid_runs:
                        means.append(np.mean(valid_runs))
                    else:
                        means.append(np.nan)
                
                # ä¸º variance per identity åˆ›å»ºå¸¦èº«ä»½æ ‡è¯†çš„æ ‡ç­¾
                identity_label = f"{combo_label} (ID={identity_suffix})"
                processed_data[identity_label] = {
                    'means': np.array(means)
                }
        else:
            # å¯¹äºŽå…¶ä»–æŒ‡æ ‡ï¼Œä¿æŒåŽŸæœ‰å¤„ç†æ–¹å¼
            for combo_label, results in all_results.items():
                metric_data = results[metric]
                means = []
                
                for i, x_runs in enumerate(metric_data):
                    valid_runs = [val for val in x_runs if not np.isnan(val)]
                    if valid_runs:
                        means.append(np.mean(valid_runs))
                    else:
                        means.append(np.nan)
                
                processed_data[combo_label] = {
                    'means': np.array(means)
                }
        
        # æ·»åŠ è¿è¡Œæ¬¡æ•°ä¿¡æ¯åˆ°æ ‡é¢˜ï¼ˆæ˜¾ç¤ºæ€»runæ•°ï¼‰
        title_suffix = f" ({min_runs}-{max_runs} total runs)" if min_runs != max_runs else f" ({min_runs} total runs)"
        
        # é«˜è´¨é‡å‡å€¼æ›²çº¿å›¾
        # å¯¹äºŽ variance per identityï¼Œä½¿ç”¨æ›´å¤§çš„å›¾è¡¨ä»¥å®¹çº³æ›´å¤šçº¿æ¡
        if metric.startswith('variance_per_identity'):
            plt.figure(figsize=(24, 14) if plot_type == 'morality_ratios' else (20, 12))
        else:
            plt.figure(figsize=(20, 12) if plot_type == 'morality_ratios' else (18, 10))
            
        for display_label, data in processed_data.items():
            # å¯¹äºŽ variance per identityï¼Œéœ€è¦ä»Žæ˜¾ç¤ºæ ‡ç­¾ä¸­æå–åŽŸå§‹ç»„åˆæ ‡ç­¾æ¥èŽ·å–runsä¿¡æ¯
            if metric.startswith('variance_per_identity'):
                # ä»Ž "Original Label (ID=1)" ä¸­æå– "Original Label"
                if metric == 'variance_per_identity_combined':
                    # å¯¹äºŽåˆå¹¶å›¾è¡¨ï¼Œä½¿ç”¨ base_combo å­—æ®µ
                    original_combo_label = data.get('base_combo', display_label.split(' (ID=')[0])
                else:
                    original_combo_label = display_label.split(' (ID=')[0]
                runs_info = total_runs_per_combination.get(original_combo_label, 0)
            else:
                original_combo_label = display_label
                runs_info = total_runs_per_combination.get(display_label, 0)
            
            short_label = simplify_label(display_label)
            label_with_runs = f"{short_label} (n={runs_info})"
            
            # ä¸ºä¸åŒç±»åž‹çš„ variance per identity å›¾è¡¨é€‰æ‹©åˆé€‚çš„æ ·å¼é…ç½®å‡½æ•°
            if metric == 'variance_per_identity_combined':
                style = get_combined_variance_per_identity_style(display_label, plot_type)
            elif metric.startswith('variance_per_identity'):
                style = get_variance_per_identity_style(display_label, plot_type)
            else:
                style = style_config.get(display_label, {})
            
            plt.plot(x_values, data['means'], label=label_with_runs, 
                    color=style.get('color', 'blue'),
                    linestyle=style.get('linestyle', '-'),
                    marker=style.get('marker', 'o'), 
                    linewidth=3.5, markersize=style.get('markersize', 10), alpha=0.85,
                    markeredgewidth=2, markeredgecolor='white')
        
        plt.xlabel(x_label, fontsize=16)
        plt.ylabel(metric_labels[metric], fontsize=16)
        plt.title(f'{metric_labels[metric]} vs {x_label}{title_suffix}', fontsize=18, fontweight='bold')
        
        # æ ¹æ®æŒ‡æ ‡ç±»åž‹å’Œçº¿æ¡æ•°é‡è°ƒæ•´å›¾ä¾‹å¸ƒå±€
        if metric == 'variance_per_identity_combined':
            # åˆå¹¶çš„ variance per identity å›¾è¡¨ï¼šæ¯ä¸ªç»„åˆ2æ¡çº¿
            if plot_type == 'morality_ratios':
                # 20æ¡çº¿ï¼Œä½¿ç”¨4åˆ—
                plt.legend(bbox_to_anchor=(0.5, -0.20), loc='upper center', ncol=4, 
                          fontsize=10, frameon=True, fancybox=True, shadow=True)
            else:
                # 8æ¡çº¿ï¼Œä½¿ç”¨3åˆ—
                plt.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=3, fontsize=11)
        elif metric.startswith('variance_per_identity'):
            # å•ç‹¬çš„ variance per identity å›¾è¡¨æœ‰æ›´å¤šçº¿æ¡ï¼Œéœ€è¦æ›´å¤šåˆ—å’Œæ›´å°å­—ä½“
            if plot_type == 'morality_ratios':
                # 20æ¡çº¿ï¼Œä½¿ç”¨4åˆ—
                plt.legend(bbox_to_anchor=(0.5, -0.20), loc='upper center', ncol=4, 
                          fontsize=10, frameon=True, fancybox=True, shadow=True)
            else:
                # 8æ¡çº¿ï¼Œä½¿ç”¨3åˆ—
                plt.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=3, fontsize=11)
        else:
            # å…¶ä»–æŒ‡æ ‡ä¿æŒåŽŸæœ‰å¸ƒå±€
            if plot_type == 'morality_ratios':
                plt.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=3, 
                          fontsize=12, frameon=True, fancybox=True, shadow=True)
            else:
                plt.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=2, fontsize=12)
        
        plt.grid(True, alpha=0.3, linestyle='--')
        plt.tight_layout()
        
        filename = f"{plot_type}_{metric}_mean{runs_suffix}.png"
        filepath = os.path.join(plot_folders['mean'], filename)
        
        # é«˜è´¨é‡PNGä¿å­˜ (DPI 300)
        plt.savefig(filepath, dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='white', 
                   format='png', transparent=False, 
                   pad_inches=0.1, metadata={'Creator': 'Zealot Morality Analysis'})
        
        plt.close()
    
    print(f"  âœ… Generated high-quality mean plots for {plot_type}:")
    print(f"     - Mean line plots: {plot_folders['mean']}")


# =====================================
# é«˜çº§æŽ¥å£å‡½æ•°
# =====================================

def run_and_accumulate_data(output_dir: str = "results/zealot_morality_analysis", 
                           num_runs: int = 5, max_zealots: int = 50, max_morality: int = 30,
                           batch_name: str = "", num_processes: int = 1):
    """
    è¿è¡Œæµ‹è¯•å¹¶ä½¿ç”¨æ–°çš„æ•°æ®ç®¡ç†å™¨ä¿å­˜æ•°æ®ï¼ˆç¬¬ä¸€éƒ¨åˆ†ï¼‰
    
    Args:
    output_dir: è¾“å‡ºç›®å½•
    num_runs: æœ¬æ¬¡è¿è¡Œçš„æ¬¡æ•°
    max_zealots: æœ€å¤§zealotæ•°é‡
    max_morality: æœ€å¤§morality ratio (%)
    batch_name: æ‰¹æ¬¡åç§°ï¼Œç”¨äºŽæ ‡è¯†æœ¬æ¬¡è¿è¡Œ
    num_processes: å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œ1è¡¨ç¤ºä¸²è¡Œæ‰§è¡Œ
    """
    print("ðŸ”¬ Running Tests and Accumulating Data with New Data Manager")
    print("=" * 70)
    
    start_time = time.time()
    
    # åˆ›å»ºæ•°æ®ç®¡ç†å™¨
    data_manager = ExperimentDataManager(output_dir)
    
    # èŽ·å–å‚æ•°ç»„åˆ
    combinations = create_config_combinations()
    
    if not batch_name:
        batch_name = time.strftime("%Y%m%d_%H%M%S")
    
    print(f"ðŸ“Š Batch Configuration:")
    print(f"   Batch name: {batch_name}")
    print(f"   Number of runs this batch: {num_runs}")
    print(f"   Max zealots: {max_zealots}")
    print(f"   Max morality ratio: {max_morality}%")
    print(f"   Parallel processes: {num_processes} ({'Parallel' if num_processes > 1 else 'Serial'})")
    print(f"   Output directory: {output_dir}")
    print(f"   Storage format: Parquet (optimized for space and speed)")
    print()
    
    # === å¤„ç†å›¾1ï¼šxè½´ä¸ºzealot numbers ===
    print("ðŸ“ˆ Running Test Type 1: Zealot Numbers Analysis")
    print("-" * 50)
    
    plot1_start_time = time.time()
    
    zealot_x_values = list(range(0, max_zealots + 1, 1))  # 0, 1, 2, ..., n
    zealot_results = {}
    
    for combo in combinations['zealot_numbers']:
        print(f"Running combination: {combo['label']}")
        results = run_parameter_sweep('zealot_numbers', combo, zealot_x_values, num_runs, num_processes)
        zealot_results[combo['label']] = results
    
    # ä½¿ç”¨æ–°çš„æ•°æ®ç®¡ç†å™¨ä¿å­˜zealot numbersçš„æ•°æ®
    zealot_batch_metadata = {
        'batch_id': batch_name,
        'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
        'experiment_type': 'zealot_numbers',
        'num_runs': num_runs,
        'max_zealots': max_zealots,
        'x_range': [0, max_zealots],
        'combinations_count': len(combinations['zealot_numbers'])
    }
    
    save_data_with_manager(data_manager, 'zealot_numbers', zealot_x_values, zealot_results, zealot_batch_metadata)
    
    plot1_end_time = time.time()
    plot1_duration = plot1_end_time - plot1_start_time
    
    print(f"â±ï¸  Test Type 1 completed in: {format_duration(plot1_duration)}")
    print()
    
    # === å¤„ç†å›¾2ï¼šxè½´ä¸ºmorality ratio ===
    print("ðŸ“ˆ Running Test Type 2: Morality Ratio Analysis")
    print("-" * 50)
    
    plot2_start_time = time.time()
    
    morality_x_values = list(range(0, max_morality + 1, 1))  # 0, 1, 2, ..., n
    morality_results = {}
    
    for combo in combinations['morality_ratios']:
        print(f"Running combination: {combo['label']}")
        results = run_parameter_sweep('morality_ratios', combo, morality_x_values, num_runs, num_processes)
        morality_results[combo['label']] = results
    
    # ä½¿ç”¨æ–°çš„æ•°æ®ç®¡ç†å™¨ä¿å­˜morality ratioçš„æ•°æ®
    morality_batch_metadata = {
        'batch_id': batch_name,
        'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
        'experiment_type': 'morality_ratios', 
        'num_runs': num_runs,
        'max_morality': max_morality,
        'x_range': [0, max_morality],
        'combinations_count': len(combinations['morality_ratios'])
    }
    
    save_data_with_manager(data_manager, 'morality_ratios', morality_x_values, morality_results, morality_batch_metadata)
    
    plot2_end_time = time.time()
    plot2_duration = plot2_end_time - plot2_start_time
    
    print(f"â±ï¸  Test Type 2 completed in: {format_duration(plot2_duration)}")
    print()
    
    # è®¡ç®—æ€»è€—æ—¶
    end_time = time.time()
    elapsed_time = end_time - start_time
    hours, remainder = divmod(elapsed_time, 3600)
    minutes, seconds = divmod(remainder, 60)
    
    print("\n" + "=" * 70)
    print("ðŸŽ‰ Data Collection Completed Successfully!")
    print(f"ðŸ“Š Batch '{batch_name}' with {num_runs} runs per parameter point")
    print()
    print("â±ï¸  Timing Summary:")
    print(f"   Test Type 1 (Zealot Numbers): {format_duration(plot1_duration)}")
    print(f"   Test Type 2 (Morality Ratios): {format_duration(plot2_duration)}")
    print(f"   Total execution time: {format_duration(elapsed_time)}")
    print(f"ðŸ“ Data saved using Parquet format in: {output_dir}/")
    
    # ä¿å­˜å®žéªŒé…ç½®åˆ°æ•°æ®ç®¡ç†å™¨
    experiment_config = {
        'batch_name': batch_name,
        'num_runs': num_runs,
        'max_zealots': max_zealots,
        'max_morality': max_morality,
        'elapsed_time': elapsed_time,
        'total_combinations': len(combinations['zealot_numbers']) + len(combinations['morality_ratios'])
    }
    data_manager.save_experiment_config(experiment_config)
    
    # æ˜¾ç¤ºæ•°æ®ç®¡ç†å™¨æ‘˜è¦
    print("\n" + data_manager.export_summary_report())


def plot_from_accumulated_data(output_dir: str = "results/zealot_morality_analysis"):
    """
    ä»Žæ–°çš„æ•°æ®ç®¡ç†å™¨ä¸­è¯»å–æ•°æ®å¹¶ç”Ÿæˆå›¾è¡¨ï¼ˆç¬¬äºŒéƒ¨åˆ†ï¼‰
    
    Args:
    output_dir: è¾“å‡ºç›®å½•
    """
    print("ðŸ“Š Generating Plots from Data Manager")
    print("=" * 70)
    
    start_time = time.time()
    
    # åˆ›å»ºæ•°æ®ç®¡ç†å™¨
    data_manager = ExperimentDataManager(output_dir)
    
    # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
    print("\n" + data_manager.export_summary_report())
    
    # ç”Ÿæˆzealot numberså›¾è¡¨
    print("\nðŸ“ˆ Generating Zealot Numbers Plots...")
    zealot_summary = data_manager.get_experiment_summary('zealot_numbers')
    if zealot_summary['total_records'] > 0:
        plot_results_with_manager(data_manager, 'zealot_numbers')
        print(f"âœ… Generated {len(zealot_summary['combinations'])} zealot numbers plots")
    else:
        print("âŒ No zealot numbers data found")
    
    # ç”Ÿæˆmorality ratioså›¾è¡¨
    print("\nðŸ“ˆ Generating Morality Ratios Plots...")
    morality_summary = data_manager.get_experiment_summary('morality_ratios')
    if morality_summary['total_records'] > 0:
        plot_results_with_manager(data_manager, 'morality_ratios')
        print(f"âœ… Generated {len(morality_summary['combinations'])} morality ratios plots")
    else:
        print("âŒ No morality ratios data found")
    
    # è®¡ç®—æ€»è€—æ—¶
    end_time = time.time()
    elapsed_time = end_time - start_time
    
    print("\n" + "=" * 70)
    print("ðŸŽ‰ Plot Generation Completed Successfully!")
    print(f"ðŸ“Š Generated plots from Parquet data files")
    print(f"â±ï¸  Total plotting time: {format_duration(elapsed_time)}")
    print(f"ðŸ“ Plots saved to: {output_dir}/mean_plots/")


def run_zealot_morality_analysis(output_dir: str = "results/zealot_morality_analysis", 
                                num_runs: int = 5, max_zealots: int = 50, max_morality: int = 30, num_processes: int = 1):
    """
    è¿è¡Œå®Œæ•´çš„zealotå’Œmoralityåˆ†æžå®žéªŒï¼ˆä¿æŒå‘åŽå…¼å®¹ï¼‰
    
    Args:
    output_dir: è¾“å‡ºç›®å½•
    num_runs: æ¯ä¸ªå‚æ•°ç‚¹çš„è¿è¡Œæ¬¡æ•°
    max_zealots: æœ€å¤§zealotæ•°é‡
    max_morality: æœ€å¤§morality ratio (%)
    num_processes: å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œ1è¡¨ç¤ºä¸²è¡Œæ‰§è¡Œ
    """
    print("ðŸ”¬ Starting Complete Zealot and Morality Analysis Experiment")
    print("=" * 70)
    
    # ç¬¬ä¸€æ­¥ï¼šè¿è¡Œæµ‹è¯•å¹¶ç´¯ç§¯æ•°æ®
    run_and_accumulate_data(output_dir, num_runs, max_zealots, max_morality, "", num_processes)
    
    # ç¬¬äºŒæ­¥ï¼šä»Žç´¯ç§¯æ•°æ®ç”Ÿæˆå›¾è¡¨
    plot_from_accumulated_data(output_dir)


def run_no_zealot_morality_data(output_dir: str = "results/zealot_morality_analysis", 
                               num_runs: int = 5, max_morality: int = 30,
                               batch_name: str = "", num_processes: int = 1):
    """
    å•ç‹¬è¿è¡Œ no zealot çš„ morality ratio æ•°æ®æ”¶é›†ï¼ˆä½¿ç”¨æ–°æ•°æ®ç®¡ç†å™¨ï¼‰
    
    Args:
    output_dir: è¾“å‡ºç›®å½•
    num_runs: æ¯ä¸ªå‚æ•°ç‚¹çš„è¿è¡Œæ¬¡æ•°
    max_morality: æœ€å¤§ morality ratio (%)
    batch_name: æ‰¹æ¬¡åç§°
    num_processes: å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œ1è¡¨ç¤ºä¸²è¡Œæ‰§è¡Œ
    """
    print("ðŸ”¬ Running No Zealot Morality Ratio Data Collection with New Data Manager")
    print("=" * 70)
    
    start_time = time.time()
    
    # åˆ›å»ºæ•°æ®ç®¡ç†å™¨
    data_manager = ExperimentDataManager(output_dir)
    
    # èŽ·å–æ‰€æœ‰å‚æ•°ç»„åˆ
    combinations = create_config_combinations()
    
    # åªé€‰æ‹© zealot_mode ä¸º 'none' çš„ç»„åˆ
    no_zealot_combinations = [combo for combo in combinations['morality_ratios'] 
                             if combo['zealot_mode'] == 'none']
    
    if not no_zealot_combinations:
        print("âŒ æ²¡æœ‰æ‰¾åˆ° zealot_mode='none' çš„ç»„åˆ")
        return
    
    if not batch_name:
        batch_name = f"no_zealot_{time.strftime('%Y%m%d_%H%M%S')}"
    
    print(f"ðŸ“Š No Zealot Batch Configuration:")
    print(f"   Batch name: {batch_name}")
    print(f"   Number of runs this batch: {num_runs}")
    print(f"   Max morality ratio: {max_morality}%")
    print(f"   Number of no-zealot combinations: {len(no_zealot_combinations)}")
    print(f"   Output directory: {output_dir}")
    print(f"   Storage format: Parquet (optimized for space and speed)")
    print()
    
    # è®¾ç½® morality ratio çš„ x è½´å–å€¼
    morality_x_values = list(range(0, max_morality + 1, 2))  # 0, 2, 4, ..., max_morality
    morality_results = {}
    
    print("ðŸ“ˆ Running No Zealot Morality Ratio Analysis")
    print("-" * 50)
    
    for combo in no_zealot_combinations:
        print(f"Running no-zealot combination: {combo['label']}")
        results = run_parameter_sweep('morality_ratios', combo, morality_x_values, num_runs, num_processes)
        morality_results[combo['label']] = results
    
    # ä½¿ç”¨æ–°çš„æ•°æ®ç®¡ç†å™¨ä¿å­˜ no zealot morality ratio æ•°æ®
    no_zealot_batch_metadata = {
        'batch_id': batch_name,
        'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
        'experiment_type': 'morality_ratios_no_zealot',
        'num_runs': num_runs,
        'max_morality': max_morality,
        'x_range': [0, max_morality],
        'combinations_count': len(no_zealot_combinations),
        'special_conditions': 'no_zealot_only'
    }
    
    save_data_with_manager(data_manager, 'morality_ratios', morality_x_values, morality_results, no_zealot_batch_metadata)
    
    # è®¡ç®—è€—æ—¶
    end_time = time.time()
    elapsed_time = end_time - start_time
    
    print("\n" + "=" * 70)
    print("ðŸŽ‰ No Zealot Data Collection Completed Successfully!")
    print(f"ðŸ“Š Batch '{batch_name}' with {num_runs} runs per parameter point")
    print(f"â±ï¸  Total execution time: {format_duration(elapsed_time)}")
    print(f"ðŸ“ Data saved using Parquet format in: {output_dir}/")
    
    # ä¿å­˜å®žéªŒé…ç½®åˆ°æ•°æ®ç®¡ç†å™¨
    experiment_config = {
        'batch_name': batch_name,
        'num_runs': num_runs,
        'max_morality': max_morality,
        'elapsed_time': elapsed_time,
        'total_combinations': len(no_zealot_combinations),
        'experiment_type': 'no_zealot_only'
    }
    data_manager.save_experiment_config(experiment_config)
    
    # æ˜¾ç¤ºæ•°æ®ç®¡ç†å™¨æ‘˜è¦
    print("\n" + data_manager.export_summary_report())


if __name__ == "__main__":
    # æ–°çš„åˆ†ç¦»å¼ä½¿ç”¨æ–¹æ³•ï¼š
    
    # å¼€å§‹è®¡æ—¶
    main_start_time = time.time()
    
    # æ–¹æ³•1ï¼šåˆ†ä¸¤æ­¥è¿è¡Œ
    # ç¬¬ä¸€æ­¥ï¼šè¿è¡Œæµ‹è¯•å¹¶ç§¯ç´¯æ•°æ®ï¼ˆå¯ä»¥å¤šæ¬¡è¿è¡Œä»¥ç§¯ç´¯æ›´å¤šæ•°æ®ï¼‰
    print("=" * 50)
    print("ðŸš€ ç¤ºä¾‹ï¼šåˆ†æ­¥éª¤è¿è¡Œå®žéªŒ")
    print("=" * 50)
    
    # æ•°æ®æ”¶é›†é˜¶æ®µ
    data_collection_start_time = time.time()
    
    # å¯ä»¥å¤šæ¬¡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥ç§¯ç´¯æ•°æ®ï¼š
    run_and_accumulate_data(
        output_dir="results/zealot_morality_analysis",
        num_runs=100,  # æ¯æ¬¡è¿è¡Œ100è½®æµ‹è¯•
        max_zealots=100,  
        max_morality=100,
        # batch_name="batch_001"  # å¯é€‰ï¼šç»™æ‰¹æ¬¡å‘½å
        num_processes=8  # ä½¿ç”¨8ä¸ªè¿›ç¨‹è¿›è¡Œå¹¶è¡Œè®¡ç®—
    )
    
    data_collection_end_time = time.time()
    data_collection_duration = data_collection_end_time - data_collection_start_time
    

    # ç¬¬äºŒæ­¥ï¼šç»˜å›¾é˜¶æ®µ

    plotting_start_time = time.time()

    plot_from_accumulated_data("results/zealot_morality_analysis")
    
    plotting_end_time = time.time()
    plotting_duration = plotting_end_time - plotting_start_time
    
    # è®¡ç®—æ€»è€—æ—¶
    main_end_time = time.time()
    total_duration = main_end_time - main_start_time
    
    # æ˜¾ç¤ºè€—æ—¶æ€»ç»“
    print("\n" + "ðŸ•’" * 50)
    print("â±ï¸  å®Œæ•´å®žéªŒè€—æ—¶æ€»ç»“")
    print("ðŸ•’" * 50)
    # print(f"ðŸ“Š æ•°æ®æ”¶é›†é˜¶æ®µè€—æ—¶: {format_duration(data_collection_duration)}")
    print(f"ðŸ“ˆ å›¾è¡¨ç”Ÿæˆé˜¶æ®µè€—æ—¶: {format_duration(plotting_duration)}")
    print(f"ðŸŽ¯ æ€»è€—æ—¶: {format_duration(total_duration)}")
    print("ðŸ•’" * 50) 